{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4TU5XBhNQROA","outputId":"929ba8f1-24f1-4a30-e326-f2ff8582f05a","executionInfo":{"status":"ok","timestamp":1673545040712,"user_tz":-60,"elapsed":81957,"user":{"displayName":"Adrien","userId":"14922326483433512417"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["#%cd /content/drive/MyDrive/FR/Master/M2_IASD/DeepLearning/project_DL"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u1QFegZk3sMh","executionInfo":{"status":"ok","timestamp":1673545043036,"user_tz":-60,"elapsed":352,"user":{"displayName":"Adrien","userId":"14922326483433512417"}},"outputId":"45e4c5db-e33d-4804-b1a3-8abb29188aca"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: '/content/drive/MyDrive/FR/Master/M2_IASD/DeepLearning/project_DL'\n","/content\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ks7AjhAto2dV","executionInfo":{"status":"ok","timestamp":1673545057608,"user_tz":-60,"elapsed":253,"user":{"displayName":"Adrien","userId":"14922326483433512417"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6c02f836-81dc-4cd1-a798-fa35a78e88a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1W4NhmHf0UoKZyjlFKo0ESderX0ZLKDD1/project_DL\n"]}],"source":["%cd /content/drive/MyDrive/project_DL"]},{"cell_type":"code","source":["!apt-get install python3.7\n","!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 3\n","!sudo apt install python3-pip\n","!python -m pip install --upgrade pip\n","!pip install pybind11\n","!python3 -m pip install tensorflow\n","\n","\n","!sudo apt install python3.7-dev\n","!sh compile.sh "],"metadata":{"id":"DD6UgnHVYMLa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8f013b49-7c57-4860-dd82-c64b7af6923f","executionInfo":{"status":"ok","timestamp":1673545145783,"user_tz":-60,"elapsed":85858,"user":{"displayName":"Adrien","userId":"14922326483433512417"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  libpython3.7-minimal libpython3.7-stdlib python3.7-minimal\n","Suggested packages:\n","  python3.7-venv binfmt-support\n","The following NEW packages will be installed:\n","  libpython3.7-minimal libpython3.7-stdlib python3.7 python3.7-minimal\n","0 upgraded, 4 newly installed, 0 to remove and 21 not upgraded.\n","Need to get 4,448 kB of archives.\n","After this operation, 22.5 MB of additional disk space will be used.\n","Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7-minimal amd64 3.7.16-1+bionic1 [589 kB]\n","Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7-minimal amd64 3.7.16-1+bionic1 [1,725 kB]\n","Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7-stdlib amd64 3.7.16-1+bionic1 [1,773 kB]\n","Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7 amd64 3.7.16-1+bionic1 [360 kB]\n","Fetched 4,448 kB in 3s (1,350 kB/s)\n","Selecting previously unselected package libpython3.7-minimal:amd64.\n","(Reading database ... 124016 files and directories currently installed.)\n","Preparing to unpack .../libpython3.7-minimal_3.7.16-1+bionic1_amd64.deb ...\n","Unpacking libpython3.7-minimal:amd64 (3.7.16-1+bionic1) ...\n","Selecting previously unselected package python3.7-minimal.\n","Preparing to unpack .../python3.7-minimal_3.7.16-1+bionic1_amd64.deb ...\n","Unpacking python3.7-minimal (3.7.16-1+bionic1) ...\n","Selecting previously unselected package libpython3.7-stdlib:amd64.\n","Preparing to unpack .../libpython3.7-stdlib_3.7.16-1+bionic1_amd64.deb ...\n","Unpacking libpython3.7-stdlib:amd64 (3.7.16-1+bionic1) ...\n","Selecting previously unselected package python3.7.\n","Preparing to unpack .../python3.7_3.7.16-1+bionic1_amd64.deb ...\n","Unpacking python3.7 (3.7.16-1+bionic1) ...\n","Setting up libpython3.7-minimal:amd64 (3.7.16-1+bionic1) ...\n","Setting up python3.7-minimal (3.7.16-1+bionic1) ...\n","Setting up libpython3.7-stdlib:amd64 (3.7.16-1+bionic1) ...\n","Setting up python3.7 (3.7.16-1+bionic1) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","update-alternatives: using /usr/bin/python3.7 to provide /usr/bin/python3 (python3) in auto mode\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'sudo apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n","  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n","  python3-pkg-resources python3-secretstorage python3-setuptools python3-six\n","  python3-wheel python3-xdg\n","Suggested packages:\n","  python-crypto-doc python-cryptography-doc python3-cryptography-vectors\n","  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0\n","  python-secretstorage-doc python-setuptools-doc\n","The following NEW packages will be installed:\n","  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n","  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n","  python3-pip python3-pkg-resources python3-secretstorage python3-setuptools\n","  python3-six python3-wheel python3-xdg\n","0 upgraded, 15 newly installed, 0 to remove and 21 not upgraded.\n","Need to get 2,882 kB of archives.\n","After this operation, 8,886 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.5 [1,653 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-asn1crypto all 0.24.0-1 [72.8 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-cffi-backend amd64 1.11.5-1 [64.6 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-cryptography amd64 2.1.4-1ubuntu1.4 [220 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-secretstorage all 2.3.1-2 [12.1 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyring all 10.6.0-1 [26.7 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyrings.alt all 3.0-1 [16.6 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pip all 9.0.1-2.3~ubuntu1.18.04.5 [114 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wheel all 0.30.0-0.2 [36.5 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-xdg all 0.25-4ubuntu1.1 [31.3 kB]\n","Fetched 2,882 kB in 1s (1,970 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 15.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package python-pip-whl.\n","(Reading database ... 124632 files and directories currently installed.)\n","Preparing to unpack .../00-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n","Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n","Selecting previously unselected package python3-asn1crypto.\n","Preparing to unpack .../01-python3-asn1crypto_0.24.0-1_all.deb ...\n","Unpacking python3-asn1crypto (0.24.0-1) ...\n","Selecting previously unselected package python3-cffi-backend.\n","Preparing to unpack .../02-python3-cffi-backend_1.11.5-1_amd64.deb ...\n","Unpacking python3-cffi-backend (1.11.5-1) ...\n","Selecting previously unselected package python3-crypto.\n","Preparing to unpack .../03-python3-crypto_2.6.1-8ubuntu2_amd64.deb ...\n","Unpacking python3-crypto (2.6.1-8ubuntu2) ...\n","Selecting previously unselected package python3-idna.\n","Preparing to unpack .../04-python3-idna_2.6-1_all.deb ...\n","Unpacking python3-idna (2.6-1) ...\n","Selecting previously unselected package python3-six.\n","Preparing to unpack .../05-python3-six_1.11.0-2_all.deb ...\n","Unpacking python3-six (1.11.0-2) ...\n","Selecting previously unselected package python3-cryptography.\n","Preparing to unpack .../06-python3-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n","Unpacking python3-cryptography (2.1.4-1ubuntu1.4) ...\n","Selecting previously unselected package python3-secretstorage.\n","Preparing to unpack .../07-python3-secretstorage_2.3.1-2_all.deb ...\n","Unpacking python3-secretstorage (2.3.1-2) ...\n","Selecting previously unselected package python3-keyring.\n","Preparing to unpack .../08-python3-keyring_10.6.0-1_all.deb ...\n","Unpacking python3-keyring (10.6.0-1) ...\n","Selecting previously unselected package python3-keyrings.alt.\n","Preparing to unpack .../09-python3-keyrings.alt_3.0-1_all.deb ...\n","Unpacking python3-keyrings.alt (3.0-1) ...\n","Selecting previously unselected package python3-pip.\n","Preparing to unpack .../10-python3-pip_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n","Unpacking python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n","Selecting previously unselected package python3-pkg-resources.\n","Preparing to unpack .../11-python3-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python3-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python3-setuptools.\n","Preparing to unpack .../12-python3-setuptools_39.0.1-2_all.deb ...\n","Unpacking python3-setuptools (39.0.1-2) ...\n","Selecting previously unselected package python3-wheel.\n","Preparing to unpack .../13-python3-wheel_0.30.0-0.2_all.deb ...\n","Unpacking python3-wheel (0.30.0-0.2) ...\n","Selecting previously unselected package python3-xdg.\n","Preparing to unpack .../14-python3-xdg_0.25-4ubuntu1.1_all.deb ...\n","Unpacking python3-xdg (0.25-4ubuntu1.1) ...\n","Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n","Setting up python3-cffi-backend (1.11.5-1) ...\n","Setting up python3-crypto (2.6.1-8ubuntu2) ...\n","Setting up python3-idna (2.6-1) ...\n","Setting up python3-xdg (0.25-4ubuntu1.1) ...\n","Setting up python3-six (1.11.0-2) ...\n","Setting up python3-wheel (0.30.0-0.2) ...\n","Setting up python3-pkg-resources (39.0.1-2) ...\n","Setting up python3-asn1crypto (0.24.0-1) ...\n","Setting up python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n","Setting up python3-setuptools (39.0.1-2) ...\n","Setting up python3-cryptography (2.1.4-1ubuntu1.4) ...\n","Setting up python3-keyrings.alt (3.0-1) ...\n","Setting up python3-secretstorage (2.3.1-2) ...\n","Setting up python3-keyring (10.6.0-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Collecting pip\n","  Downloading https://files.pythonhosted.org/packages/09/bd/2410905c76ee14c62baf69e3f4aa780226c1bbfc9485731ad018e35b0cb5/pip-22.3.1-py3-none-any.whl (2.1MB)\n","\u001b[K    100% |████████████████████████████████| 2.1MB 582kB/s \n","\u001b[?25hInstalling collected packages: pip\n","  Found existing installation: pip 9.0.1\n","    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n","Successfully installed pip-22.3.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pybind11\n","  Downloading pybind11-2.10.3-py3-none-any.whl (222 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.4/222.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pybind11\n","Successfully installed pybind11-2.10.3\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow\n","  Downloading tensorflow-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n","  Downloading tensorflow_io_gcs_filesystem-0.29.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n","  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting flatbuffers>=2.0\n","  Downloading flatbuffers-23.1.4-py2.py3-none-any.whl (26 kB)\n","Collecting grpcio<2.0,>=1.24.3\n","  Downloading grpcio-1.51.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting absl-py>=1.0.0\n","  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.12,>=2.11\n","  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n","  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Collecting opt-einsum>=2.3.2\n","  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-pasta>=0.1.1\n","  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras<2.12,>=2.11.0\n","  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-extensions>=3.6.6\n","  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n","Collecting astunparse>=1.6.0\n","  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Collecting termcolor>=1.1.0\n","  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n","Collecting libclang>=13.0.0\n","  Downloading libclang-15.0.6.1-py2.py3-none-manylinux2010_x86_64.whl (21.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wrapt>=1.11.0\n","  Downloading wrapt-1.14.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.2/75.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h5py>=2.9.0\n","  Downloading h5py-3.7.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting six>=1.12.0\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting numpy>=1.20\n","  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting packaging\n","  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (39.0.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.30.0)\n","Collecting markdown>=2.6.8\n","  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Collecting google-auth<3,>=1.6.3\n","  Downloading google_auth-2.16.0-py2.py3-none-any.whl (177 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.8/177.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests<3,>=2.21.0\n","  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting setuptools\n","  Downloading setuptools-65.7.0-py3-none-any.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting werkzeug>=1.0.1\n","  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n","  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyasn1-modules>=0.2.1\n","  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n","  Downloading cachetools-5.2.1-py3-none-any.whl (9.3 kB)\n","Collecting rsa<5,>=3.1.4\n","  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n","Collecting requests-oauthlib>=0.7.0\n","  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n","Collecting importlib-metadata>=4.4\n","  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting charset-normalizer<4,>=2\n","  Downloading charset_normalizer-3.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (170 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.6)\n","Collecting certifi>=2017.4.17\n","  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting MarkupSafe>=2.1.1\n","  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n","Collecting zipp>=0.5\n","  Downloading zipp-3.11.0-py3-none-any.whl (6.6 kB)\n","Collecting pyasn1<0.5.0,>=0.4.6\n","  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting oauthlib>=3.0.0\n","  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, pyasn1, libclang, flatbuffers, charset-normalizer, zipp, wrapt, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, rsa, pyasn1-modules, protobuf, packaging, oauthlib, numpy, MarkupSafe, keras, grpcio, gast, certifi, cachetools, absl-py, werkzeug, requests, opt-einsum, importlib-metadata, h5py, google-pasta, google-auth, astunparse, requests-oauthlib, markdown, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: six\n","    Found existing installation: six 1.11.0\n","    Uninstalling six-1.11.0:\n","      Successfully uninstalled six-1.11.0\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 39.0.1\n","    Uninstalling setuptools-39.0.1:\n","      Successfully uninstalled setuptools-39.0.1\n","Successfully installed MarkupSafe-2.1.1 absl-py-1.4.0 astunparse-1.6.3 cachetools-5.2.1 certifi-2022.12.7 charset-normalizer-3.0.1 flatbuffers-23.1.4 gast-0.4.0 google-auth-2.16.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.1 h5py-3.7.0 importlib-metadata-6.0.0 keras-2.11.0 libclang-15.0.6.1 markdown-3.4.1 numpy-1.21.6 oauthlib-3.2.2 opt-einsum-3.3.0 packaging-23.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.28.2 requests-oauthlib-1.3.1 rsa-4.9 setuptools-65.7.0 six-1.16.0 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.29.0 termcolor-2.2.0 typing-extensions-4.4.0 urllib3-1.26.14 werkzeug-2.2.2 wrapt-1.14.1 zipp-3.11.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'sudo apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  libpython3.7 libpython3.7-dev\n","The following NEW packages will be installed:\n","  libpython3.7 libpython3.7-dev python3.7-dev\n","0 upgraded, 3 newly installed, 0 to remove and 21 not upgraded.\n","Need to get 44.9 MB of archives.\n","After this operation, 67.2 MB of additional disk space will be used.\n","Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7 amd64 3.7.16-1+bionic1 [1,527 kB]\n","Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7-dev amd64 3.7.16-1+bionic1 [42.9 MB]\n","Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7-dev amd64 3.7.16-1+bionic1 [501 kB]\n","Fetched 44.9 MB in 5s (9,718 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libpython3.7:amd64.\n","(Reading database ... 125312 files and directories currently installed.)\n","Preparing to unpack .../libpython3.7_3.7.16-1+bionic1_amd64.deb ...\n","Unpacking libpython3.7:amd64 (3.7.16-1+bionic1) ...\n","Selecting previously unselected package libpython3.7-dev:amd64.\n","Preparing to unpack .../libpython3.7-dev_3.7.16-1+bionic1_amd64.deb ...\n","Unpacking libpython3.7-dev:amd64 (3.7.16-1+bionic1) ...\n","Selecting previously unselected package python3.7-dev.\n","Preparing to unpack .../python3.7-dev_3.7.16-1+bionic1_amd64.deb ...\n","Unpacking python3.7-dev (3.7.16-1+bionic1) ...\n","Setting up libpython3.7:amd64 (3.7.16-1+bionic1) ...\n","Setting up libpython3.7-dev:amd64 (3.7.16-1+bionic1) ...\n","Setting up python3.7-dev (3.7.16-1+bionic1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","In file included from \u001b[01m\u001b[Kgolois.cpp:17:0\u001b[m\u001b[K:\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kbool Board::isCapturedLadder(int, int, Rzone*)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:1767:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn1\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","    int \u001b[01;35m\u001b[Kn1\u001b[m\u001b[K = nbLiberties (inter, liberties1, stones1, 3);\n","        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:1788:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn1\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","        int \u001b[01;35m\u001b[Kn1\u001b[m\u001b[K = nbLiberties (inter, liberties1, stones1, 3);\n","            \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid Board::computeLadders(int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:1819:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kother\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kother\u001b[m\u001b[K = opponent (color);\n","         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid Board::computeAllLadders(int, bool)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:2065:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn1\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kn1\u001b[m\u001b[K = nbLiberties (i, liberties1, stones1);\n","         \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:2101:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn1\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","   int \u001b[01;35m\u001b[Kn1\u001b[m\u001b[K = nbLiberties (i, liberties1, stones1);\n","       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:2134:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn1\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kn1\u001b[m\u001b[K = nbLiberties (i, liberties1, stones1);\n","         \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:2171:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn1\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","   int \u001b[01;35m\u001b[Kn1\u001b[m\u001b[K = nbLiberties (i, liberties1, stones1);\n","       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid Board::computeIsInLadder()\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:2242:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn1\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","   int \u001b[01;35m\u001b[Kn1\u001b[m\u001b[K = nbLiberties (s, liberties1, stones1);\n","       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid Board::computeLostLadders()\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:2275:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn1\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","   int \u001b[01;35m\u001b[Kn1\u001b[m\u001b[K = nbLiberties (s, liberties1, stones1);\n","       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid Board::printLadders(FILE*, int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:2287:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kother\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kother\u001b[m\u001b[K = opponent (color);\n","         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kbool Board::sameString(int, int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:2336:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kn\u001b[m\u001b[K = nbLiberties (inter, liberties, stones);\n","         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kbool Board::atariLent(int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:2655:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ksuggest explicit braces to avoid ambiguous ‘\u001b[01m\u001b[Kelse\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wdangling-else\u001b[m\u001b[K]\n","       if \u001b[01;35m\u001b[K(\u001b[m\u001b[Kboard [pierre - 1] == Empty)\n","          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:2658:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ksuggest explicit braces to avoid ambiguous ‘\u001b[01m\u001b[Kelse\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wdangling-else\u001b[m\u001b[K]\n","       if \u001b[01;35m\u001b[K(\u001b[m\u001b[Kboard [pierre + 1] == Empty)\n","          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:2661:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ksuggest explicit braces to avoid ambiguous ‘\u001b[01m\u001b[Kelse\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wdangling-else\u001b[m\u001b[K]\n","       if \u001b[01;35m\u001b[K(\u001b[m\u001b[Kboard [pierre - dxBoard] == Empty)\n","          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:2664:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ksuggest explicit braces to avoid ambiguous ‘\u001b[01m\u001b[Kelse\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wdangling-else\u001b[m\u001b[K]\n","       if \u001b[01;35m\u001b[K(\u001b[m\u001b[Kboard [pierre + dxBoard] == Empty)\n","          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kint Board::playAtariIfCapture(int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:3043:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kother\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kother\u001b[m\u001b[K = opponent (couleur);\n","         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kint Board::captureAdjacentAtari(int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:3099:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kother\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kother\u001b[m\u001b[K = opponent (couleur);\n","         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kint Board::captureAtari(int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:3135:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kother\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kother\u001b[m\u001b[K = opponent (couleur);\n","         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kint Board::avoidCaptureAtari(int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:3158:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kother\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kother\u001b[m\u001b[K = opponent (couleur);\n","         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kint Board::playout(int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:3294:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Km\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n","  Move \u001b[01;35m\u001b[Km\u001b[m\u001b[K;\n","       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:3315:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ks\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","    char \u001b[01;35m\u001b[Ks\u001b[m\u001b[K [256];\n","         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kint Board::loadSGF(FILE*)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:3783:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kres\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","    int \u001b[01;35m\u001b[Kres\u001b[m\u001b[K = sscanf (InsideBracket, \"%d\", &sz);\n","        \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:3790:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ki\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","    int \u001b[01;35m\u001b[Ki\u001b[m\u001b[K = 0;\n","        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[Kgolois.cpp:18:0\u001b[m\u001b[K:\n","\u001b[01m\u001b[KGame.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid loadGamesData(char*)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KGame.h:219:129:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint*\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Kshort int*\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","         fscanf (fp, \"%d %d %f %f\", \u001b[32m\u001b[K&proGame [g] [i].inter\u001b[m\u001b[K, &proGame [g] [i].color, &proGame [g] [i].val, &proGame [g] [i].points\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                                    \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:219:129:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint*\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Kchar*\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[KGame.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid loadGamesDataVal(char*)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KGame.h:301:95:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint*\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Kshort int*\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","  fscanf (fp, \"%d %f %d \", \u001b[32m\u001b[K&proGame [g] [i].inter\u001b[m\u001b[K, &proGame [g] [i].val, &proGame [g] [i].color\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                           \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:301:95:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint*\u001b[m\u001b[K’, but argument 5 has type ‘\u001b[01m\u001b[Kchar*\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kgolois.cpp:70:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","  fprintf (stderr, \"r.shape = (%d, %d, %d, %d)\\n\", \u001b[32m\u001b[Kr.shape (0)\u001b[m\u001b[K, r.shape (1), r.shape (2), r.shape (3)\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                                                   \u001b[32m\u001b[K~~~~~~~~~~~\u001b[m\u001b[K                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[Kgolois.cpp:70:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:70:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 5 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:70:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 6 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:76:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kgame\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","    int \u001b[01;35m\u001b[Kgame\u001b[m\u001b[K = positionSGF [pos].game;\n","        \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kgolois.cpp:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kgolois.cpp:168:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","  fprintf (stderr, \"r.shape = (%d, %d, %d, %d)\\n\", \u001b[32m\u001b[Kr.shape (0)\u001b[m\u001b[K, r.shape (1), r.shape (2), r.shape (3)\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                                                   \u001b[32m\u001b[K~~~~~~~~~~~\u001b[m\u001b[K                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[Kgolois.cpp:168:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:168:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 5 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:168:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 6 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:177:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KISO C++ forbids converting a string constant to ‘\u001b[01m\u001b[Kchar*\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wwrite-strings\u001b[m\u001b[K]\n","    loadGamesData (\"games.data\"\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[Kgolois.cpp:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kgolois.cpp:314:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KISO C++ forbids converting a string constant to ‘\u001b[01m\u001b[Kchar*\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wwrite-strings\u001b[m\u001b[K]\n","    loadGamesDataVal (\"games.val.data\"\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[Kgolois.cpp:322:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","  fprintf (stderr, \"r.shape = (%d, %d, %d, %d)\\n\", \u001b[32m\u001b[Kr.shape (0)\u001b[m\u001b[K, r.shape (1), r.shape (2), r.shape (3)\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                                                   \u001b[32m\u001b[K~~~~~~~~~~~\u001b[m\u001b[K                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[Kgolois.cpp:322:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:322:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 5 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:322:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 6 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","In file included from \u001b[01m\u001b[Kgolois.cpp:18:0\u001b[m\u001b[K:\n","\u001b[01m\u001b[KGame.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid loadGamesData(char*)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KGame.h:206:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","     \u001b[01;35m\u001b[Kfscanf (fp, \"%d\", &nbGames)\u001b[m\u001b[K;\n","     \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:208:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kfscanf (fp, \"%f\", &komi [g])\u001b[m\u001b[K;\n","       \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:209:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kfscanf (fp, \"%s \", s)\u001b[m\u001b[K;\n","       \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:212:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kfscanf (fp, \"%d\", &nbMovesSGFGame [g])\u001b[m\u001b[K;\n","       \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:219:16:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","         \u001b[01;35m\u001b[Kfscanf (fp, \"%d %d %f %f\", &proGame [g] [i].inter, &proGame [g] [i].color, &proGame [g] [i].val, &proGame [g] [i].points)\u001b[m\u001b[K;\n","         \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid loadGamesDataVal(char*)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KGame.h:294:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","     \u001b[01;35m\u001b[Kfscanf (fp, \"%d\", &nbGames)\u001b[m\u001b[K;\n","     \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:296:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kfscanf (fp, \"%s \", s)\u001b[m\u001b[K;\n","       \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:298:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kfscanf (fp, \"%d\", &nbMovesSGFGame [g])\u001b[m\u001b[K;\n","       \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:301:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","  \u001b[01;35m\u001b[Kfscanf (fp, \"%d %f %d \", &proGame [g] [i].inter, &proGame [g] [i].val, &proGame [g] [i].color)\u001b[m\u001b[K;\n","  \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kgolois.cpp:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kgolois.cpp:213:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","      \u001b[01;35m\u001b[Kfscanf (fp, \"%d\", &nbExamples)\u001b[m\u001b[K;\n","      \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kgolois.cpp:215:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","        \u001b[01;35m\u001b[Kfscanf (fp, \"%d\", &indexValidation [i])\u001b[m\u001b[K;\n","        \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n"]}]},{"cell_type":"code","source":["!wget https://www.lamsade.dauphine.fr/~cazenave/project2022.zip\n","!unzip project2022.zip"],"metadata":{"id":"LFk2vr8LC488","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673545269586,"user_tz":-60,"elapsed":17618,"user":{"displayName":"Adrien","userId":"14922326483433512417"}},"outputId":"ffdcdc79-1d53-4cb4-c7ea-45d84dd2ffaf"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-01-12 17:40:51--  https://www.lamsade.dauphine.fr/~cazenave/project2022.zip\n","Resolving www.lamsade.dauphine.fr (www.lamsade.dauphine.fr)... 193.48.71.250\n","Connecting to www.lamsade.dauphine.fr (www.lamsade.dauphine.fr)|193.48.71.250|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 138784129 (132M) [application/zip]\n","Saving to: ‘project2022.zip.5’\n","\n","project2022.zip.5   100%[===================>] 132.35M  25.0MB/s    in 6.4s    \n","\n","2023-01-12 17:40:58 (20.6 MB/s) - ‘project2022.zip.5’ saved [138784129/138784129]\n","\n","Archive:  project2022.zip\n","replace Board.h? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","  inflating: Board.h                 \n","  inflating: Game.h                  \n","  inflating: Rzone.h                 \n","  inflating: compile.sh              \n","  inflating: compileMAC.sh           \n","  inflating: games.data              \n","  inflating: golois.cpp              \n","  inflating: golois.cpython-310-x86_64-linux-gnu.so  \n","  inflating: golois.cpython-37m-x86_64-linux-gnu.so  \n","  inflating: golois.cpython-38-x86_64-linux-gnu.so  \n","  inflating: golois.py               \n","  inflating: importGolois.ipynb      \n","  inflating: zip.sh                  \n"]}]},{"cell_type":"code","source":["#test mobilenetv2 for go game\n","!python mobilenetV2.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yFCdfAdbDznN","executionInfo":{"status":"ok","timestamp":1673560694523,"user_tz":-60,"elapsed":9,"user":{"displayName":"Adrien","userId":"14922326483433512417"}},"outputId":"6a42a6fd-c155-43bc-962d-4001a27935ef"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["python3: can't open file 'mobilenetV2.py': [Errno 2] No such file or directory\n"]}]},{"cell_type":"code","source":["#test mobile net v2 for go game\n","!python mobilenet_v2.py"],"metadata":{"id":"8IDYmKCKMNpW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673382355253,"user_tz":-60,"elapsed":176833,"user":{"displayName":"Adrien","userId":"14922326483433512417"}},"outputId":"fa1dcbd3-fd8e-43ab-8294-616d116398ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-10 20:22:58.194901: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-10 20:22:59.372866: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-01-10 20:22:59.373003: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-01-10 20:22:59.373027: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","4\n","(10000, 19, 19, 31)\n","getValidation\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","tcmalloc: large alloc 2400002048 bytes == 0x56fc2000 @  0x7fd6baebf887 0x7fd6680ba0d9 0x7fd6680bf85f 0x7fd6680d406f 0x58e314 0x514581 0x5a5fb6 0x607433 0x601066 0x60112c 0x6015f6 0x64faa2 0x64fc4e 0x7fd6baabac87 0x5b64ca\n","nbPositionsSGF = 29425326\n","nbPositionsSGF = 29425326\n","loading validation.data\n","2023-01-10 20:23:28.594145: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:23:28.600096: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:23:28.600823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:23:28.601872: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-10 20:23:28.602170: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:23:28.602856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:23:28.603509: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:23:29.185839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:23:29.186597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:23:29.187237: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:23:29.187862: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-01-10 20:23:29.187930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13779 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," board (InputLayer)             [(None, 19, 19, 31)  0           []                               \n","                                ]                                                                 \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 19, 19, 64)   2048        ['board[0][0]']                  \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 19, 19, 64)  256         ['conv2d[0][0]']                 \n"," alization)                                                                                       \n","                                                                                                  \n"," re_lu (ReLU)                   (None, 19, 19, 64)   0           ['batch_normalization[0][0]']    \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 19, 19, 198)  12672       ['re_lu[0][0]']                  \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 19, 19, 198)  792        ['conv2d_1[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation (Activation)        (None, 19, 19, 198)  0           ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," depthwise_conv2d (DepthwiseCon  (None, 19, 19, 198)  1782       ['activation[0][0]']             \n"," v2D)                                                                                             \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 19, 19, 198)  792        ['depthwise_conv2d[0][0]']       \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_1 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_2[0][0]']  \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 19, 19, 64)   12672       ['activation_1[0][0]']           \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 19, 19, 64)  256         ['conv2d_2[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add (Add)                      (None, 19, 19, 64)   0           ['batch_normalization_3[0][0]',  \n","                                                                  're_lu[0][0]']                  \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 19, 19, 198)  12672       ['add[0][0]']                    \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 19, 19, 198)  792        ['conv2d_3[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_2 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_4[0][0]']  \n","                                                                                                  \n"," depthwise_conv2d_1 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_2[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 19, 19, 198)  792        ['depthwise_conv2d_1[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_3 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 19, 19, 64)   12672       ['activation_3[0][0]']           \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 19, 19, 64)  256         ['conv2d_4[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add_1 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_6[0][0]',  \n","                                                                  'add[0][0]']                    \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 19, 19, 198)  12672       ['add_1[0][0]']                  \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 19, 19, 198)  792        ['conv2d_5[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_4 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_7[0][0]']  \n","                                                                                                  \n"," depthwise_conv2d_2 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_4[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 19, 19, 198)  792        ['depthwise_conv2d_2[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_5 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_8[0][0]']  \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 19, 19, 64)   12672       ['activation_5[0][0]']           \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 19, 19, 64)  256         ['conv2d_6[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add_2 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_9[0][0]',  \n","                                                                  'add_1[0][0]']                  \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 19, 19, 198)  12672       ['add_2[0][0]']                  \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 19, 19, 198)  792        ['conv2d_7[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_6 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_10[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_6[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_11 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_3[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_7 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_11[0][0]'] \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 19, 19, 64)   12672       ['activation_7[0][0]']           \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 19, 19, 64)  256         ['conv2d_8[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_3 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_12[0][0]', \n","                                                                  'add_2[0][0]']                  \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 19, 19, 198)  12672       ['add_3[0][0]']                  \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 19, 19, 198)  792        ['conv2d_9[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_8 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_13[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_8[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_4[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_9 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_14[0][0]'] \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_9[0][0]']           \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 19, 19, 64)  256         ['conv2d_10[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_4 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_15[0][0]', \n","                                                                  'add_3[0][0]']                  \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 19, 19, 198)  12672       ['add_4[0][0]']                  \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 19, 19, 198)  792        ['conv2d_11[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_10 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_16[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_5 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_10[0][0]']          \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_5[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_11 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_17[0][0]'] \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_11[0][0]']          \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 19, 19, 64)  256         ['conv2d_12[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_5 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_18[0][0]', \n","                                                                  'add_4[0][0]']                  \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 19, 19, 198)  12672       ['add_5[0][0]']                  \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 19, 19, 198)  792        ['conv2d_13[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_12 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_19[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_6 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_12[0][0]']          \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_6[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_13 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_20[0][0]'] \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_13[0][0]']          \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 19, 19, 64)  256         ['conv2d_14[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_6 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_21[0][0]', \n","                                                                  'add_5[0][0]']                  \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 19, 19, 198)  12672       ['add_6[0][0]']                  \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 19, 19, 198)  792        ['conv2d_15[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_14 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_22[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_7 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_14[0][0]']          \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_7[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_15 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_23[0][0]'] \n","                                                                                                  \n"," conv2d_16 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_15[0][0]']          \n","                                                                                                  \n"," batch_normalization_24 (BatchN  (None, 19, 19, 64)  256         ['conv2d_16[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_7 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_24[0][0]', \n","                                                                  'add_6[0][0]']                  \n","                                                                                                  \n"," conv2d_17 (Conv2D)             (None, 19, 19, 198)  12672       ['add_7[0][0]']                  \n","                                                                                                  \n"," batch_normalization_25 (BatchN  (None, 19, 19, 198)  792        ['conv2d_17[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_16 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_25[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_8 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_16[0][0]']          \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_26 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_8[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_17 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_26[0][0]'] \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_17[0][0]']          \n","                                                                                                  \n"," batch_normalization_27 (BatchN  (None, 19, 19, 64)  256         ['conv2d_18[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_8 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_27[0][0]', \n","                                                                  'add_7[0][0]']                  \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 19, 19, 198)  12672       ['add_8[0][0]']                  \n","                                                                                                  \n"," batch_normalization_28 (BatchN  (None, 19, 19, 198)  792        ['conv2d_19[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_18 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_28[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_9 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_18[0][0]']          \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_29 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_9[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_19 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_29[0][0]'] \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_19[0][0]']          \n","                                                                                                  \n"," batch_normalization_30 (BatchN  (None, 19, 19, 64)  256         ['conv2d_20[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_9 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_30[0][0]', \n","                                                                  'add_8[0][0]']                  \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 19, 19, 198)  12672       ['add_9[0][0]']                  \n","                                                                                                  \n"," batch_normalization_31 (BatchN  (None, 19, 19, 198)  792        ['conv2d_21[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_20 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_31[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_10 (Depthwise  (None, 19, 19, 198)  1782       ['activation_20[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_32 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_10[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_21 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_32[0][0]'] \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_21[0][0]']          \n","                                                                                                  \n"," batch_normalization_33 (BatchN  (None, 19, 19, 64)  256         ['conv2d_22[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_10 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_33[0][0]', \n","                                                                  'add_9[0][0]']                  \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 19, 19, 198)  12672       ['add_10[0][0]']                 \n","                                                                                                  \n"," batch_normalization_34 (BatchN  (None, 19, 19, 198)  792        ['conv2d_23[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_22 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_34[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_11 (Depthwise  (None, 19, 19, 198)  1782       ['activation_22[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_35 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_11[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_23 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_35[0][0]'] \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_23[0][0]']          \n","                                                                                                  \n"," batch_normalization_36 (BatchN  (None, 19, 19, 64)  256         ['conv2d_24[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_11 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_36[0][0]', \n","                                                                  'add_10[0][0]']                 \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 19, 19, 198)  12672       ['add_11[0][0]']                 \n","                                                                                                  \n"," batch_normalization_37 (BatchN  (None, 19, 19, 198)  792        ['conv2d_25[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_24 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_37[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_12 (Depthwise  (None, 19, 19, 198)  1782       ['activation_24[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_38 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_12[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_25 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_38[0][0]'] \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_25[0][0]']          \n","                                                                                                  \n"," batch_normalization_39 (BatchN  (None, 19, 19, 64)  256         ['conv2d_26[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_12 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_39[0][0]', \n","                                                                  'add_11[0][0]']                 \n","                                                                                                  \n"," conv2d_27 (Conv2D)             (None, 19, 19, 198)  12672       ['add_12[0][0]']                 \n","                                                                                                  \n"," batch_normalization_40 (BatchN  (None, 19, 19, 198)  792        ['conv2d_27[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_26 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_40[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_13 (Depthwise  (None, 19, 19, 198)  1782       ['activation_26[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_41 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_13[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_27 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_41[0][0]'] \n","                                                                                                  \n"," conv2d_28 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_27[0][0]']          \n","                                                                                                  \n"," batch_normalization_42 (BatchN  (None, 19, 19, 64)  256         ['conv2d_28[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_13 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_42[0][0]', \n","                                                                  'add_12[0][0]']                 \n","                                                                                                  \n"," conv2d_29 (Conv2D)             (None, 19, 19, 198)  12672       ['add_13[0][0]']                 \n","                                                                                                  \n"," batch_normalization_43 (BatchN  (None, 19, 19, 198)  792        ['conv2d_29[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_28 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_43[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_14 (Depthwise  (None, 19, 19, 198)  1782       ['activation_28[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_44 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_14[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_29 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_44[0][0]'] \n","                                                                                                  \n"," conv2d_30 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_29[0][0]']          \n","                                                                                                  \n"," batch_normalization_45 (BatchN  (None, 19, 19, 64)  256         ['conv2d_30[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_14 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_45[0][0]', \n","                                                                  'add_13[0][0]']                 \n","                                                                                                  \n"," conv2d_31 (Conv2D)             (None, 19, 19, 198)  12672       ['add_14[0][0]']                 \n","                                                                                                  \n"," batch_normalization_46 (BatchN  (None, 19, 19, 198)  792        ['conv2d_31[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_30 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_46[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_15 (Depthwise  (None, 19, 19, 198)  1782       ['activation_30[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_47 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_15[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_31 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_47[0][0]'] \n","                                                                                                  \n"," conv2d_32 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_31[0][0]']          \n","                                                                                                  \n"," batch_normalization_48 (BatchN  (None, 19, 19, 64)  256         ['conv2d_32[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_15 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_48[0][0]', \n","                                                                  'add_14[0][0]']                 \n","                                                                                                  \n"," conv2d_33 (Conv2D)             (None, 19, 19, 198)  12672       ['add_15[0][0]']                 \n","                                                                                                  \n"," batch_normalization_49 (BatchN  (None, 19, 19, 198)  792        ['conv2d_33[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_32 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_49[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_16 (Depthwise  (None, 19, 19, 198)  1782       ['activation_32[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_50 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_16[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_33 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_50[0][0]'] \n","                                                                                                  \n"," conv2d_34 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_33[0][0]']          \n","                                                                                                  \n"," batch_normalization_51 (BatchN  (None, 19, 19, 64)  256         ['conv2d_34[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_16 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_51[0][0]', \n","                                                                  'add_15[0][0]']                 \n","                                                                                                  \n"," conv2d_35 (Conv2D)             (None, 19, 19, 198)  12672       ['add_16[0][0]']                 \n","                                                                                                  \n"," batch_normalization_52 (BatchN  (None, 19, 19, 198)  792        ['conv2d_35[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_34 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_52[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_17 (Depthwise  (None, 19, 19, 198)  1782       ['activation_34[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_53 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_17[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_35 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_53[0][0]'] \n","                                                                                                  \n"," conv2d_36 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_35[0][0]']          \n","                                                                                                  \n"," batch_normalization_54 (BatchN  (None, 19, 19, 64)  256         ['conv2d_36[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_17 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_54[0][0]', \n","                                                                  'add_16[0][0]']                 \n","                                                                                                  \n"," conv2d_37 (Conv2D)             (None, 19, 19, 198)  12672       ['add_17[0][0]']                 \n","                                                                                                  \n"," batch_normalization_55 (BatchN  (None, 19, 19, 198)  792        ['conv2d_37[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_36 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_55[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_18 (Depthwise  (None, 19, 19, 198)  1782       ['activation_36[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_56 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_18[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_37 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_56[0][0]'] \n","                                                                                                  \n"," conv2d_38 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_37[0][0]']          \n","                                                                                                  \n"," batch_normalization_57 (BatchN  (None, 19, 19, 64)  256         ['conv2d_38[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_18 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_57[0][0]', \n","                                                                  'add_17[0][0]']                 \n","                                                                                                  \n"," conv2d_39 (Conv2D)             (None, 19, 19, 198)  12672       ['add_18[0][0]']                 \n","                                                                                                  \n"," batch_normalization_58 (BatchN  (None, 19, 19, 198)  792        ['conv2d_39[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_38 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_58[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_19 (Depthwise  (None, 19, 19, 198)  1782       ['activation_38[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_59 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_19[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_39 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_59[0][0]'] \n","                                                                                                  \n"," conv2d_40 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_39[0][0]']          \n","                                                                                                  \n"," batch_normalization_60 (BatchN  (None, 19, 19, 64)  256         ['conv2d_40[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_19 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_60[0][0]', \n","                                                                  'add_18[0][0]']                 \n","                                                                                                  \n"," conv2d_41 (Conv2D)             (None, 19, 19, 198)  12672       ['add_19[0][0]']                 \n","                                                                                                  \n"," batch_normalization_61 (BatchN  (None, 19, 19, 198)  792        ['conv2d_41[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_40 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_61[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_20 (Depthwise  (None, 19, 19, 198)  1782       ['activation_40[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_62 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_20[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_41 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_62[0][0]'] \n","                                                                                                  \n"," conv2d_42 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_41[0][0]']          \n","                                                                                                  \n"," batch_normalization_63 (BatchN  (None, 19, 19, 64)  256         ['conv2d_42[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_20 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_63[0][0]', \n","                                                                  'add_19[0][0]']                 \n","                                                                                                  \n"," conv2d_43 (Conv2D)             (None, 19, 19, 198)  12672       ['add_20[0][0]']                 \n","                                                                                                  \n"," batch_normalization_64 (BatchN  (None, 19, 19, 198)  792        ['conv2d_43[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_42 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_64[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_21 (Depthwise  (None, 19, 19, 198)  1782       ['activation_42[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_65 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_21[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_43 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_65[0][0]'] \n","                                                                                                  \n"," conv2d_44 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_43[0][0]']          \n","                                                                                                  \n"," batch_normalization_66 (BatchN  (None, 19, 19, 64)  256         ['conv2d_44[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_21 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_66[0][0]', \n","                                                                  'add_20[0][0]']                 \n","                                                                                                  \n"," conv2d_45 (Conv2D)             (None, 19, 19, 198)  12672       ['add_21[0][0]']                 \n","                                                                                                  \n"," batch_normalization_67 (BatchN  (None, 19, 19, 198)  792        ['conv2d_45[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_44 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_67[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_22 (Depthwise  (None, 19, 19, 198)  1782       ['activation_44[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_68 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_22[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_45 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_68[0][0]'] \n","                                                                                                  \n"," conv2d_46 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_45[0][0]']          \n","                                                                                                  \n"," batch_normalization_69 (BatchN  (None, 19, 19, 64)  256         ['conv2d_46[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_22 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_69[0][0]', \n","                                                                  'add_21[0][0]']                 \n","                                                                                                  \n"," conv2d_47 (Conv2D)             (None, 19, 19, 198)  12672       ['add_22[0][0]']                 \n","                                                                                                  \n"," batch_normalization_70 (BatchN  (None, 19, 19, 198)  792        ['conv2d_47[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_46 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_70[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_23 (Depthwise  (None, 19, 19, 198)  1782       ['activation_46[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_71 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_23[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_47 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_71[0][0]'] \n","                                                                                                  \n"," conv2d_48 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_47[0][0]']          \n","                                                                                                  \n"," batch_normalization_72 (BatchN  (None, 19, 19, 64)  256         ['conv2d_48[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_23 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_72[0][0]', \n","                                                                  'add_22[0][0]']                 \n","                                                                                                  \n"," conv2d_49 (Conv2D)             (None, 19, 19, 198)  12672       ['add_23[0][0]']                 \n","                                                                                                  \n"," batch_normalization_73 (BatchN  (None, 19, 19, 198)  792        ['conv2d_49[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_48 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_73[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_24 (Depthwise  (None, 19, 19, 198)  1782       ['activation_48[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_74 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_24[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_49 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_74[0][0]'] \n","                                                                                                  \n"," conv2d_50 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_49[0][0]']          \n","                                                                                                  \n"," batch_normalization_75 (BatchN  (None, 19, 19, 64)  256         ['conv2d_50[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_24 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_75[0][0]', \n","                                                                  'add_23[0][0]']                 \n","                                                                                                  \n"," conv2d_51 (Conv2D)             (None, 19, 19, 198)  12672       ['add_24[0][0]']                 \n","                                                                                                  \n"," batch_normalization_76 (BatchN  (None, 19, 19, 198)  792        ['conv2d_51[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_50 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_76[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_25 (Depthwise  (None, 19, 19, 198)  1782       ['activation_50[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_77 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_25[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_51 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_77[0][0]'] \n","                                                                                                  \n"," conv2d_52 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_51[0][0]']          \n","                                                                                                  \n"," batch_normalization_78 (BatchN  (None, 19, 19, 64)  256         ['conv2d_52[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_25 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_78[0][0]', \n","                                                                  'add_24[0][0]']                 \n","                                                                                                  \n"," conv2d_53 (Conv2D)             (None, 19, 19, 198)  12672       ['add_25[0][0]']                 \n","                                                                                                  \n"," batch_normalization_79 (BatchN  (None, 19, 19, 198)  792        ['conv2d_53[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_52 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_79[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_26 (Depthwise  (None, 19, 19, 198)  1782       ['activation_52[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_80 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_26[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_53 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_80[0][0]'] \n","                                                                                                  \n"," conv2d_54 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_53[0][0]']          \n","                                                                                                  \n"," batch_normalization_81 (BatchN  (None, 19, 19, 64)  256         ['conv2d_54[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_26 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_81[0][0]', \n","                                                                  'add_25[0][0]']                 \n","                                                                                                  \n"," conv2d_55 (Conv2D)             (None, 19, 19, 198)  12672       ['add_26[0][0]']                 \n","                                                                                                  \n"," batch_normalization_82 (BatchN  (None, 19, 19, 198)  792        ['conv2d_55[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_54 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_82[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_27 (Depthwise  (None, 19, 19, 198)  1782       ['activation_54[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_83 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_27[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_55 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_83[0][0]'] \n","                                                                                                  \n"," conv2d_56 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_55[0][0]']          \n","                                                                                                  \n"," batch_normalization_84 (BatchN  (None, 19, 19, 64)  256         ['conv2d_56[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_27 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_84[0][0]', \n","                                                                  'add_26[0][0]']                 \n","                                                                                                  \n"," conv2d_57 (Conv2D)             (None, 19, 19, 198)  12672       ['add_27[0][0]']                 \n","                                                                                                  \n"," batch_normalization_85 (BatchN  (None, 19, 19, 198)  792        ['conv2d_57[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_56 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_85[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_28 (Depthwise  (None, 19, 19, 198)  1782       ['activation_56[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_86 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_28[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_57 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_86[0][0]'] \n","                                                                                                  \n"," conv2d_58 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_57[0][0]']          \n","                                                                                                  \n"," batch_normalization_87 (BatchN  (None, 19, 19, 64)  256         ['conv2d_58[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_28 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_87[0][0]', \n","                                                                  'add_27[0][0]']                 \n","                                                                                                  \n"," conv2d_59 (Conv2D)             (None, 19, 19, 198)  12672       ['add_28[0][0]']                 \n","                                                                                                  \n"," batch_normalization_88 (BatchN  (None, 19, 19, 198)  792        ['conv2d_59[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_58 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_88[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_29 (Depthwise  (None, 19, 19, 198)  1782       ['activation_58[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_89 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_29[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_59 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_89[0][0]'] \n","                                                                                                  \n"," conv2d_60 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_59[0][0]']          \n","                                                                                                  \n"," batch_normalization_90 (BatchN  (None, 19, 19, 64)  256         ['conv2d_60[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_29 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_90[0][0]', \n","                                                                  'add_28[0][0]']                 \n","                                                                                                  \n"," conv2d_61 (Conv2D)             (None, 19, 19, 198)  12672       ['add_29[0][0]']                 \n","                                                                                                  \n"," batch_normalization_91 (BatchN  (None, 19, 19, 198)  792        ['conv2d_61[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_60 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_91[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_30 (Depthwise  (None, 19, 19, 198)  1782       ['activation_60[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_92 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_30[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_61 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_92[0][0]'] \n","                                                                                                  \n"," conv2d_62 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_61[0][0]']          \n","                                                                                                  \n"," batch_normalization_93 (BatchN  (None, 19, 19, 64)  256         ['conv2d_62[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_30 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_93[0][0]', \n","                                                                  'add_29[0][0]']                 \n","                                                                                                  \n"," conv2d_63 (Conv2D)             (None, 19, 19, 198)  12672       ['add_30[0][0]']                 \n","                                                                                                  \n"," batch_normalization_94 (BatchN  (None, 19, 19, 198)  792        ['conv2d_63[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_62 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_94[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_31 (Depthwise  (None, 19, 19, 198)  1782       ['activation_62[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_95 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_31[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_63 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_95[0][0]'] \n","                                                                                                  \n"," conv2d_64 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_63[0][0]']          \n","                                                                                                  \n"," batch_normalization_96 (BatchN  (None, 19, 19, 64)  256         ['conv2d_64[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_31 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_96[0][0]', \n","                                                                  'add_30[0][0]']                 \n","                                                                                                  \n"," conv2d_65 (Conv2D)             (None, 19, 19, 198)  12672       ['add_31[0][0]']                 \n","                                                                                                  \n"," batch_normalization_97 (BatchN  (None, 19, 19, 198)  792        ['conv2d_65[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_64 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_97[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_32 (Depthwise  (None, 19, 19, 198)  1782       ['activation_64[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_98 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_32[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_65 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_98[0][0]'] \n","                                                                                                  \n"," conv2d_66 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_65[0][0]']          \n","                                                                                                  \n"," batch_normalization_99 (BatchN  (None, 19, 19, 64)  256         ['conv2d_66[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_32 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_99[0][0]', \n","                                                                  'add_31[0][0]']                 \n","                                                                                                  \n"," conv2d_67 (Conv2D)             (None, 19, 19, 1)    64          ['add_32[0][0]']                 \n","                                                                                                  \n"," global_average_pooling2d (Glob  (None, 64)          0           ['add_32[0][0]']                 \n"," alAveragePooling2D)                                                                              \n","                                                                                                  \n"," flatten (Flatten)              (None, 361)          0           ['conv2d_67[0][0]']              \n","                                                                                                  \n"," dense (Dense)                  (None, 50)           3250        ['global_average_pooling2d[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," policy (Activation)            (None, 361)          0           ['flatten[0][0]']                \n","                                                                                                  \n"," value (Dense)                  (None, 1)            51          ['dense[0][0]']                  \n","                                                                                                  \n","==================================================================================================\n","Total params: 961,547\n","Trainable params: 931,059\n","Non-trainable params: 30,488\n","__________________________________________________________________________________________________\n","epoch 1\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-10 20:23:33.392065: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","2023-01-10 20:23:51.913295: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n","2023-01-10 20:23:53.517612: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x113f75600 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-01-10 20:23:53.517675: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2023-01-10 20:23:53.648576: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","157/157 [==============================] - 56s 201ms/step - loss: 13.7260 - policy_loss: 6.1507 - value_loss: 0.7506 - policy_categorical_accuracy: 0.0071 - value_mse: 0.1392\n","epoch 2\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-10 20:24:34.522213: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","157/157 [==============================] - 32s 204ms/step - loss: 12.6232 - policy_loss: 5.6240 - value_loss: 0.6994 - policy_categorical_accuracy: 0.0262 - value_mse: 0.1222\n","epoch 3\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-10 20:25:09.505694: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","157/157 [==============================] - 33s 206ms/step - loss: 9.7101 - policy_loss: 4.1682 - value_loss: 0.6963 - policy_categorical_accuracy: 0.1660 - value_mse: 0.1218\n","Traceback (most recent call last):\n","  File \"mobilenet_v2.py\", line 168, in <module>\n","    epochs=1, batch_size=batch)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n","    return fn(*args, **kwargs)\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["#test mobilenetV1 version 2\n","\n","!python mobilenet_v2.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DAePFLmOaf60","outputId":"f7db71b3-940d-4ab8-baad-3b89cf58580f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-10 20:32:13.980758: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-10 20:32:15.172821: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-01-10 20:32:15.172992: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-01-10 20:32:15.173017: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","4\n","(10000, 19, 19, 31)\n","getValidation\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","tcmalloc: large alloc 2400002048 bytes == 0x5571a000 @  0x7f12dd38e887 0x7f128a5890d9 0x7f128a58e85f 0x7f128a5a306f 0x58e314 0x514581 0x5a5fb6 0x607433 0x601066 0x60112c 0x6015f6 0x64faa2 0x64fc4e 0x7f12dcf89c87 0x5b64ca\n","nbPositionsSGF = 29425326\n","nbPositionsSGF = 29425326\n","loading validation.data\n","2023-01-10 20:32:44.372754: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:32:44.381301: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:32:44.382005: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:32:44.382955: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-10 20:32:44.383204: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:32:44.383903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:32:44.384535: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:32:44.977131: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:32:44.977906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:32:44.978573: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-10 20:32:44.979166: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-01-10 20:32:44.979233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13779 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," board (InputLayer)             [(None, 19, 19, 31)  0           []                               \n","                                ]                                                                 \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 19, 19, 64)   2048        ['board[0][0]']                  \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 19, 19, 64)  256         ['conv2d[0][0]']                 \n"," alization)                                                                                       \n","                                                                                                  \n"," re_lu (ReLU)                   (None, 19, 19, 64)   0           ['batch_normalization[0][0]']    \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 19, 19, 198)  12672       ['re_lu[0][0]']                  \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 19, 19, 198)  792        ['conv2d_1[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation (Activation)        (None, 19, 19, 198)  0           ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," depthwise_conv2d (DepthwiseCon  (None, 19, 19, 198)  1782       ['activation[0][0]']             \n"," v2D)                                                                                             \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 19, 19, 198)  792        ['depthwise_conv2d[0][0]']       \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_1 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_2[0][0]']  \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 19, 19, 64)   12672       ['activation_1[0][0]']           \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 19, 19, 64)  256         ['conv2d_2[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add (Add)                      (None, 19, 19, 64)   0           ['batch_normalization_3[0][0]',  \n","                                                                  're_lu[0][0]']                  \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 19, 19, 198)  12672       ['add[0][0]']                    \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 19, 19, 198)  792        ['conv2d_3[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_2 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_4[0][0]']  \n","                                                                                                  \n"," depthwise_conv2d_1 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_2[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 19, 19, 198)  792        ['depthwise_conv2d_1[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_3 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 19, 19, 64)   12672       ['activation_3[0][0]']           \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 19, 19, 64)  256         ['conv2d_4[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add_1 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_6[0][0]',  \n","                                                                  'add[0][0]']                    \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 19, 19, 198)  12672       ['add_1[0][0]']                  \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 19, 19, 198)  792        ['conv2d_5[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_4 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_7[0][0]']  \n","                                                                                                  \n"," depthwise_conv2d_2 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_4[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 19, 19, 198)  792        ['depthwise_conv2d_2[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_5 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_8[0][0]']  \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 19, 19, 64)   12672       ['activation_5[0][0]']           \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 19, 19, 64)  256         ['conv2d_6[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add_2 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_9[0][0]',  \n","                                                                  'add_1[0][0]']                  \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 19, 19, 198)  12672       ['add_2[0][0]']                  \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 19, 19, 198)  792        ['conv2d_7[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_6 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_10[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_6[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_11 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_3[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_7 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_11[0][0]'] \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 19, 19, 64)   12672       ['activation_7[0][0]']           \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 19, 19, 64)  256         ['conv2d_8[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_3 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_12[0][0]', \n","                                                                  'add_2[0][0]']                  \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 19, 19, 198)  12672       ['add_3[0][0]']                  \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 19, 19, 198)  792        ['conv2d_9[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_8 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_13[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_8[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_4[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_9 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_14[0][0]'] \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_9[0][0]']           \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 19, 19, 64)  256         ['conv2d_10[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_4 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_15[0][0]', \n","                                                                  'add_3[0][0]']                  \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 19, 19, 198)  12672       ['add_4[0][0]']                  \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 19, 19, 198)  792        ['conv2d_11[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_10 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_16[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_5 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_10[0][0]']          \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_5[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_11 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_17[0][0]'] \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_11[0][0]']          \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 19, 19, 64)  256         ['conv2d_12[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_5 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_18[0][0]', \n","                                                                  'add_4[0][0]']                  \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 19, 19, 198)  12672       ['add_5[0][0]']                  \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 19, 19, 198)  792        ['conv2d_13[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_12 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_19[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_6 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_12[0][0]']          \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_6[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_13 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_20[0][0]'] \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_13[0][0]']          \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 19, 19, 64)  256         ['conv2d_14[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_6 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_21[0][0]', \n","                                                                  'add_5[0][0]']                  \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 19, 19, 198)  12672       ['add_6[0][0]']                  \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 19, 19, 198)  792        ['conv2d_15[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_14 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_22[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_7 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_14[0][0]']          \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_7[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_15 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_23[0][0]'] \n","                                                                                                  \n"," conv2d_16 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_15[0][0]']          \n","                                                                                                  \n"," batch_normalization_24 (BatchN  (None, 19, 19, 64)  256         ['conv2d_16[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_7 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_24[0][0]', \n","                                                                  'add_6[0][0]']                  \n","                                                                                                  \n"," conv2d_17 (Conv2D)             (None, 19, 19, 198)  12672       ['add_7[0][0]']                  \n","                                                                                                  \n"," batch_normalization_25 (BatchN  (None, 19, 19, 198)  792        ['conv2d_17[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_16 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_25[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_8 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_16[0][0]']          \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_26 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_8[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_17 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_26[0][0]'] \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_17[0][0]']          \n","                                                                                                  \n"," batch_normalization_27 (BatchN  (None, 19, 19, 64)  256         ['conv2d_18[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_8 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_27[0][0]', \n","                                                                  'add_7[0][0]']                  \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 19, 19, 198)  12672       ['add_8[0][0]']                  \n","                                                                                                  \n"," batch_normalization_28 (BatchN  (None, 19, 19, 198)  792        ['conv2d_19[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_18 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_28[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_9 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_18[0][0]']          \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_29 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_9[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_19 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_29[0][0]'] \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_19[0][0]']          \n","                                                                                                  \n"," batch_normalization_30 (BatchN  (None, 19, 19, 64)  256         ['conv2d_20[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_9 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_30[0][0]', \n","                                                                  'add_8[0][0]']                  \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 19, 19, 198)  12672       ['add_9[0][0]']                  \n","                                                                                                  \n"," batch_normalization_31 (BatchN  (None, 19, 19, 198)  792        ['conv2d_21[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_20 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_31[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_10 (Depthwise  (None, 19, 19, 198)  1782       ['activation_20[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_32 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_10[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_21 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_32[0][0]'] \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_21[0][0]']          \n","                                                                                                  \n"," batch_normalization_33 (BatchN  (None, 19, 19, 64)  256         ['conv2d_22[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_10 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_33[0][0]', \n","                                                                  'add_9[0][0]']                  \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 19, 19, 198)  12672       ['add_10[0][0]']                 \n","                                                                                                  \n"," batch_normalization_34 (BatchN  (None, 19, 19, 198)  792        ['conv2d_23[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_22 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_34[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_11 (Depthwise  (None, 19, 19, 198)  1782       ['activation_22[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_35 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_11[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_23 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_35[0][0]'] \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_23[0][0]']          \n","                                                                                                  \n"," batch_normalization_36 (BatchN  (None, 19, 19, 64)  256         ['conv2d_24[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_11 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_36[0][0]', \n","                                                                  'add_10[0][0]']                 \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 19, 19, 198)  12672       ['add_11[0][0]']                 \n","                                                                                                  \n"," batch_normalization_37 (BatchN  (None, 19, 19, 198)  792        ['conv2d_25[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_24 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_37[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_12 (Depthwise  (None, 19, 19, 198)  1782       ['activation_24[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_38 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_12[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_25 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_38[0][0]'] \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_25[0][0]']          \n","                                                                                                  \n"," batch_normalization_39 (BatchN  (None, 19, 19, 64)  256         ['conv2d_26[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_12 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_39[0][0]', \n","                                                                  'add_11[0][0]']                 \n","                                                                                                  \n"," conv2d_27 (Conv2D)             (None, 19, 19, 198)  12672       ['add_12[0][0]']                 \n","                                                                                                  \n"," batch_normalization_40 (BatchN  (None, 19, 19, 198)  792        ['conv2d_27[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_26 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_40[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_13 (Depthwise  (None, 19, 19, 198)  1782       ['activation_26[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_41 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_13[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_27 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_41[0][0]'] \n","                                                                                                  \n"," conv2d_28 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_27[0][0]']          \n","                                                                                                  \n"," batch_normalization_42 (BatchN  (None, 19, 19, 64)  256         ['conv2d_28[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_13 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_42[0][0]', \n","                                                                  'add_12[0][0]']                 \n","                                                                                                  \n"," conv2d_29 (Conv2D)             (None, 19, 19, 198)  12672       ['add_13[0][0]']                 \n","                                                                                                  \n"," batch_normalization_43 (BatchN  (None, 19, 19, 198)  792        ['conv2d_29[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_28 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_43[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_14 (Depthwise  (None, 19, 19, 198)  1782       ['activation_28[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_44 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_14[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_29 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_44[0][0]'] \n","                                                                                                  \n"," conv2d_30 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_29[0][0]']          \n","                                                                                                  \n"," batch_normalization_45 (BatchN  (None, 19, 19, 64)  256         ['conv2d_30[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_14 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_45[0][0]', \n","                                                                  'add_13[0][0]']                 \n","                                                                                                  \n"," conv2d_31 (Conv2D)             (None, 19, 19, 198)  12672       ['add_14[0][0]']                 \n","                                                                                                  \n"," batch_normalization_46 (BatchN  (None, 19, 19, 198)  792        ['conv2d_31[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_30 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_46[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_15 (Depthwise  (None, 19, 19, 198)  1782       ['activation_30[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_47 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_15[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_31 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_47[0][0]'] \n","                                                                                                  \n"," conv2d_32 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_31[0][0]']          \n","                                                                                                  \n"," batch_normalization_48 (BatchN  (None, 19, 19, 64)  256         ['conv2d_32[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_15 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_48[0][0]', \n","                                                                  'add_14[0][0]']                 \n","                                                                                                  \n"," conv2d_33 (Conv2D)             (None, 19, 19, 198)  12672       ['add_15[0][0]']                 \n","                                                                                                  \n"," batch_normalization_49 (BatchN  (None, 19, 19, 198)  792        ['conv2d_33[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_32 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_49[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_16 (Depthwise  (None, 19, 19, 198)  1782       ['activation_32[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_50 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_16[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_33 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_50[0][0]'] \n","                                                                                                  \n"," conv2d_34 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_33[0][0]']          \n","                                                                                                  \n"," batch_normalization_51 (BatchN  (None, 19, 19, 64)  256         ['conv2d_34[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_16 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_51[0][0]', \n","                                                                  'add_15[0][0]']                 \n","                                                                                                  \n"," conv2d_35 (Conv2D)             (None, 19, 19, 198)  12672       ['add_16[0][0]']                 \n","                                                                                                  \n"," batch_normalization_52 (BatchN  (None, 19, 19, 198)  792        ['conv2d_35[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_34 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_52[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_17 (Depthwise  (None, 19, 19, 198)  1782       ['activation_34[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_53 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_17[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_35 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_53[0][0]'] \n","                                                                                                  \n"," conv2d_36 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_35[0][0]']          \n","                                                                                                  \n"," batch_normalization_54 (BatchN  (None, 19, 19, 64)  256         ['conv2d_36[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_17 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_54[0][0]', \n","                                                                  'add_16[0][0]']                 \n","                                                                                                  \n"," conv2d_37 (Conv2D)             (None, 19, 19, 198)  12672       ['add_17[0][0]']                 \n","                                                                                                  \n"," batch_normalization_55 (BatchN  (None, 19, 19, 198)  792        ['conv2d_37[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_36 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_55[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_18 (Depthwise  (None, 19, 19, 198)  1782       ['activation_36[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_56 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_18[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_37 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_56[0][0]'] \n","                                                                                                  \n"," conv2d_38 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_37[0][0]']          \n","                                                                                                  \n"," batch_normalization_57 (BatchN  (None, 19, 19, 64)  256         ['conv2d_38[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_18 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_57[0][0]', \n","                                                                  'add_17[0][0]']                 \n","                                                                                                  \n"," conv2d_39 (Conv2D)             (None, 19, 19, 198)  12672       ['add_18[0][0]']                 \n","                                                                                                  \n"," batch_normalization_58 (BatchN  (None, 19, 19, 198)  792        ['conv2d_39[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_38 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_58[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_19 (Depthwise  (None, 19, 19, 198)  1782       ['activation_38[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_59 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_19[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_39 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_59[0][0]'] \n","                                                                                                  \n"," conv2d_40 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_39[0][0]']          \n","                                                                                                  \n"," batch_normalization_60 (BatchN  (None, 19, 19, 64)  256         ['conv2d_40[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_19 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_60[0][0]', \n","                                                                  'add_18[0][0]']                 \n","                                                                                                  \n"," conv2d_41 (Conv2D)             (None, 19, 19, 198)  12672       ['add_19[0][0]']                 \n","                                                                                                  \n"," batch_normalization_61 (BatchN  (None, 19, 19, 198)  792        ['conv2d_41[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_40 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_61[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_20 (Depthwise  (None, 19, 19, 198)  1782       ['activation_40[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_62 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_20[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_41 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_62[0][0]'] \n","                                                                                                  \n"," conv2d_42 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_41[0][0]']          \n","                                                                                                  \n"," batch_normalization_63 (BatchN  (None, 19, 19, 64)  256         ['conv2d_42[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_20 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_63[0][0]', \n","                                                                  'add_19[0][0]']                 \n","                                                                                                  \n"," conv2d_43 (Conv2D)             (None, 19, 19, 198)  12672       ['add_20[0][0]']                 \n","                                                                                                  \n"," batch_normalization_64 (BatchN  (None, 19, 19, 198)  792        ['conv2d_43[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_42 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_64[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_21 (Depthwise  (None, 19, 19, 198)  1782       ['activation_42[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_65 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_21[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_43 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_65[0][0]'] \n","                                                                                                  \n"," conv2d_44 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_43[0][0]']          \n","                                                                                                  \n"," batch_normalization_66 (BatchN  (None, 19, 19, 64)  256         ['conv2d_44[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_21 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_66[0][0]', \n","                                                                  'add_20[0][0]']                 \n","                                                                                                  \n"," conv2d_45 (Conv2D)             (None, 19, 19, 198)  12672       ['add_21[0][0]']                 \n","                                                                                                  \n"," batch_normalization_67 (BatchN  (None, 19, 19, 198)  792        ['conv2d_45[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_44 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_67[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_22 (Depthwise  (None, 19, 19, 198)  1782       ['activation_44[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_68 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_22[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_45 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_68[0][0]'] \n","                                                                                                  \n"," conv2d_46 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_45[0][0]']          \n","                                                                                                  \n"," batch_normalization_69 (BatchN  (None, 19, 19, 64)  256         ['conv2d_46[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_22 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_69[0][0]', \n","                                                                  'add_21[0][0]']                 \n","                                                                                                  \n"," conv2d_47 (Conv2D)             (None, 19, 19, 198)  12672       ['add_22[0][0]']                 \n","                                                                                                  \n"," batch_normalization_70 (BatchN  (None, 19, 19, 198)  792        ['conv2d_47[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_46 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_70[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_23 (Depthwise  (None, 19, 19, 198)  1782       ['activation_46[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_71 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_23[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_47 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_71[0][0]'] \n","                                                                                                  \n"," conv2d_48 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_47[0][0]']          \n","                                                                                                  \n"," batch_normalization_72 (BatchN  (None, 19, 19, 64)  256         ['conv2d_48[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_23 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_72[0][0]', \n","                                                                  'add_22[0][0]']                 \n","                                                                                                  \n"," conv2d_49 (Conv2D)             (None, 19, 19, 198)  12672       ['add_23[0][0]']                 \n","                                                                                                  \n"," batch_normalization_73 (BatchN  (None, 19, 19, 198)  792        ['conv2d_49[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_48 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_73[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_24 (Depthwise  (None, 19, 19, 198)  1782       ['activation_48[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_74 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_24[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_49 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_74[0][0]'] \n","                                                                                                  \n"," conv2d_50 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_49[0][0]']          \n","                                                                                                  \n"," batch_normalization_75 (BatchN  (None, 19, 19, 64)  256         ['conv2d_50[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_24 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_75[0][0]', \n","                                                                  'add_23[0][0]']                 \n","                                                                                                  \n"," conv2d_51 (Conv2D)             (None, 19, 19, 198)  12672       ['add_24[0][0]']                 \n","                                                                                                  \n"," batch_normalization_76 (BatchN  (None, 19, 19, 198)  792        ['conv2d_51[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_50 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_76[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_25 (Depthwise  (None, 19, 19, 198)  1782       ['activation_50[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_77 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_25[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_51 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_77[0][0]'] \n","                                                                                                  \n"," conv2d_52 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_51[0][0]']          \n","                                                                                                  \n"," batch_normalization_78 (BatchN  (None, 19, 19, 64)  256         ['conv2d_52[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_25 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_78[0][0]', \n","                                                                  'add_24[0][0]']                 \n","                                                                                                  \n"," conv2d_53 (Conv2D)             (None, 19, 19, 198)  12672       ['add_25[0][0]']                 \n","                                                                                                  \n"," batch_normalization_79 (BatchN  (None, 19, 19, 198)  792        ['conv2d_53[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_52 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_79[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_26 (Depthwise  (None, 19, 19, 198)  1782       ['activation_52[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_80 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_26[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_53 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_80[0][0]'] \n","                                                                                                  \n"," conv2d_54 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_53[0][0]']          \n","                                                                                                  \n"," batch_normalization_81 (BatchN  (None, 19, 19, 64)  256         ['conv2d_54[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_26 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_81[0][0]', \n","                                                                  'add_25[0][0]']                 \n","                                                                                                  \n"," conv2d_55 (Conv2D)             (None, 19, 19, 198)  12672       ['add_26[0][0]']                 \n","                                                                                                  \n"," batch_normalization_82 (BatchN  (None, 19, 19, 198)  792        ['conv2d_55[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_54 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_82[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_27 (Depthwise  (None, 19, 19, 198)  1782       ['activation_54[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_83 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_27[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_55 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_83[0][0]'] \n","                                                                                                  \n"," conv2d_56 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_55[0][0]']          \n","                                                                                                  \n"," batch_normalization_84 (BatchN  (None, 19, 19, 64)  256         ['conv2d_56[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_27 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_84[0][0]', \n","                                                                  'add_26[0][0]']                 \n","                                                                                                  \n"," conv2d_57 (Conv2D)             (None, 19, 19, 198)  12672       ['add_27[0][0]']                 \n","                                                                                                  \n"," batch_normalization_85 (BatchN  (None, 19, 19, 198)  792        ['conv2d_57[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_56 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_85[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_28 (Depthwise  (None, 19, 19, 198)  1782       ['activation_56[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_86 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_28[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_57 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_86[0][0]'] \n","                                                                                                  \n"," conv2d_58 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_57[0][0]']          \n","                                                                                                  \n"," batch_normalization_87 (BatchN  (None, 19, 19, 64)  256         ['conv2d_58[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_28 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_87[0][0]', \n","                                                                  'add_27[0][0]']                 \n","                                                                                                  \n"," conv2d_59 (Conv2D)             (None, 19, 19, 198)  12672       ['add_28[0][0]']                 \n","                                                                                                  \n"," batch_normalization_88 (BatchN  (None, 19, 19, 198)  792        ['conv2d_59[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_58 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_88[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_29 (Depthwise  (None, 19, 19, 198)  1782       ['activation_58[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_89 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_29[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_59 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_89[0][0]'] \n","                                                                                                  \n"," conv2d_60 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_59[0][0]']          \n","                                                                                                  \n"," batch_normalization_90 (BatchN  (None, 19, 19, 64)  256         ['conv2d_60[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_29 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_90[0][0]', \n","                                                                  'add_28[0][0]']                 \n","                                                                                                  \n"," conv2d_61 (Conv2D)             (None, 19, 19, 198)  12672       ['add_29[0][0]']                 \n","                                                                                                  \n"," batch_normalization_91 (BatchN  (None, 19, 19, 198)  792        ['conv2d_61[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_60 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_91[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_30 (Depthwise  (None, 19, 19, 198)  1782       ['activation_60[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_92 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_30[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_61 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_92[0][0]'] \n","                                                                                                  \n"," conv2d_62 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_61[0][0]']          \n","                                                                                                  \n"," batch_normalization_93 (BatchN  (None, 19, 19, 64)  256         ['conv2d_62[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_30 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_93[0][0]', \n","                                                                  'add_29[0][0]']                 \n","                                                                                                  \n"," conv2d_63 (Conv2D)             (None, 19, 19, 198)  12672       ['add_30[0][0]']                 \n","                                                                                                  \n"," batch_normalization_94 (BatchN  (None, 19, 19, 198)  792        ['conv2d_63[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_62 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_94[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_31 (Depthwise  (None, 19, 19, 198)  1782       ['activation_62[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_95 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_31[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_63 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_95[0][0]'] \n","                                                                                                  \n"," conv2d_64 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_63[0][0]']          \n","                                                                                                  \n"," batch_normalization_96 (BatchN  (None, 19, 19, 64)  256         ['conv2d_64[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_31 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_96[0][0]', \n","                                                                  'add_30[0][0]']                 \n","                                                                                                  \n"," conv2d_65 (Conv2D)             (None, 19, 19, 198)  12672       ['add_31[0][0]']                 \n","                                                                                                  \n"," batch_normalization_97 (BatchN  (None, 19, 19, 198)  792        ['conv2d_65[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_64 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_97[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_32 (Depthwise  (None, 19, 19, 198)  1782       ['activation_64[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_98 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_32[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_65 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_98[0][0]'] \n","                                                                                                  \n"," conv2d_66 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_65[0][0]']          \n","                                                                                                  \n"," batch_normalization_99 (BatchN  (None, 19, 19, 64)  256         ['conv2d_66[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_32 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_99[0][0]', \n","                                                                  'add_31[0][0]']                 \n","                                                                                                  \n"," conv2d_67 (Conv2D)             (None, 19, 19, 1)    64          ['add_32[0][0]']                 \n","                                                                                                  \n"," global_average_pooling2d (Glob  (None, 64)          0           ['add_32[0][0]']                 \n"," alAveragePooling2D)                                                                              \n","                                                                                                  \n"," flatten (Flatten)              (None, 361)          0           ['conv2d_67[0][0]']              \n","                                                                                                  \n"," dense (Dense)                  (None, 50)           3250        ['global_average_pooling2d[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," policy (Activation)            (None, 361)          0           ['flatten[0][0]']                \n","                                                                                                  \n"," value (Dense)                  (None, 1)            51          ['dense[0][0]']                  \n","                                                                                                  \n","==================================================================================================\n","Total params: 961,547\n","Trainable params: 931,059\n","Non-trainable params: 30,488\n","__________________________________________________________________________________________________\n","epoch 1\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-10 20:32:49.152356: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","2023-01-10 20:33:10.732674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n","2023-01-10 20:33:12.359990: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x110b42d00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-01-10 20:33:12.360054: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2023-01-10 20:33:12.491570: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","157/157 [==============================] - 59s 204ms/step - loss: 12.8114 - policy_loss: 5.6647 - value_loss: 0.8038 - policy_categorical_accuracy: 0.0506 - value_mse: 0.1515\n","epoch 2\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-10 20:33:52.591960: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","157/157 [==============================] - 32s 206ms/step - loss: 9.5185 - policy_loss: 4.0678 - value_loss: 0.6995 - policy_categorical_accuracy: 0.1641 - value_mse: 0.1220\n","epoch 3\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-10 20:34:27.090428: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","157/157 [==============================] - 32s 205ms/step - loss: 8.8223 - policy_loss: 3.7223 - value_loss: 0.6940 - policy_categorical_accuracy: 0.2134 - value_mse: 0.1208\n","epoch 4\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-10 20:35:01.463683: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","157/157 [==============================] - 32s 205ms/step - loss: 8.4496 - policy_loss: 3.5361 - value_loss: 0.6935 - policy_categorical_accuracy: 0.2419 - value_mse: 0.1208\n","epoch 5\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-10 20:35:35.645650: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","157/157 [==============================] - 33s 207ms/step - loss: 8.0771 - policy_loss: 3.3507 - value_loss: 0.6923 - policy_categorical_accuracy: 0.2604 - value_mse: 0.1191\n","epoch 6\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 8.0687 - policy_loss: 3.3480 - value_loss: 0.6900 - policy_categorical_accuracy: 0.2663 - value_mse: 0.1164\n","epoch 7\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 7.8073 - policy_loss: 3.2171 - value_loss: 0.6908 - policy_categorical_accuracy: 0.2817 - value_mse: 0.1189\n","epoch 8\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 7.6184 - policy_loss: 3.1234 - value_loss: 0.6902 - policy_categorical_accuracy: 0.2901 - value_mse: 0.1183\n","epoch 9\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 7.5414 - policy_loss: 3.0854 - value_loss: 0.6901 - policy_categorical_accuracy: 0.2978 - value_mse: 0.1175\n","epoch 10\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 7.5119 - policy_loss: 3.0717 - value_loss: 0.6891 - policy_categorical_accuracy: 0.2971 - value_mse: 0.1170\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [7.463372707366943, 3.047577381134033, 0.689323902130127, 0.3034999966621399, 0.11811574548482895]\n","epoch 11\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 7.3775 - policy_loss: 3.0051 - value_loss: 0.6889 - policy_categorical_accuracy: 0.3086 - value_mse: 0.1190\n","epoch 12\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 7.3211 - policy_loss: 2.9775 - value_loss: 0.6889 - policy_categorical_accuracy: 0.3127 - value_mse: 0.1182\n","epoch 13\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 208ms/step - loss: 7.2479 - policy_loss: 2.9418 - value_loss: 0.6883 - policy_categorical_accuracy: 0.3183 - value_mse: 0.1167\n","epoch 14\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 7.2258 - policy_loss: 2.9309 - value_loss: 0.6892 - policy_categorical_accuracy: 0.3205 - value_mse: 0.1156\n","epoch 15\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 7.2574 - policy_loss: 2.9476 - value_loss: 0.6888 - policy_categorical_accuracy: 0.3134 - value_mse: 0.1181\n","epoch 16\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 7.1581 - policy_loss: 2.8988 - value_loss: 0.6882 - policy_categorical_accuracy: 0.3211 - value_mse: 0.1158\n","epoch 17\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 7.2044 - policy_loss: 2.9225 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3141 - value_mse: 0.1160\n","epoch 18\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 7.1418 - policy_loss: 2.8922 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3258 - value_mse: 0.1183\n","epoch 19\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 7.1054 - policy_loss: 2.8747 - value_loss: 0.6875 - policy_categorical_accuracy: 0.3249 - value_mse: 0.1146\n","epoch 20\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 7.0691 - policy_loss: 2.8566 - value_loss: 0.6889 - policy_categorical_accuracy: 0.3280 - value_mse: 0.1185\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [7.000323295593262, 2.822834014892578, 0.6881687641143799, 0.33219999074935913, 0.11755646765232086]\n","epoch 21\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 209ms/step - loss: 6.9892 - policy_loss: 2.8180 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3231 - value_mse: 0.1163\n","epoch 22\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 7.0018 - policy_loss: 2.8246 - value_loss: 0.6881 - policy_categorical_accuracy: 0.3290 - value_mse: 0.1178\n","epoch 23\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 205ms/step - loss: 7.0161 - policy_loss: 2.8326 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3259 - value_mse: 0.1173\n","epoch 24\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 208ms/step - loss: 6.9914 - policy_loss: 2.8205 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3405 - value_mse: 0.1178\n","epoch 25\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 6.9785 - policy_loss: 2.8146 - value_loss: 0.6886 - policy_categorical_accuracy: 0.3379 - value_mse: 0.1167\n","epoch 26\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 208ms/step - loss: 6.9713 - policy_loss: 2.8126 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3303 - value_mse: 0.1151\n","epoch 27\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 6.8524 - policy_loss: 2.7530 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3438 - value_mse: 0.1186\n","epoch 28\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 208ms/step - loss: 6.8597 - policy_loss: 2.7573 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3448 - value_mse: 0.1168\n","epoch 29\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 205ms/step - loss: 6.8498 - policy_loss: 2.7533 - value_loss: 0.6878 - policy_categorical_accuracy: 0.3411 - value_mse: 0.1162\n","epoch 30\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 209ms/step - loss: 6.7250 - policy_loss: 2.6915 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3486 - value_mse: 0.1171\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.846860885620117, 2.7516722679138184, 0.6901021003723145, 0.33959999680519104, 0.11850772798061371]\n","epoch 31\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 6.8319 - policy_loss: 2.7460 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3385 - value_mse: 0.1154\n","epoch 32\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 207ms/step - loss: 6.7998 - policy_loss: 2.7302 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3472 - value_mse: 0.1159\n","epoch 33\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 6.8108 - policy_loss: 2.7362 - value_loss: 0.6882 - policy_categorical_accuracy: 0.3457 - value_mse: 0.1160\n","epoch 34\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 6.7902 - policy_loss: 2.7269 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3466 - value_mse: 0.1171\n","epoch 35\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 207ms/step - loss: 6.7566 - policy_loss: 2.7106 - value_loss: 0.6880 - policy_categorical_accuracy: 0.3523 - value_mse: 0.1157\n","epoch 36\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 6.7538 - policy_loss: 2.7103 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3458 - value_mse: 0.1174\n","epoch 37\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 6.7345 - policy_loss: 2.7016 - value_loss: 0.6865 - policy_categorical_accuracy: 0.3526 - value_mse: 0.1169\n","epoch 38\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 6.7895 - policy_loss: 2.7293 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3387 - value_mse: 0.1176\n","epoch 39\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 6.7542 - policy_loss: 2.7125 - value_loss: 0.6869 - policy_categorical_accuracy: 0.3448 - value_mse: 0.1163\n","epoch 40\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 205ms/step - loss: 6.7067 - policy_loss: 2.6891 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3497 - value_mse: 0.1145\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.620529651641846, 2.645172357559204, 0.6898407936096191, 0.3562999963760376, 0.11838366836309433]\n","epoch 41\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 208ms/step - loss: 6.6951 - policy_loss: 2.6840 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3500 - value_mse: 0.1161\n","epoch 42\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 6.6576 - policy_loss: 2.6663 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3494 - value_mse: 0.1178\n","epoch 43\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 6.5803 - policy_loss: 2.6277 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3598 - value_mse: 0.1164\n","epoch 44\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 207ms/step - loss: 6.5544 - policy_loss: 2.6162 - value_loss: 0.6862 - policy_categorical_accuracy: 0.3595 - value_mse: 0.1158\n","epoch 45\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 6.5884 - policy_loss: 2.6337 - value_loss: 0.6865 - policy_categorical_accuracy: 0.3602 - value_mse: 0.1158\n","epoch 46\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 6.6283 - policy_loss: 2.6544 - value_loss: 0.6862 - policy_categorical_accuracy: 0.3527 - value_mse: 0.1159\n","epoch 47\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 6.5705 - policy_loss: 2.6266 - value_loss: 0.6852 - policy_categorical_accuracy: 0.3639 - value_mse: 0.1171\n","epoch 48\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 6.5980 - policy_loss: 2.6412 - value_loss: 0.6849 - policy_categorical_accuracy: 0.3570 - value_mse: 0.1169\n","epoch 49\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 207ms/step - loss: 6.5812 - policy_loss: 2.6339 - value_loss: 0.6840 - policy_categorical_accuracy: 0.3508 - value_mse: 0.1162\n","epoch 50\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 208ms/step - loss: 6.5202 - policy_loss: 2.6038 - value_loss: 0.6844 - policy_categorical_accuracy: 0.3625 - value_mse: 0.1163\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.536857604980469, 2.612239360809326, 0.6847958564758301, 0.3589000105857849, 0.1159464493393898]\n","epoch 51\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 6.6195 - policy_loss: 2.6557 - value_loss: 0.6810 - policy_categorical_accuracy: 0.3513 - value_mse: 0.1154\n","epoch 52\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 6.5697 - policy_loss: 2.6315 - value_loss: 0.6809 - policy_categorical_accuracy: 0.3556 - value_mse: 0.1116\n","epoch 53\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.6010 - policy_loss: 2.6499 - value_loss: 0.6767 - policy_categorical_accuracy: 0.3523 - value_mse: 0.1113\n","epoch 54\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 205ms/step - loss: 6.5414 - policy_loss: 2.6216 - value_loss: 0.6749 - policy_categorical_accuracy: 0.3617 - value_mse: 0.1101\n","epoch 55\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.5680 - policy_loss: 2.6364 - value_loss: 0.6732 - policy_categorical_accuracy: 0.3551 - value_mse: 0.1099\n","epoch 56\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.5469 - policy_loss: 2.6257 - value_loss: 0.6747 - policy_categorical_accuracy: 0.3596 - value_mse: 0.1112\n","epoch 57\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.5062 - policy_loss: 2.6054 - value_loss: 0.6757 - policy_categorical_accuracy: 0.3609 - value_mse: 0.1130\n","epoch 58\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.5228 - policy_loss: 2.6162 - value_loss: 0.6721 - policy_categorical_accuracy: 0.3638 - value_mse: 0.1097\n","epoch 59\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.4691 - policy_loss: 2.5892 - value_loss: 0.6735 - policy_categorical_accuracy: 0.3678 - value_mse: 0.1106\n","epoch 60\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 6.4801 - policy_loss: 2.5991 - value_loss: 0.6660 - policy_categorical_accuracy: 0.3606 - value_mse: 0.1068\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.424819469451904, 2.570371389389038, 0.6687771677970886, 0.3662000000476837, 0.10831893235445023]\n","epoch 61\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 6.4594 - policy_loss: 2.5884 - value_loss: 0.6679 - policy_categorical_accuracy: 0.3620 - value_mse: 0.1079\n","epoch 62\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.4893 - policy_loss: 2.6037 - value_loss: 0.6685 - policy_categorical_accuracy: 0.3603 - value_mse: 0.1079\n","epoch 63\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 6.3924 - policy_loss: 2.5558 - value_loss: 0.6685 - policy_categorical_accuracy: 0.3712 - value_mse: 0.1063\n","epoch 64\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.4687 - policy_loss: 2.5954 - value_loss: 0.6668 - policy_categorical_accuracy: 0.3602 - value_mse: 0.1073\n","epoch 65\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.4411 - policy_loss: 2.5826 - value_loss: 0.6662 - policy_categorical_accuracy: 0.3575 - value_mse: 0.1076\n","epoch 66\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.4121 - policy_loss: 2.5705 - value_loss: 0.6625 - policy_categorical_accuracy: 0.3670 - value_mse: 0.1044\n","epoch 67\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.4296 - policy_loss: 2.5788 - value_loss: 0.6645 - policy_categorical_accuracy: 0.3663 - value_mse: 0.1044\n","epoch 68\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.4159 - policy_loss: 2.5731 - value_loss: 0.6634 - policy_categorical_accuracy: 0.3676 - value_mse: 0.1054\n","epoch 69\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.4342 - policy_loss: 2.5828 - value_loss: 0.6634 - policy_categorical_accuracy: 0.3634 - value_mse: 0.1059\n","epoch 70\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.4211 - policy_loss: 2.5763 - value_loss: 0.6646 - policy_categorical_accuracy: 0.3650 - value_mse: 0.1062\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.3467583656311035, 2.53839111328125, 0.6667073965072632, 0.3684000074863434, 0.10748528689146042]\n","epoch 71\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.4298 - policy_loss: 2.5820 - value_loss: 0.6632 - policy_categorical_accuracy: 0.3679 - value_mse: 0.1056\n","epoch 72\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.3610 - policy_loss: 2.5505 - value_loss: 0.6584 - policy_categorical_accuracy: 0.3695 - value_mse: 0.1034\n","epoch 73\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 6.3852 - policy_loss: 2.5608 - value_loss: 0.6633 - policy_categorical_accuracy: 0.3651 - value_mse: 0.1038\n","epoch 74\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.3466 - policy_loss: 2.5422 - value_loss: 0.6631 - policy_categorical_accuracy: 0.3637 - value_mse: 0.1032\n","epoch 75\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.3357 - policy_loss: 2.5382 - value_loss: 0.6613 - policy_categorical_accuracy: 0.3694 - value_mse: 0.1038\n","epoch 76\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 6.3432 - policy_loss: 2.5429 - value_loss: 0.6606 - policy_categorical_accuracy: 0.3775 - value_mse: 0.1026\n","epoch 77\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.3925 - policy_loss: 2.5666 - value_loss: 0.6637 - policy_categorical_accuracy: 0.3640 - value_mse: 0.1053\n","epoch 78\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.2529 - policy_loss: 2.4988 - value_loss: 0.6608 - policy_categorical_accuracy: 0.3793 - value_mse: 0.1045\n","epoch 79\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.4128 - policy_loss: 2.5807 - value_loss: 0.6580 - policy_categorical_accuracy: 0.3679 - value_mse: 0.1024\n","epoch 80\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 6.3467 - policy_loss: 2.5462 - value_loss: 0.6621 - policy_categorical_accuracy: 0.3710 - value_mse: 0.1052\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.247426986694336, 2.494617462158203, 0.6665144562721252, 0.3797000050544739, 0.10715219378471375]\n","epoch 81\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.3204 - policy_loss: 2.5361 - value_loss: 0.6571 - policy_categorical_accuracy: 0.3638 - value_mse: 0.1017\n","epoch 82\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.3852 - policy_loss: 2.5676 - value_loss: 0.6601 - policy_categorical_accuracy: 0.3671 - value_mse: 0.1028\n","epoch 83\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.3265 - policy_loss: 2.5395 - value_loss: 0.6588 - policy_categorical_accuracy: 0.3618 - value_mse: 0.1036\n","epoch 84\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.3025 - policy_loss: 2.5276 - value_loss: 0.6598 - policy_categorical_accuracy: 0.3693 - value_mse: 0.1026\n","epoch 85\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 6.2569 - policy_loss: 2.5068 - value_loss: 0.6568 - policy_categorical_accuracy: 0.3732 - value_mse: 0.1015\n","epoch 86\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.2577 - policy_loss: 2.5090 - value_loss: 0.6543 - policy_categorical_accuracy: 0.3749 - value_mse: 0.1018\n","epoch 87\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.2230 - policy_loss: 2.4914 - value_loss: 0.6561 - policy_categorical_accuracy: 0.3791 - value_mse: 0.1029\n","epoch 88\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 6.2134 - policy_loss: 2.4844 - value_loss: 0.6615 - policy_categorical_accuracy: 0.3733 - value_mse: 0.1058\n","epoch 89\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.3328 - policy_loss: 2.5476 - value_loss: 0.6556 - policy_categorical_accuracy: 0.3629 - value_mse: 0.1024\n","epoch 90\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.2126 - policy_loss: 2.4890 - value_loss: 0.6538 - policy_categorical_accuracy: 0.3746 - value_mse: 0.1028\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.17501974105835, 2.4666807651519775, 0.6613128781318665, 0.3828999996185303, 0.10463251918554306]\n","epoch 91\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.3394 - policy_loss: 2.5499 - value_loss: 0.6598 - policy_categorical_accuracy: 0.3622 - value_mse: 0.1045\n","epoch 92\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.2869 - policy_loss: 2.5254 - value_loss: 0.6574 - policy_categorical_accuracy: 0.3677 - value_mse: 0.1021\n","epoch 93\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.2007 - policy_loss: 2.4832 - value_loss: 0.6567 - policy_categorical_accuracy: 0.3792 - value_mse: 0.1023\n","epoch 94\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 201ms/step - loss: 6.2603 - policy_loss: 2.5150 - value_loss: 0.6537 - policy_categorical_accuracy: 0.3682 - value_mse: 0.1020\n","epoch 95\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.2595 - policy_loss: 2.5138 - value_loss: 0.6564 - policy_categorical_accuracy: 0.3651 - value_mse: 0.1023\n","epoch 96\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.2527 - policy_loss: 2.5107 - value_loss: 0.6569 - policy_categorical_accuracy: 0.3751 - value_mse: 0.1025\n","epoch 97\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.2036 - policy_loss: 2.4837 - value_loss: 0.6630 - policy_categorical_accuracy: 0.3743 - value_mse: 0.1057\n","epoch 98\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.2562 - policy_loss: 2.5147 - value_loss: 0.6547 - policy_categorical_accuracy: 0.3677 - value_mse: 0.1026\n","epoch 99\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.2158 - policy_loss: 2.4953 - value_loss: 0.6542 - policy_categorical_accuracy: 0.3754 - value_mse: 0.1018\n","epoch 100\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.2303 - policy_loss: 2.5014 - value_loss: 0.6575 - policy_categorical_accuracy: 0.3715 - value_mse: 0.1031\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.167445659637451, 2.4647417068481445, 0.6685338616371155, 0.3799999952316284, 0.10790468752384186]\n","epoch 101\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.1980 - policy_loss: 2.4880 - value_loss: 0.6532 - policy_categorical_accuracy: 0.3712 - value_mse: 0.1008\n","epoch 102\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.1994 - policy_loss: 2.4862 - value_loss: 0.6592 - policy_categorical_accuracy: 0.3770 - value_mse: 0.1023\n","epoch 103\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.1379 - policy_loss: 2.4568 - value_loss: 0.6575 - policy_categorical_accuracy: 0.3820 - value_mse: 0.1030\n","epoch 104\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 205ms/step - loss: 6.1614 - policy_loss: 2.4705 - value_loss: 0.6546 - policy_categorical_accuracy: 0.3781 - value_mse: 0.1012\n","epoch 105\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.2213 - policy_loss: 2.5016 - value_loss: 0.6534 - policy_categorical_accuracy: 0.3689 - value_mse: 0.1010\n","epoch 106\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.1852 - policy_loss: 2.4837 - value_loss: 0.6543 - policy_categorical_accuracy: 0.3742 - value_mse: 0.1010\n","epoch 107\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.1808 - policy_loss: 2.4825 - value_loss: 0.6532 - policy_categorical_accuracy: 0.3750 - value_mse: 0.1029\n","epoch 108\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.1293 - policy_loss: 2.4563 - value_loss: 0.6553 - policy_categorical_accuracy: 0.3778 - value_mse: 0.1025\n","epoch 109\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.2098 - policy_loss: 2.4993 - value_loss: 0.6509 - policy_categorical_accuracy: 0.3737 - value_mse: 0.1010\n","epoch 110\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.1400 - policy_loss: 2.4626 - value_loss: 0.6554 - policy_categorical_accuracy: 0.3837 - value_mse: 0.1017\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.0379204750061035, 2.3999149799346924, 0.6792623996734619, 0.3898000121116638, 0.11193933337926865]\n","epoch 111\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.1696 - policy_loss: 2.4770 - value_loss: 0.6572 - policy_categorical_accuracy: 0.3775 - value_mse: 0.1000\n","epoch 112\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.1236 - policy_loss: 2.4576 - value_loss: 0.6512 - policy_categorical_accuracy: 0.3815 - value_mse: 0.1008\n","epoch 113\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.1249 - policy_loss: 2.4589 - value_loss: 0.6508 - policy_categorical_accuracy: 0.3757 - value_mse: 0.1008\n","epoch 114\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.1371 - policy_loss: 2.4649 - value_loss: 0.6520 - policy_categorical_accuracy: 0.3756 - value_mse: 0.0996\n","epoch 115\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.1472 - policy_loss: 2.4698 - value_loss: 0.6534 - policy_categorical_accuracy: 0.3823 - value_mse: 0.0993\n","epoch 116\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.0460 - policy_loss: 2.4195 - value_loss: 0.6537 - policy_categorical_accuracy: 0.3866 - value_mse: 0.1023\n","epoch 117\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.1244 - policy_loss: 2.4628 - value_loss: 0.6465 - policy_categorical_accuracy: 0.3813 - value_mse: 0.0991\n","epoch 118\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.1376 - policy_loss: 2.4683 - value_loss: 0.6499 - policy_categorical_accuracy: 0.3764 - value_mse: 0.0984\n","epoch 119\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.1305 - policy_loss: 2.4641 - value_loss: 0.6521 - policy_categorical_accuracy: 0.3795 - value_mse: 0.0983\n","epoch 120\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.0781 - policy_loss: 2.4395 - value_loss: 0.6499 - policy_categorical_accuracy: 0.3816 - value_mse: 0.0988\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.048554420471191, 2.4149224758148193, 0.6701046824455261, 0.3869999945163727, 0.10765417665243149]\n","epoch 121\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.1180 - policy_loss: 2.4585 - value_loss: 0.6529 - policy_categorical_accuracy: 0.3832 - value_mse: 0.1005\n","epoch 122\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.0471 - policy_loss: 2.4242 - value_loss: 0.6515 - policy_categorical_accuracy: 0.3830 - value_mse: 0.0993\n","epoch 123\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.0712 - policy_loss: 2.4393 - value_loss: 0.6465 - policy_categorical_accuracy: 0.3819 - value_mse: 0.0982\n","epoch 124\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 6.1128 - policy_loss: 2.4594 - value_loss: 0.6487 - policy_categorical_accuracy: 0.3764 - value_mse: 0.0987\n","epoch 125\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 6.0143 - policy_loss: 2.4112 - value_loss: 0.6478 - policy_categorical_accuracy: 0.3891 - value_mse: 0.1001\n","epoch 126\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.0860 - policy_loss: 2.4450 - value_loss: 0.6528 - policy_categorical_accuracy: 0.3840 - value_mse: 0.1016\n","epoch 127\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.9810 - policy_loss: 2.3954 - value_loss: 0.6481 - policy_categorical_accuracy: 0.3877 - value_mse: 0.0976\n","epoch 128\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 6.0128 - policy_loss: 2.4123 - value_loss: 0.6469 - policy_categorical_accuracy: 0.3878 - value_mse: 0.0984\n","epoch 129\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.0547 - policy_loss: 2.4315 - value_loss: 0.6516 - policy_categorical_accuracy: 0.3882 - value_mse: 0.1000\n","epoch 130\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 6.0254 - policy_loss: 2.4199 - value_loss: 0.6463 - policy_categorical_accuracy: 0.3848 - value_mse: 0.0993\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.981416702270508, 2.3809914588928223, 0.680685818195343, 0.3935999870300293, 0.10914623737335205]\n","epoch 131\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.9653 - policy_loss: 2.3903 - value_loss: 0.6465 - policy_categorical_accuracy: 0.3923 - value_mse: 0.0992\n","epoch 132\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.0623 - policy_loss: 2.4381 - value_loss: 0.6488 - policy_categorical_accuracy: 0.3851 - value_mse: 0.0996\n","epoch 133\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 6.0479 - policy_loss: 2.4299 - value_loss: 0.6517 - policy_categorical_accuracy: 0.3843 - value_mse: 0.1000\n","epoch 134\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.0210 - policy_loss: 2.4198 - value_loss: 0.6461 - policy_categorical_accuracy: 0.3839 - value_mse: 0.0964\n","epoch 135\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 6.0205 - policy_loss: 2.4189 - value_loss: 0.6482 - policy_categorical_accuracy: 0.3827 - value_mse: 0.0985\n","epoch 136\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 6.0008 - policy_loss: 2.4098 - value_loss: 0.6477 - policy_categorical_accuracy: 0.3899 - value_mse: 0.0980\n","epoch 137\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.9501 - policy_loss: 2.3846 - value_loss: 0.6484 - policy_categorical_accuracy: 0.3922 - value_mse: 0.0970\n","epoch 138\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 6.0168 - policy_loss: 2.4172 - value_loss: 0.6508 - policy_categorical_accuracy: 0.3850 - value_mse: 0.0992\n","epoch 139\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.9815 - policy_loss: 2.4042 - value_loss: 0.6424 - policy_categorical_accuracy: 0.3892 - value_mse: 0.0962\n","epoch 140\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.9347 - policy_loss: 2.3806 - value_loss: 0.6439 - policy_categorical_accuracy: 0.3922 - value_mse: 0.0978\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.92413330078125, 2.3709278106689453, 0.6530082821846008, 0.39149999618530273, 0.10085124522447586]\n","epoch 141\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.9762 - policy_loss: 2.4003 - value_loss: 0.6467 - policy_categorical_accuracy: 0.3889 - value_mse: 0.0995\n","epoch 142\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 6.0051 - policy_loss: 2.4153 - value_loss: 0.6467 - policy_categorical_accuracy: 0.3863 - value_mse: 0.0996\n","epoch 143\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.9594 - policy_loss: 2.3919 - value_loss: 0.6487 - policy_categorical_accuracy: 0.3900 - value_mse: 0.0992\n","epoch 144\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.9882 - policy_loss: 2.4053 - value_loss: 0.6516 - policy_categorical_accuracy: 0.3909 - value_mse: 0.1009\n","epoch 145\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.9198 - policy_loss: 2.3723 - value_loss: 0.6501 - policy_categorical_accuracy: 0.3928 - value_mse: 0.0991\n","epoch 146\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.9724 - policy_loss: 2.4006 - value_loss: 0.6470 - policy_categorical_accuracy: 0.3891 - value_mse: 0.0994\n","epoch 147\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.9829 - policy_loss: 2.4067 - value_loss: 0.6461 - policy_categorical_accuracy: 0.3939 - value_mse: 0.0992\n","epoch 148\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.9038 - policy_loss: 2.3682 - value_loss: 0.6448 - policy_categorical_accuracy: 0.3987 - value_mse: 0.0966\n","epoch 149\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.9919 - policy_loss: 2.4121 - value_loss: 0.6461 - policy_categorical_accuracy: 0.3850 - value_mse: 0.0982\n","epoch 150\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 201ms/step - loss: 6.0515 - policy_loss: 2.4411 - value_loss: 0.6485 - policy_categorical_accuracy: 0.3811 - value_mse: 0.0992\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.890916347503662, 2.355067729949951, 0.6604933738708496, 0.3986999988555908, 0.10423831641674042]\n","epoch 151\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.9468 - policy_loss: 2.3911 - value_loss: 0.6448 - policy_categorical_accuracy: 0.3917 - value_mse: 0.0961\n","epoch 152\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.9216 - policy_loss: 2.3772 - value_loss: 0.6482 - policy_categorical_accuracy: 0.3920 - value_mse: 0.0990\n","epoch 153\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.9012 - policy_loss: 2.3706 - value_loss: 0.6420 - policy_categorical_accuracy: 0.3887 - value_mse: 0.0980\n","epoch 154\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.9470 - policy_loss: 2.3907 - value_loss: 0.6484 - policy_categorical_accuracy: 0.3906 - value_mse: 0.0989\n","epoch 155\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.9446 - policy_loss: 2.3912 - value_loss: 0.6458 - policy_categorical_accuracy: 0.3914 - value_mse: 0.0981\n","epoch 156\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.9238 - policy_loss: 2.3801 - value_loss: 0.6482 - policy_categorical_accuracy: 0.3897 - value_mse: 0.0993\n","epoch 157\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.8835 - policy_loss: 2.3632 - value_loss: 0.6425 - policy_categorical_accuracy: 0.3897 - value_mse: 0.0960\n","epoch 158\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.9229 - policy_loss: 2.3817 - value_loss: 0.6458 - policy_categorical_accuracy: 0.3953 - value_mse: 0.0992\n","epoch 159\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.8883 - policy_loss: 2.3664 - value_loss: 0.6428 - policy_categorical_accuracy: 0.3952 - value_mse: 0.0976\n","epoch 160\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.9064 - policy_loss: 2.3729 - value_loss: 0.6486 - policy_categorical_accuracy: 0.3973 - value_mse: 0.0978\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.850431442260742, 2.349140167236328, 0.6405938863754272, 0.3984000086784363, 0.09593799710273743]\n","epoch 161\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.8780 - policy_loss: 2.3630 - value_loss: 0.6409 - policy_categorical_accuracy: 0.3953 - value_mse: 0.0955\n","epoch 162\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.8996 - policy_loss: 2.3731 - value_loss: 0.6430 - policy_categorical_accuracy: 0.3965 - value_mse: 0.0972\n","epoch 163\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.8677 - policy_loss: 2.3578 - value_loss: 0.6427 - policy_categorical_accuracy: 0.4008 - value_mse: 0.0983\n","epoch 164\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.9695 - policy_loss: 2.4080 - value_loss: 0.6449 - policy_categorical_accuracy: 0.3805 - value_mse: 0.0954\n","epoch 165\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.8699 - policy_loss: 2.3582 - value_loss: 0.6456 - policy_categorical_accuracy: 0.3947 - value_mse: 0.0984\n","epoch 166\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.8001 - policy_loss: 2.3249 - value_loss: 0.6433 - policy_categorical_accuracy: 0.4055 - value_mse: 0.0967\n","epoch 167\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.8995 - policy_loss: 2.3748 - value_loss: 0.6437 - policy_categorical_accuracy: 0.3895 - value_mse: 0.0966\n","epoch 168\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.9242 - policy_loss: 2.3900 - value_loss: 0.6389 - policy_categorical_accuracy: 0.3945 - value_mse: 0.0951\n","epoch 169\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.8899 - policy_loss: 2.3703 - value_loss: 0.6449 - policy_categorical_accuracy: 0.3942 - value_mse: 0.0969\n","epoch 170\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.9200 - policy_loss: 2.3847 - value_loss: 0.6468 - policy_categorical_accuracy: 0.3946 - value_mse: 0.0963\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.93283748626709, 2.383639097213745, 0.6623313426971436, 0.390500009059906, 0.10548276454210281]\n","epoch 171\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.8575 - policy_loss: 2.3558 - value_loss: 0.6431 - policy_categorical_accuracy: 0.3978 - value_mse: 0.0962\n","epoch 172\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.8278 - policy_loss: 2.3413 - value_loss: 0.6432 - policy_categorical_accuracy: 0.3965 - value_mse: 0.0976\n","epoch 173\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.8949 - policy_loss: 2.3752 - value_loss: 0.6432 - policy_categorical_accuracy: 0.3915 - value_mse: 0.0960\n","epoch 174\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.7479 - policy_loss: 2.3008 - value_loss: 0.6460 - policy_categorical_accuracy: 0.4058 - value_mse: 0.0989\n","epoch 175\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.8767 - policy_loss: 2.3648 - value_loss: 0.6476 - policy_categorical_accuracy: 0.3933 - value_mse: 0.1000\n","epoch 176\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.8498 - policy_loss: 2.3545 - value_loss: 0.6420 - policy_categorical_accuracy: 0.3988 - value_mse: 0.0954\n","epoch 177\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.8811 - policy_loss: 2.3689 - value_loss: 0.6454 - policy_categorical_accuracy: 0.3941 - value_mse: 0.0968\n","epoch 178\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.9433 - policy_loss: 2.4008 - value_loss: 0.6446 - policy_categorical_accuracy: 0.3918 - value_mse: 0.0963\n","epoch 179\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.9058 - policy_loss: 2.3845 - value_loss: 0.6404 - policy_categorical_accuracy: 0.3945 - value_mse: 0.0959\n","epoch 180\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.8395 - policy_loss: 2.3522 - value_loss: 0.6395 - policy_categorical_accuracy: 0.3943 - value_mse: 0.0963\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.859508037567139, 2.356856107711792, 0.6507000923156738, 0.3984000086784363, 0.1003480926156044]\n","epoch 181\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.8425 - policy_loss: 2.3539 - value_loss: 0.6400 - policy_categorical_accuracy: 0.3957 - value_mse: 0.0951\n","epoch 182\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.8978 - policy_loss: 2.3816 - value_loss: 0.6408 - policy_categorical_accuracy: 0.3915 - value_mse: 0.0971\n","epoch 183\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.8022 - policy_loss: 2.3316 - value_loss: 0.6460 - policy_categorical_accuracy: 0.4058 - value_mse: 0.0982\n","epoch 184\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.8408 - policy_loss: 2.3542 - value_loss: 0.6400 - policy_categorical_accuracy: 0.3957 - value_mse: 0.0951\n","epoch 185\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.8628 - policy_loss: 2.3625 - value_loss: 0.6463 - policy_categorical_accuracy: 0.3959 - value_mse: 0.0985\n","epoch 186\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.8360 - policy_loss: 2.3518 - value_loss: 0.6417 - policy_categorical_accuracy: 0.3948 - value_mse: 0.0959\n","epoch 187\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.8335 - policy_loss: 2.3521 - value_loss: 0.6394 - policy_categorical_accuracy: 0.3927 - value_mse: 0.0956\n","epoch 188\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.7652 - policy_loss: 2.3184 - value_loss: 0.6393 - policy_categorical_accuracy: 0.4014 - value_mse: 0.0942\n","epoch 189\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.8009 - policy_loss: 2.3382 - value_loss: 0.6359 - policy_categorical_accuracy: 0.4010 - value_mse: 0.0957\n","epoch 190\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.7425 - policy_loss: 2.3063 - value_loss: 0.6422 - policy_categorical_accuracy: 0.4065 - value_mse: 0.0980\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.775160312652588, 2.3219857215881348, 0.6438956260681152, 0.399399995803833, 0.09761360287666321]\n","epoch 191\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.8302 - policy_loss: 2.3543 - value_loss: 0.6347 - policy_categorical_accuracy: 0.3967 - value_mse: 0.0934\n","epoch 192\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.7881 - policy_loss: 2.3287 - value_loss: 0.6445 - policy_categorical_accuracy: 0.4010 - value_mse: 0.0960\n","epoch 193\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.7863 - policy_loss: 2.3287 - value_loss: 0.6435 - policy_categorical_accuracy: 0.4048 - value_mse: 0.0968\n","epoch 194\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.8386 - policy_loss: 2.3597 - value_loss: 0.6345 - policy_categorical_accuracy: 0.3925 - value_mse: 0.0937\n","epoch 195\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.8134 - policy_loss: 2.3410 - value_loss: 0.6474 - policy_categorical_accuracy: 0.3986 - value_mse: 0.0998\n","epoch 196\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.7790 - policy_loss: 2.3277 - value_loss: 0.6403 - policy_categorical_accuracy: 0.3980 - value_mse: 0.0944\n","epoch 197\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.7511 - policy_loss: 2.3138 - value_loss: 0.6411 - policy_categorical_accuracy: 0.4053 - value_mse: 0.0946\n","epoch 198\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 201ms/step - loss: 5.7926 - policy_loss: 2.3361 - value_loss: 0.6387 - policy_categorical_accuracy: 0.3972 - value_mse: 0.0935\n","epoch 199\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.8066 - policy_loss: 2.3430 - value_loss: 0.6397 - policy_categorical_accuracy: 0.3923 - value_mse: 0.0974\n","epoch 200\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.8488 - policy_loss: 2.3636 - value_loss: 0.6414 - policy_categorical_accuracy: 0.3902 - value_mse: 0.0945\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.727588653564453, 2.3022541999816895, 0.6432207226753235, 0.4092999994754791, 0.09741624444723129]\n","epoch 201\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.7727 - policy_loss: 2.3268 - value_loss: 0.6396 - policy_categorical_accuracy: 0.3981 - value_mse: 0.0937\n","epoch 202\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.7360 - policy_loss: 2.3104 - value_loss: 0.6366 - policy_categorical_accuracy: 0.4052 - value_mse: 0.0944\n","epoch 203\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.7624 - policy_loss: 2.3236 - value_loss: 0.6371 - policy_categorical_accuracy: 0.3976 - value_mse: 0.0955\n","epoch 204\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.7595 - policy_loss: 2.3204 - value_loss: 0.6413 - policy_categorical_accuracy: 0.4058 - value_mse: 0.0970\n","epoch 205\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.7646 - policy_loss: 2.3236 - value_loss: 0.6409 - policy_categorical_accuracy: 0.4033 - value_mse: 0.0938\n","epoch 206\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.7698 - policy_loss: 2.3275 - value_loss: 0.6391 - policy_categorical_accuracy: 0.3948 - value_mse: 0.0925\n","epoch 207\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.7571 - policy_loss: 2.3230 - value_loss: 0.6360 - policy_categorical_accuracy: 0.3994 - value_mse: 0.0956\n","epoch 208\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.7996 - policy_loss: 2.3440 - value_loss: 0.6373 - policy_categorical_accuracy: 0.4016 - value_mse: 0.0926\n","epoch 209\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.7541 - policy_loss: 2.3218 - value_loss: 0.6368 - policy_categorical_accuracy: 0.4012 - value_mse: 0.0962\n","epoch 210\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.7820 - policy_loss: 2.3346 - value_loss: 0.6398 - policy_categorical_accuracy: 0.3977 - value_mse: 0.0961\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.705399036407471, 2.2994227409362793, 0.6339009404182434, 0.4074000120162964, 0.093321792781353]\n","epoch 211\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.6980 - policy_loss: 2.2934 - value_loss: 0.6388 - policy_categorical_accuracy: 0.4076 - value_mse: 0.0958\n","epoch 212\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.7381 - policy_loss: 2.3149 - value_loss: 0.6366 - policy_categorical_accuracy: 0.4071 - value_mse: 0.0936\n","epoch 213\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.7185 - policy_loss: 2.3021 - value_loss: 0.6435 - policy_categorical_accuracy: 0.4084 - value_mse: 0.0995\n","epoch 214\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.7283 - policy_loss: 2.3075 - value_loss: 0.6430 - policy_categorical_accuracy: 0.4037 - value_mse: 0.0955\n","epoch 215\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7337 - policy_loss: 2.3125 - value_loss: 0.6390 - policy_categorical_accuracy: 0.4026 - value_mse: 0.0938\n","epoch 216\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.7004 - policy_loss: 2.2952 - value_loss: 0.6411 - policy_categorical_accuracy: 0.3987 - value_mse: 0.0961\n","epoch 217\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.6979 - policy_loss: 2.2971 - value_loss: 0.6355 - policy_categorical_accuracy: 0.4107 - value_mse: 0.0932\n","epoch 218\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7587 - policy_loss: 2.3279 - value_loss: 0.6355 - policy_categorical_accuracy: 0.4014 - value_mse: 0.0935\n","epoch 219\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7100 - policy_loss: 2.3015 - value_loss: 0.6401 - policy_categorical_accuracy: 0.4077 - value_mse: 0.0946\n","epoch 220\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6592 - policy_loss: 2.2775 - value_loss: 0.6380 - policy_categorical_accuracy: 0.4086 - value_mse: 0.0956\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.659242630004883, 2.2749767303466797, 0.643467366695404, 0.4059999883174896, 0.09744638204574585]\n","epoch 221\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.7331 - policy_loss: 2.3166 - value_loss: 0.6344 - policy_categorical_accuracy: 0.3954 - value_mse: 0.0928\n","epoch 222\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6836 - policy_loss: 2.2910 - value_loss: 0.6367 - policy_categorical_accuracy: 0.4075 - value_mse: 0.0926\n","epoch 223\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.7843 - policy_loss: 2.3410 - value_loss: 0.6381 - policy_categorical_accuracy: 0.3952 - value_mse: 0.0953\n","epoch 224\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.6715 - policy_loss: 2.2862 - value_loss: 0.6355 - policy_categorical_accuracy: 0.4064 - value_mse: 0.0945\n","epoch 225\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.6691 - policy_loss: 2.2820 - value_loss: 0.6423 - policy_categorical_accuracy: 0.4123 - value_mse: 0.0959\n","epoch 226\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.6502 - policy_loss: 2.2759 - value_loss: 0.6361 - policy_categorical_accuracy: 0.4117 - value_mse: 0.0946\n","epoch 227\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.7176 - policy_loss: 2.3083 - value_loss: 0.6394 - policy_categorical_accuracy: 0.3993 - value_mse: 0.0961\n","epoch 228\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.7308 - policy_loss: 2.3172 - value_loss: 0.6356 - policy_categorical_accuracy: 0.3992 - value_mse: 0.0930\n","epoch 229\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.7139 - policy_loss: 2.3079 - value_loss: 0.6377 - policy_categorical_accuracy: 0.4018 - value_mse: 0.0939\n","epoch 230\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.6500 - policy_loss: 2.2753 - value_loss: 0.6398 - policy_categorical_accuracy: 0.4093 - value_mse: 0.0942\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.586818218231201, 2.2436044216156006, 0.6403638124465942, 0.41130000352859497, 0.09586084634065628]\n","epoch 231\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.6755 - policy_loss: 2.2884 - value_loss: 0.6398 - policy_categorical_accuracy: 0.4043 - value_mse: 0.0937\n","epoch 232\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.7161 - policy_loss: 2.3088 - value_loss: 0.6402 - policy_categorical_accuracy: 0.3959 - value_mse: 0.0953\n","epoch 233\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.7982 - policy_loss: 2.3524 - value_loss: 0.6357 - policy_categorical_accuracy: 0.3961 - value_mse: 0.0930\n","epoch 234\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.6956 - policy_loss: 2.3006 - value_loss: 0.6373 - policy_categorical_accuracy: 0.4046 - value_mse: 0.0928\n","epoch 235\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.6435 - policy_loss: 2.2737 - value_loss: 0.6396 - policy_categorical_accuracy: 0.4055 - value_mse: 0.0933\n","epoch 236\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.6584 - policy_loss: 2.2839 - value_loss: 0.6350 - policy_categorical_accuracy: 0.4103 - value_mse: 0.0932\n","epoch 237\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.6873 - policy_loss: 2.2970 - value_loss: 0.6382 - policy_categorical_accuracy: 0.4025 - value_mse: 0.0942\n","epoch 238\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.6516 - policy_loss: 2.2801 - value_loss: 0.6370 - policy_categorical_accuracy: 0.4118 - value_mse: 0.0934\n","epoch 239\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.6672 - policy_loss: 2.2869 - value_loss: 0.6396 - policy_categorical_accuracy: 0.4069 - value_mse: 0.0951\n","epoch 240\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.6837 - policy_loss: 2.2981 - value_loss: 0.6345 - policy_categorical_accuracy: 0.4007 - value_mse: 0.0933\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.665212154388428, 2.2908835411071777, 0.6306201815605164, 0.41530001163482666, 0.09186563640832901]\n","epoch 241\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.6557 - policy_loss: 2.2848 - value_loss: 0.6336 - policy_categorical_accuracy: 0.4084 - value_mse: 0.0916\n","epoch 242\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.6453 - policy_loss: 2.2802 - value_loss: 0.6330 - policy_categorical_accuracy: 0.4043 - value_mse: 0.0924\n","epoch 243\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.6425 - policy_loss: 2.2777 - value_loss: 0.6359 - policy_categorical_accuracy: 0.4075 - value_mse: 0.0937\n","epoch 244\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.6935 - policy_loss: 2.3041 - value_loss: 0.6346 - policy_categorical_accuracy: 0.4057 - value_mse: 0.0931\n","epoch 245\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.6991 - policy_loss: 2.3057 - value_loss: 0.6377 - policy_categorical_accuracy: 0.4003 - value_mse: 0.0943\n","epoch 246\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6896 - policy_loss: 2.3022 - value_loss: 0.6357 - policy_categorical_accuracy: 0.4026 - value_mse: 0.0920\n","epoch 247\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.6691 - policy_loss: 2.2930 - value_loss: 0.6342 - policy_categorical_accuracy: 0.4023 - value_mse: 0.0930\n","epoch 248\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.5704 - policy_loss: 2.2426 - value_loss: 0.6370 - policy_categorical_accuracy: 0.4140 - value_mse: 0.0938\n","epoch 249\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.6105 - policy_loss: 2.2651 - value_loss: 0.6328 - policy_categorical_accuracy: 0.4069 - value_mse: 0.0920\n","epoch 250\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.6369 - policy_loss: 2.2766 - value_loss: 0.6367 - policy_categorical_accuracy: 0.4094 - value_mse: 0.0949\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.593422889709473, 2.248422861099243, 0.6498545408248901, 0.4156000018119812, 0.10027779638767242]\n","epoch 251\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6231 - policy_loss: 2.2707 - value_loss: 0.6353 - policy_categorical_accuracy: 0.4126 - value_mse: 0.0921\n","epoch 252\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.6255 - policy_loss: 2.2731 - value_loss: 0.6334 - policy_categorical_accuracy: 0.4078 - value_mse: 0.0918\n","epoch 253\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.5801 - policy_loss: 2.2513 - value_loss: 0.6323 - policy_categorical_accuracy: 0.4164 - value_mse: 0.0942\n","epoch 254\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6435 - policy_loss: 2.2821 - value_loss: 0.6346 - policy_categorical_accuracy: 0.4019 - value_mse: 0.0933\n","epoch 255\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.6279 - policy_loss: 2.2769 - value_loss: 0.6299 - policy_categorical_accuracy: 0.4074 - value_mse: 0.0922\n","epoch 256\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6193 - policy_loss: 2.2704 - value_loss: 0.6350 - policy_categorical_accuracy: 0.4045 - value_mse: 0.0927\n","epoch 257\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.6367 - policy_loss: 2.2783 - value_loss: 0.6373 - policy_categorical_accuracy: 0.4089 - value_mse: 0.0953\n","epoch 258\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.6184 - policy_loss: 2.2703 - value_loss: 0.6355 - policy_categorical_accuracy: 0.4028 - value_mse: 0.0915\n","epoch 259\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.6445 - policy_loss: 2.2851 - value_loss: 0.6324 - policy_categorical_accuracy: 0.4140 - value_mse: 0.0909\n","epoch 260\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.7014 - policy_loss: 2.3140 - value_loss: 0.6322 - policy_categorical_accuracy: 0.3989 - value_mse: 0.0927\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.577657699584961, 2.2449514865875244, 0.6468853950500488, 0.4099000096321106, 0.09852629154920578]\n","epoch 261\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.5825 - policy_loss: 2.2528 - value_loss: 0.6363 - policy_categorical_accuracy: 0.4104 - value_mse: 0.0949\n","epoch 262\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.5820 - policy_loss: 2.2531 - value_loss: 0.6357 - policy_categorical_accuracy: 0.4104 - value_mse: 0.0929\n","epoch 263\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.6407 - policy_loss: 2.2819 - value_loss: 0.6373 - policy_categorical_accuracy: 0.4007 - value_mse: 0.0941\n","epoch 264\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 201ms/step - loss: 5.5737 - policy_loss: 2.2499 - value_loss: 0.6351 - policy_categorical_accuracy: 0.4156 - value_mse: 0.0923\n","epoch 265\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5919 - policy_loss: 2.2590 - value_loss: 0.6357 - policy_categorical_accuracy: 0.4072 - value_mse: 0.0937\n","epoch 266\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.5819 - policy_loss: 2.2561 - value_loss: 0.6320 - policy_categorical_accuracy: 0.4088 - value_mse: 0.0915\n","epoch 267\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.5210 - policy_loss: 2.2260 - value_loss: 0.6319 - policy_categorical_accuracy: 0.4164 - value_mse: 0.0931\n","epoch 268\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.5566 - policy_loss: 2.2431 - value_loss: 0.6338 - policy_categorical_accuracy: 0.4096 - value_mse: 0.0917\n","epoch 269\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.6034 - policy_loss: 2.2656 - value_loss: 0.6361 - policy_categorical_accuracy: 0.4112 - value_mse: 0.0923\n","epoch 270\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5950 - policy_loss: 2.2605 - value_loss: 0.6386 - policy_categorical_accuracy: 0.4073 - value_mse: 0.0927\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.63677978515625, 2.2626731395721436, 0.6762345433235168, 0.41440001130104065, 0.1093665137887001]\n","epoch 271\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.5768 - policy_loss: 2.2556 - value_loss: 0.6306 - policy_categorical_accuracy: 0.4063 - value_mse: 0.0913\n","epoch 272\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.5213 - policy_loss: 2.2278 - value_loss: 0.6313 - policy_categorical_accuracy: 0.4220 - value_mse: 0.0908\n","epoch 273\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.6247 - policy_loss: 2.2789 - value_loss: 0.6330 - policy_categorical_accuracy: 0.4022 - value_mse: 0.0928\n","epoch 274\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5590 - policy_loss: 2.2464 - value_loss: 0.6330 - policy_categorical_accuracy: 0.4128 - value_mse: 0.0929\n","epoch 275\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.6048 - policy_loss: 2.2721 - value_loss: 0.6278 - policy_categorical_accuracy: 0.4099 - value_mse: 0.0910\n","epoch 276\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.5329 - policy_loss: 2.2332 - value_loss: 0.6342 - policy_categorical_accuracy: 0.4135 - value_mse: 0.0931\n","epoch 277\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.5929 - policy_loss: 2.2663 - value_loss: 0.6286 - policy_categorical_accuracy: 0.4030 - value_mse: 0.0900\n","epoch 278\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.6264 - policy_loss: 2.2809 - value_loss: 0.6334 - policy_categorical_accuracy: 0.4096 - value_mse: 0.0910\n","epoch 279\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.5874 - policy_loss: 2.2630 - value_loss: 0.6309 - policy_categorical_accuracy: 0.4080 - value_mse: 0.0905\n","epoch 280\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.4943 - policy_loss: 2.2188 - value_loss: 0.6266 - policy_categorical_accuracy: 0.4197 - value_mse: 0.0901\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.445083141326904, 2.1902670860290527, 0.6347354650497437, 0.421099990606308, 0.09389384835958481]\n","epoch 281\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.4970 - policy_loss: 2.2168 - value_loss: 0.6338 - policy_categorical_accuracy: 0.4197 - value_mse: 0.0931\n","epoch 282\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.6018 - policy_loss: 2.2692 - value_loss: 0.6344 - policy_categorical_accuracy: 0.4139 - value_mse: 0.0933\n","epoch 283\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.5914 - policy_loss: 2.2648 - value_loss: 0.6332 - policy_categorical_accuracy: 0.4070 - value_mse: 0.0918\n","epoch 284\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.5831 - policy_loss: 2.2601 - value_loss: 0.6349 - policy_categorical_accuracy: 0.4134 - value_mse: 0.0922\n","epoch 285\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.5852 - policy_loss: 2.2649 - value_loss: 0.6279 - policy_categorical_accuracy: 0.4135 - value_mse: 0.0914\n","epoch 286\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.4655 - policy_loss: 2.2040 - value_loss: 0.6305 - policy_categorical_accuracy: 0.4265 - value_mse: 0.0907\n","epoch 287\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.4991 - policy_loss: 2.2204 - value_loss: 0.6318 - policy_categorical_accuracy: 0.4152 - value_mse: 0.0916\n","epoch 288\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.5385 - policy_loss: 2.2397 - value_loss: 0.6334 - policy_categorical_accuracy: 0.4139 - value_mse: 0.0920\n","epoch 289\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5639 - policy_loss: 2.2524 - value_loss: 0.6337 - policy_categorical_accuracy: 0.4116 - value_mse: 0.0908\n","epoch 290\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.5455 - policy_loss: 2.2455 - value_loss: 0.6297 - policy_categorical_accuracy: 0.4154 - value_mse: 0.0917\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.504255294799805, 2.2170467376708984, 0.6455918550491333, 0.4156999886035919, 0.09799360483884811]\n","epoch 291\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.5508 - policy_loss: 2.2471 - value_loss: 0.6322 - policy_categorical_accuracy: 0.4129 - value_mse: 0.0915\n","epoch 292\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.5976 - policy_loss: 2.2705 - value_loss: 0.6329 - policy_categorical_accuracy: 0.4058 - value_mse: 0.0927\n","epoch 293\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.5280 - policy_loss: 2.2390 - value_loss: 0.6267 - policy_categorical_accuracy: 0.4149 - value_mse: 0.0908\n","epoch 294\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.5714 - policy_loss: 2.2578 - value_loss: 0.6330 - policy_categorical_accuracy: 0.4076 - value_mse: 0.0902\n","epoch 295\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.4832 - policy_loss: 2.2145 - value_loss: 0.6318 - policy_categorical_accuracy: 0.4184 - value_mse: 0.0913\n","epoch 296\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.5682 - policy_loss: 2.2571 - value_loss: 0.6323 - policy_categorical_accuracy: 0.4121 - value_mse: 0.0922\n","epoch 297\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.5703 - policy_loss: 2.2580 - value_loss: 0.6330 - policy_categorical_accuracy: 0.4078 - value_mse: 0.0917\n","epoch 298\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.5360 - policy_loss: 2.2412 - value_loss: 0.6329 - policy_categorical_accuracy: 0.4120 - value_mse: 0.0945\n","epoch 299\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5119 - policy_loss: 2.2303 - value_loss: 0.6310 - policy_categorical_accuracy: 0.4131 - value_mse: 0.0914\n","epoch 300\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5586 - policy_loss: 2.2546 - value_loss: 0.6295 - policy_categorical_accuracy: 0.4106 - value_mse: 0.0912\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.4276814460754395, 2.1921374797821045, 0.6237872242927551, 0.41830000281333923, 0.0894155502319336]\n","epoch 301\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.5483 - policy_loss: 2.2480 - value_loss: 0.6330 - policy_categorical_accuracy: 0.4028 - value_mse: 0.0924\n","epoch 302\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.4766 - policy_loss: 2.2120 - value_loss: 0.6337 - policy_categorical_accuracy: 0.4227 - value_mse: 0.0932\n","epoch 303\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.5259 - policy_loss: 2.2386 - value_loss: 0.6303 - policy_categorical_accuracy: 0.4174 - value_mse: 0.0908\n","epoch 304\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.5107 - policy_loss: 2.2306 - value_loss: 0.6317 - policy_categorical_accuracy: 0.4137 - value_mse: 0.0920\n","epoch 305\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.5341 - policy_loss: 2.2419 - value_loss: 0.6328 - policy_categorical_accuracy: 0.4082 - value_mse: 0.0918\n","epoch 306\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.4662 - policy_loss: 2.2075 - value_loss: 0.6342 - policy_categorical_accuracy: 0.4189 - value_mse: 0.0917\n","epoch 307\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.5049 - policy_loss: 2.2318 - value_loss: 0.6248 - policy_categorical_accuracy: 0.4152 - value_mse: 0.0911\n","epoch 308\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.5444 - policy_loss: 2.2498 - value_loss: 0.6288 - policy_categorical_accuracy: 0.4091 - value_mse: 0.0910\n","epoch 309\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5371 - policy_loss: 2.2470 - value_loss: 0.6275 - policy_categorical_accuracy: 0.4070 - value_mse: 0.0915\n","epoch 310\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.4711 - policy_loss: 2.2123 - value_loss: 0.6313 - policy_categorical_accuracy: 0.4174 - value_mse: 0.0908\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.468003749847412, 2.2099521160125732, 0.6332240104675293, 0.4205000102519989, 0.09308777749538422]\n","epoch 311\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.5035 - policy_loss: 2.2269 - value_loss: 0.6350 - policy_categorical_accuracy: 0.4141 - value_mse: 0.0921\n","epoch 312\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.4789 - policy_loss: 2.2168 - value_loss: 0.6310 - policy_categorical_accuracy: 0.4205 - value_mse: 0.0918\n","epoch 313\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.5102 - policy_loss: 2.2364 - value_loss: 0.6238 - policy_categorical_accuracy: 0.4105 - value_mse: 0.0902\n","epoch 314\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.5522 - policy_loss: 2.2566 - value_loss: 0.6259 - policy_categorical_accuracy: 0.4118 - value_mse: 0.0900\n","epoch 315\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 201ms/step - loss: 5.4809 - policy_loss: 2.2196 - value_loss: 0.6290 - policy_categorical_accuracy: 0.4153 - value_mse: 0.0918\n","epoch 316\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.5192 - policy_loss: 2.2370 - value_loss: 0.6330 - policy_categorical_accuracy: 0.4124 - value_mse: 0.0905\n","epoch 317\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.4821 - policy_loss: 2.2224 - value_loss: 0.6254 - policy_categorical_accuracy: 0.4125 - value_mse: 0.0896\n","epoch 318\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.5569 - policy_loss: 2.2560 - value_loss: 0.6336 - policy_categorical_accuracy: 0.4129 - value_mse: 0.0934\n","epoch 319\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.5448 - policy_loss: 2.2504 - value_loss: 0.6330 - policy_categorical_accuracy: 0.4141 - value_mse: 0.0927\n","epoch 320\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.4531 - policy_loss: 2.2054 - value_loss: 0.6319 - policy_categorical_accuracy: 0.4163 - value_mse: 0.0913\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.468192100524902, 2.209472894668579, 0.6389641165733337, 0.41819998621940613, 0.09587063640356064]\n","epoch 321\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.4413 - policy_loss: 2.2032 - value_loss: 0.6248 - policy_categorical_accuracy: 0.4226 - value_mse: 0.0880\n","epoch 322\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.4746 - policy_loss: 2.2180 - value_loss: 0.6289 - policy_categorical_accuracy: 0.4190 - value_mse: 0.0892\n","epoch 323\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.5135 - policy_loss: 2.2371 - value_loss: 0.6301 - policy_categorical_accuracy: 0.4110 - value_mse: 0.0897\n","epoch 324\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.4521 - policy_loss: 2.2090 - value_loss: 0.6254 - policy_categorical_accuracy: 0.4159 - value_mse: 0.0898\n","epoch 325\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.4667 - policy_loss: 2.2166 - value_loss: 0.6253 - policy_categorical_accuracy: 0.4164 - value_mse: 0.0881\n","epoch 326\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.4961 - policy_loss: 2.2288 - value_loss: 0.6305 - policy_categorical_accuracy: 0.4158 - value_mse: 0.0909\n","epoch 327\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.4650 - policy_loss: 2.2134 - value_loss: 0.6308 - policy_categorical_accuracy: 0.4229 - value_mse: 0.0924\n","epoch 328\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.4730 - policy_loss: 2.2172 - value_loss: 0.6316 - policy_categorical_accuracy: 0.4160 - value_mse: 0.0916\n","epoch 329\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.5144 - policy_loss: 2.2407 - value_loss: 0.6263 - policy_categorical_accuracy: 0.4071 - value_mse: 0.0891\n","epoch 330\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.5029 - policy_loss: 2.2340 - value_loss: 0.6288 - policy_categorical_accuracy: 0.4078 - value_mse: 0.0887\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.439973831176758, 2.1999409198760986, 0.6341494917869568, 0.42160001397132874, 0.0939340740442276]\n","epoch 331\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.5081 - policy_loss: 2.2392 - value_loss: 0.6239 - policy_categorical_accuracy: 0.4088 - value_mse: 0.0879\n","epoch 332\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.4708 - policy_loss: 2.2157 - value_loss: 0.6340 - policy_categorical_accuracy: 0.4150 - value_mse: 0.0920\n","epoch 333\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.4756 - policy_loss: 2.2218 - value_loss: 0.6271 - policy_categorical_accuracy: 0.4132 - value_mse: 0.0903\n","epoch 334\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.4986 - policy_loss: 2.2298 - value_loss: 0.6345 - policy_categorical_accuracy: 0.4089 - value_mse: 0.0922\n","epoch 335\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.4569 - policy_loss: 2.2127 - value_loss: 0.6275 - policy_categorical_accuracy: 0.4166 - value_mse: 0.0908\n","epoch 336\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.4374 - policy_loss: 2.2034 - value_loss: 0.6268 - policy_categorical_accuracy: 0.4151 - value_mse: 0.0927\n","epoch 337\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.4224 - policy_loss: 2.1975 - value_loss: 0.6242 - policy_categorical_accuracy: 0.4185 - value_mse: 0.0908\n","epoch 338\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 200ms/step - loss: 5.4584 - policy_loss: 2.2122 - value_loss: 0.6311 - policy_categorical_accuracy: 0.4187 - value_mse: 0.0929\n","epoch 339\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.4592 - policy_loss: 2.2119 - value_loss: 0.6329 - policy_categorical_accuracy: 0.4196 - value_mse: 0.0911\n","epoch 340\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 201ms/step - loss: 5.4727 - policy_loss: 2.2220 - value_loss: 0.6267 - policy_categorical_accuracy: 0.4205 - value_mse: 0.0890\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.38816499710083, 2.180401563644409, 0.6255199909210205, 0.42149999737739563, 0.09033674001693726]\n","epoch 341\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.4053 - policy_loss: 2.1869 - value_loss: 0.6299 - policy_categorical_accuracy: 0.4254 - value_mse: 0.0902\n","epoch 342\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.4849 - policy_loss: 2.2298 - value_loss: 0.6240 - policy_categorical_accuracy: 0.4138 - value_mse: 0.0897\n","epoch 343\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.4520 - policy_loss: 2.2116 - value_loss: 0.6279 - policy_categorical_accuracy: 0.4216 - value_mse: 0.0882\n","epoch 344\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 201ms/step - loss: 5.4605 - policy_loss: 2.2175 - value_loss: 0.6251 - policy_categorical_accuracy: 0.4156 - value_mse: 0.0885\n","epoch 345\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.4286 - policy_loss: 2.2013 - value_loss: 0.6261 - policy_categorical_accuracy: 0.4230 - value_mse: 0.0888\n","epoch 346\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.4335 - policy_loss: 2.2028 - value_loss: 0.6283 - policy_categorical_accuracy: 0.4191 - value_mse: 0.0906\n","epoch 347\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.4285 - policy_loss: 2.2009 - value_loss: 0.6275 - policy_categorical_accuracy: 0.4163 - value_mse: 0.0902\n","epoch 348\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.4110 - policy_loss: 2.1951 - value_loss: 0.6220 - policy_categorical_accuracy: 0.4172 - value_mse: 0.0883\n","epoch 349\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 5.4037 - policy_loss: 2.1898 - value_loss: 0.6257 - policy_categorical_accuracy: 0.4238 - value_mse: 0.0897\n","epoch 350\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.4429 - policy_loss: 2.2093 - value_loss: 0.6263 - policy_categorical_accuracy: 0.4170 - value_mse: 0.0899\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.393927097320557, 2.1889989376068115, 0.6180958151817322, 0.42329999804496765, 0.08697212487459183]\n","epoch 351\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 209ms/step - loss: 5.4247 - policy_loss: 2.2028 - value_loss: 0.6215 - policy_categorical_accuracy: 0.4208 - value_mse: 0.0870\n","epoch 352\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3650 - policy_loss: 2.1699 - value_loss: 0.6280 - policy_categorical_accuracy: 0.4215 - value_mse: 0.0913\n","epoch 353\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3917 - policy_loss: 2.1844 - value_loss: 0.6261 - policy_categorical_accuracy: 0.4251 - value_mse: 0.0879\n","epoch 354\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.4641 - policy_loss: 2.2227 - value_loss: 0.6222 - policy_categorical_accuracy: 0.4110 - value_mse: 0.0873\n","epoch 355\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 5.4161 - policy_loss: 2.1967 - value_loss: 0.6266 - policy_categorical_accuracy: 0.4226 - value_mse: 0.0897\n","epoch 356\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 5.4117 - policy_loss: 2.1953 - value_loss: 0.6255 - policy_categorical_accuracy: 0.4195 - value_mse: 0.0892\n","epoch 357\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 5.4428 - policy_loss: 2.2109 - value_loss: 0.6257 - policy_categorical_accuracy: 0.4181 - value_mse: 0.0904\n","epoch 358\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3916 - policy_loss: 2.1857 - value_loss: 0.6253 - policy_categorical_accuracy: 0.4183 - value_mse: 0.0904\n","epoch 359\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 207ms/step - loss: 5.3925 - policy_loss: 2.1880 - value_loss: 0.6220 - policy_categorical_accuracy: 0.4213 - value_mse: 0.0888\n","epoch 360\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.4207 - policy_loss: 2.2016 - value_loss: 0.6232 - policy_categorical_accuracy: 0.4180 - value_mse: 0.0886\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.327877521514893, 2.1506154537200928, 0.6327244639396667, 0.4300000071525574, 0.09249947220087051]\n","epoch 361\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 5.4362 - policy_loss: 2.2106 - value_loss: 0.6212 - policy_categorical_accuracy: 0.4121 - value_mse: 0.0871\n","epoch 362\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3940 - policy_loss: 2.1891 - value_loss: 0.6224 - policy_categorical_accuracy: 0.4200 - value_mse: 0.0889\n","epoch 363\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 207ms/step - loss: 5.4140 - policy_loss: 2.1968 - value_loss: 0.6273 - policy_categorical_accuracy: 0.4191 - value_mse: 0.0897\n","epoch 364\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 205ms/step - loss: 5.3544 - policy_loss: 2.1692 - value_loss: 0.6234 - policy_categorical_accuracy: 0.4221 - value_mse: 0.0886\n","epoch 365\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.4342 - policy_loss: 2.2096 - value_loss: 0.6227 - policy_categorical_accuracy: 0.4150 - value_mse: 0.0902\n","epoch 366\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.4578 - policy_loss: 2.2190 - value_loss: 0.6279 - policy_categorical_accuracy: 0.4193 - value_mse: 0.0912\n","epoch 367\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 209ms/step - loss: 5.4494 - policy_loss: 2.2177 - value_loss: 0.6226 - policy_categorical_accuracy: 0.4157 - value_mse: 0.0872\n","epoch 368\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 207ms/step - loss: 5.4121 - policy_loss: 2.1988 - value_loss: 0.6232 - policy_categorical_accuracy: 0.4189 - value_mse: 0.0886\n","epoch 369\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3769 - policy_loss: 2.1810 - value_loss: 0.6241 - policy_categorical_accuracy: 0.4265 - value_mse: 0.0899\n","epoch 370\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.4089 - policy_loss: 2.1989 - value_loss: 0.6207 - policy_categorical_accuracy: 0.4215 - value_mse: 0.0894\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.349337100982666, 2.1664981842041016, 0.6261695623397827, 0.42899999022483826, 0.09008149057626724]\n","epoch 371\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 5.3892 - policy_loss: 2.1844 - value_loss: 0.6304 - policy_categorical_accuracy: 0.4213 - value_mse: 0.0918\n","epoch 372\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 208ms/step - loss: 5.3923 - policy_loss: 2.1900 - value_loss: 0.6226 - policy_categorical_accuracy: 0.4183 - value_mse: 0.0886\n","epoch 373\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 207ms/step - loss: 5.4331 - policy_loss: 2.2088 - value_loss: 0.6263 - policy_categorical_accuracy: 0.4240 - value_mse: 0.0892\n","epoch 374\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 205ms/step - loss: 5.3739 - policy_loss: 2.1812 - value_loss: 0.6225 - policy_categorical_accuracy: 0.4237 - value_mse: 0.0898\n","epoch 375\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3314 - policy_loss: 2.1594 - value_loss: 0.6239 - policy_categorical_accuracy: 0.4264 - value_mse: 0.0891\n","epoch 376\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3773 - policy_loss: 2.1837 - value_loss: 0.6215 - policy_categorical_accuracy: 0.4236 - value_mse: 0.0875\n","epoch 377\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 209ms/step - loss: 5.4264 - policy_loss: 2.2080 - value_loss: 0.6225 - policy_categorical_accuracy: 0.4249 - value_mse: 0.0866\n","epoch 378\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 205ms/step - loss: 5.3991 - policy_loss: 2.1950 - value_loss: 0.6215 - policy_categorical_accuracy: 0.4198 - value_mse: 0.0892\n","epoch 379\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 5.4313 - policy_loss: 2.2092 - value_loss: 0.6257 - policy_categorical_accuracy: 0.4110 - value_mse: 0.0892\n","epoch 380\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 205ms/step - loss: 5.3475 - policy_loss: 2.1697 - value_loss: 0.6213 - policy_categorical_accuracy: 0.4222 - value_mse: 0.0884\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.327372074127197, 2.159163236618042, 0.6223121285438538, 0.42800000309944153, 0.08843594789505005]\n","epoch 381\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 207ms/step - loss: 5.3731 - policy_loss: 2.1830 - value_loss: 0.6205 - policy_categorical_accuracy: 0.4258 - value_mse: 0.0881\n","epoch 382\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 207ms/step - loss: 5.3837 - policy_loss: 2.1853 - value_loss: 0.6267 - policy_categorical_accuracy: 0.4179 - value_mse: 0.0912\n","epoch 383\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3862 - policy_loss: 2.1896 - value_loss: 0.6212 - policy_categorical_accuracy: 0.4275 - value_mse: 0.0890\n","epoch 384\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 5.3545 - policy_loss: 2.1744 - value_loss: 0.6202 - policy_categorical_accuracy: 0.4239 - value_mse: 0.0877\n","epoch 385\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 205ms/step - loss: 5.3944 - policy_loss: 2.1896 - value_loss: 0.6299 - policy_categorical_accuracy: 0.4214 - value_mse: 0.0908\n","epoch 386\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 5.4030 - policy_loss: 2.1943 - value_loss: 0.6295 - policy_categorical_accuracy: 0.4145 - value_mse: 0.0918\n","epoch 387\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3962 - policy_loss: 2.1934 - value_loss: 0.6248 - policy_categorical_accuracy: 0.4166 - value_mse: 0.0877\n","epoch 388\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3051 - policy_loss: 2.1480 - value_loss: 0.6248 - policy_categorical_accuracy: 0.4275 - value_mse: 0.0874\n","epoch 389\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 207ms/step - loss: 5.4244 - policy_loss: 2.2056 - value_loss: 0.6294 - policy_categorical_accuracy: 0.4131 - value_mse: 0.0892\n","epoch 390\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3872 - policy_loss: 2.1889 - value_loss: 0.6257 - policy_categorical_accuracy: 0.4156 - value_mse: 0.0876\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.349972724914551, 2.1752238273620605, 0.6160609126091003, 0.4284999966621399, 0.08617780357599258]\n","epoch 391\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 5.3603 - policy_loss: 2.1793 - value_loss: 0.6183 - policy_categorical_accuracy: 0.4188 - value_mse: 0.0879\n","epoch 392\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 208ms/step - loss: 5.4031 - policy_loss: 2.1986 - value_loss: 0.6229 - policy_categorical_accuracy: 0.4192 - value_mse: 0.0895\n","epoch 393\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3477 - policy_loss: 2.1711 - value_loss: 0.6228 - policy_categorical_accuracy: 0.4316 - value_mse: 0.0894\n","epoch 394\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3769 - policy_loss: 2.1868 - value_loss: 0.6211 - policy_categorical_accuracy: 0.4238 - value_mse: 0.0876\n","epoch 395\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3804 - policy_loss: 2.1895 - value_loss: 0.6194 - policy_categorical_accuracy: 0.4204 - value_mse: 0.0873\n","epoch 396\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3071 - policy_loss: 2.1539 - value_loss: 0.6175 - policy_categorical_accuracy: 0.4344 - value_mse: 0.0855\n","epoch 397\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3546 - policy_loss: 2.1756 - value_loss: 0.6220 - policy_categorical_accuracy: 0.4280 - value_mse: 0.0884\n","epoch 398\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 209ms/step - loss: 5.3266 - policy_loss: 2.1645 - value_loss: 0.6165 - policy_categorical_accuracy: 0.4218 - value_mse: 0.0846\n","epoch 399\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3266 - policy_loss: 2.1618 - value_loss: 0.6223 - policy_categorical_accuracy: 0.4286 - value_mse: 0.0892\n","epoch 400\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.2962 - policy_loss: 2.1469 - value_loss: 0.6218 - policy_categorical_accuracy: 0.4290 - value_mse: 0.0877\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.334929466247559, 2.163648843765259, 0.6272513270378113, 0.4309999942779541, 0.09037674218416214]\n","epoch 401\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 207ms/step - loss: 5.2926 - policy_loss: 2.1470 - value_loss: 0.6183 - policy_categorical_accuracy: 0.4302 - value_mse: 0.0850\n","epoch 402\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 206ms/step - loss: 5.3473 - policy_loss: 2.1726 - value_loss: 0.6222 - policy_categorical_accuracy: 0.4271 - value_mse: 0.0846\n","epoch 403\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 33s 208ms/step - loss: 5.3566 - policy_loss: 2.1780 - value_loss: 0.6210 - policy_categorical_accuracy: 0.4214 - value_mse: 0.0860\n","epoch 404\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","151/157 [===========================>..] - ETA: 1s - loss: 5.3954 - policy_loss: 2.1978 - value_loss: 0.6204 - policy_categorical_accuracy: 0.4193 - value_mse: 0.0872"]}]},{"cell_type":"code","source":["!python mobilenet_v2_Lucas1.py"],"metadata":{"id":"krwAsP44BWWs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"129eb080-7e8b-4684-cbbf-4098b0059618"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-11 22:38:08.012105: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-11 22:38:08.918362: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-01-11 22:38:08.918526: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-01-11 22:38:08.918561: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","4\n","(10000, 19, 19, 31)\n","getValidation\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","tcmalloc: large alloc 2400002048 bytes == 0x55a0c000 @  0x7fce68208887 0x7fce154030d9 0x7fce1540885f 0x7fce1541d06f 0x58e314 0x514581 0x5a5fb6 0x607433 0x601066 0x60112c 0x6015f6 0x64faa2 0x64fc4e 0x7fce67e03c87 0x5b64ca\n","nbPositionsSGF = 29425326\n","nbPositionsSGF = 29425326\n","loading validation.data\n","2023-01-11 22:38:38.023411: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 22:38:38.160221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 22:38:38.160910: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 22:38:38.161860: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-11 22:38:38.162083: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 22:38:38.162719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 22:38:38.163272: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 22:38:38.936762: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 22:38:38.937420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 22:38:38.938033: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 22:38:38.938596: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-01-11 22:38:38.938645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13779 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," board (InputLayer)             [(None, 19, 19, 31)  0           []                               \n","                                ]                                                                 \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 19, 19, 64)   2048        ['board[0][0]']                  \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 19, 19, 64)  256         ['conv2d[0][0]']                 \n"," alization)                                                                                       \n","                                                                                                  \n"," re_lu (ReLU)                   (None, 19, 19, 64)   0           ['batch_normalization[0][0]']    \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 19, 19, 198)  12672       ['re_lu[0][0]']                  \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 19, 19, 198)  792        ['conv2d_1[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation (Activation)        (None, 19, 19, 198)  0           ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," depthwise_conv2d (DepthwiseCon  (None, 19, 19, 198)  1782       ['activation[0][0]']             \n"," v2D)                                                                                             \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 19, 19, 198)  792        ['depthwise_conv2d[0][0]']       \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_1 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_2[0][0]']  \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 19, 19, 64)   12672       ['activation_1[0][0]']           \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 19, 19, 64)  256         ['conv2d_2[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add (Add)                      (None, 19, 19, 64)   0           ['batch_normalization_3[0][0]',  \n","                                                                  're_lu[0][0]']                  \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 19, 19, 198)  12672       ['add[0][0]']                    \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 19, 19, 198)  792        ['conv2d_3[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_2 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_4[0][0]']  \n","                                                                                                  \n"," depthwise_conv2d_1 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_2[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 19, 19, 198)  792        ['depthwise_conv2d_1[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_3 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 19, 19, 64)   12672       ['activation_3[0][0]']           \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 19, 19, 64)  256         ['conv2d_4[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add_1 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_6[0][0]',  \n","                                                                  'add[0][0]']                    \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 19, 19, 198)  12672       ['add_1[0][0]']                  \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 19, 19, 198)  792        ['conv2d_5[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_4 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_7[0][0]']  \n","                                                                                                  \n"," depthwise_conv2d_2 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_4[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 19, 19, 198)  792        ['depthwise_conv2d_2[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_5 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_8[0][0]']  \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 19, 19, 64)   12672       ['activation_5[0][0]']           \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 19, 19, 64)  256         ['conv2d_6[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add_2 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_9[0][0]',  \n","                                                                  'add_1[0][0]']                  \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 19, 19, 198)  12672       ['add_2[0][0]']                  \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 19, 19, 198)  792        ['conv2d_7[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_6 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_10[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_6[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_11 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_3[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_7 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_11[0][0]'] \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 19, 19, 64)   12672       ['activation_7[0][0]']           \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 19, 19, 64)  256         ['conv2d_8[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_3 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_12[0][0]', \n","                                                                  'add_2[0][0]']                  \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 19, 19, 198)  12672       ['add_3[0][0]']                  \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 19, 19, 198)  792        ['conv2d_9[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_8 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_13[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_8[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_4[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_9 (Activation)      (None, 19, 19, 198)  0           ['batch_normalization_14[0][0]'] \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_9[0][0]']           \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 19, 19, 64)  256         ['conv2d_10[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_4 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_15[0][0]', \n","                                                                  'add_3[0][0]']                  \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 19, 19, 198)  12672       ['add_4[0][0]']                  \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 19, 19, 198)  792        ['conv2d_11[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_10 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_16[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_5 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_10[0][0]']          \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_5[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_11 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_17[0][0]'] \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_11[0][0]']          \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 19, 19, 64)  256         ['conv2d_12[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_5 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_18[0][0]', \n","                                                                  'add_4[0][0]']                  \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 19, 19, 198)  12672       ['add_5[0][0]']                  \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 19, 19, 198)  792        ['conv2d_13[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_12 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_19[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_6 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_12[0][0]']          \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_6[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_13 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_20[0][0]'] \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_13[0][0]']          \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 19, 19, 64)  256         ['conv2d_14[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_6 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_21[0][0]', \n","                                                                  'add_5[0][0]']                  \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 19, 19, 198)  12672       ['add_6[0][0]']                  \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 19, 19, 198)  792        ['conv2d_15[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_14 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_22[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_7 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_14[0][0]']          \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_7[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_15 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_23[0][0]'] \n","                                                                                                  \n"," conv2d_16 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_15[0][0]']          \n","                                                                                                  \n"," batch_normalization_24 (BatchN  (None, 19, 19, 64)  256         ['conv2d_16[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_7 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_24[0][0]', \n","                                                                  'add_6[0][0]']                  \n","                                                                                                  \n"," conv2d_17 (Conv2D)             (None, 19, 19, 198)  12672       ['add_7[0][0]']                  \n","                                                                                                  \n"," batch_normalization_25 (BatchN  (None, 19, 19, 198)  792        ['conv2d_17[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_16 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_25[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_8 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_16[0][0]']          \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_26 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_8[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_17 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_26[0][0]'] \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_17[0][0]']          \n","                                                                                                  \n"," batch_normalization_27 (BatchN  (None, 19, 19, 64)  256         ['conv2d_18[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_8 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_27[0][0]', \n","                                                                  'add_7[0][0]']                  \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 19, 19, 198)  12672       ['add_8[0][0]']                  \n","                                                                                                  \n"," batch_normalization_28 (BatchN  (None, 19, 19, 198)  792        ['conv2d_19[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_18 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_28[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_9 (DepthwiseC  (None, 19, 19, 198)  1782       ['activation_18[0][0]']          \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_29 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_9[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_19 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_29[0][0]'] \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_19[0][0]']          \n","                                                                                                  \n"," batch_normalization_30 (BatchN  (None, 19, 19, 64)  256         ['conv2d_20[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_9 (Add)                    (None, 19, 19, 64)   0           ['batch_normalization_30[0][0]', \n","                                                                  'add_8[0][0]']                  \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 19, 19, 198)  12672       ['add_9[0][0]']                  \n","                                                                                                  \n"," batch_normalization_31 (BatchN  (None, 19, 19, 198)  792        ['conv2d_21[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_20 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_31[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_10 (Depthwise  (None, 19, 19, 198)  1782       ['activation_20[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_32 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_10[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_21 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_32[0][0]'] \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_21[0][0]']          \n","                                                                                                  \n"," batch_normalization_33 (BatchN  (None, 19, 19, 64)  256         ['conv2d_22[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_10 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_33[0][0]', \n","                                                                  'add_9[0][0]']                  \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 19, 19, 198)  12672       ['add_10[0][0]']                 \n","                                                                                                  \n"," batch_normalization_34 (BatchN  (None, 19, 19, 198)  792        ['conv2d_23[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_22 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_34[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_11 (Depthwise  (None, 19, 19, 198)  1782       ['activation_22[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_35 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_11[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_23 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_35[0][0]'] \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_23[0][0]']          \n","                                                                                                  \n"," batch_normalization_36 (BatchN  (None, 19, 19, 64)  256         ['conv2d_24[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_11 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_36[0][0]', \n","                                                                  'add_10[0][0]']                 \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 19, 19, 198)  12672       ['add_11[0][0]']                 \n","                                                                                                  \n"," batch_normalization_37 (BatchN  (None, 19, 19, 198)  792        ['conv2d_25[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_24 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_37[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_12 (Depthwise  (None, 19, 19, 198)  1782       ['activation_24[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_38 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_12[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_25 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_38[0][0]'] \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_25[0][0]']          \n","                                                                                                  \n"," batch_normalization_39 (BatchN  (None, 19, 19, 64)  256         ['conv2d_26[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_12 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_39[0][0]', \n","                                                                  'add_11[0][0]']                 \n","                                                                                                  \n"," conv2d_27 (Conv2D)             (None, 19, 19, 198)  12672       ['add_12[0][0]']                 \n","                                                                                                  \n"," batch_normalization_40 (BatchN  (None, 19, 19, 198)  792        ['conv2d_27[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_26 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_40[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_13 (Depthwise  (None, 19, 19, 198)  1782       ['activation_26[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_41 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_13[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_27 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_41[0][0]'] \n","                                                                                                  \n"," conv2d_28 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_27[0][0]']          \n","                                                                                                  \n"," batch_normalization_42 (BatchN  (None, 19, 19, 64)  256         ['conv2d_28[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_13 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_42[0][0]', \n","                                                                  'add_12[0][0]']                 \n","                                                                                                  \n"," conv2d_29 (Conv2D)             (None, 19, 19, 198)  12672       ['add_13[0][0]']                 \n","                                                                                                  \n"," batch_normalization_43 (BatchN  (None, 19, 19, 198)  792        ['conv2d_29[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_28 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_43[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_14 (Depthwise  (None, 19, 19, 198)  1782       ['activation_28[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_44 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_14[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_29 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_44[0][0]'] \n","                                                                                                  \n"," conv2d_30 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_29[0][0]']          \n","                                                                                                  \n"," batch_normalization_45 (BatchN  (None, 19, 19, 64)  256         ['conv2d_30[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_14 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_45[0][0]', \n","                                                                  'add_13[0][0]']                 \n","                                                                                                  \n"," conv2d_31 (Conv2D)             (None, 19, 19, 198)  12672       ['add_14[0][0]']                 \n","                                                                                                  \n"," batch_normalization_46 (BatchN  (None, 19, 19, 198)  792        ['conv2d_31[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_30 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_46[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_15 (Depthwise  (None, 19, 19, 198)  1782       ['activation_30[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_47 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_15[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_31 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_47[0][0]'] \n","                                                                                                  \n"," conv2d_32 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_31[0][0]']          \n","                                                                                                  \n"," batch_normalization_48 (BatchN  (None, 19, 19, 64)  256         ['conv2d_32[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_15 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_48[0][0]', \n","                                                                  'add_14[0][0]']                 \n","                                                                                                  \n"," conv2d_33 (Conv2D)             (None, 19, 19, 198)  12672       ['add_15[0][0]']                 \n","                                                                                                  \n"," batch_normalization_49 (BatchN  (None, 19, 19, 198)  792        ['conv2d_33[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_32 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_49[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_16 (Depthwise  (None, 19, 19, 198)  1782       ['activation_32[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_50 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_16[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_33 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_50[0][0]'] \n","                                                                                                  \n"," conv2d_34 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_33[0][0]']          \n","                                                                                                  \n"," batch_normalization_51 (BatchN  (None, 19, 19, 64)  256         ['conv2d_34[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_16 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_51[0][0]', \n","                                                                  'add_15[0][0]']                 \n","                                                                                                  \n"," conv2d_35 (Conv2D)             (None, 19, 19, 198)  12672       ['add_16[0][0]']                 \n","                                                                                                  \n"," batch_normalization_52 (BatchN  (None, 19, 19, 198)  792        ['conv2d_35[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_34 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_52[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_17 (Depthwise  (None, 19, 19, 198)  1782       ['activation_34[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_53 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_17[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_35 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_53[0][0]'] \n","                                                                                                  \n"," conv2d_36 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_35[0][0]']          \n","                                                                                                  \n"," batch_normalization_54 (BatchN  (None, 19, 19, 64)  256         ['conv2d_36[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_17 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_54[0][0]', \n","                                                                  'add_16[0][0]']                 \n","                                                                                                  \n"," conv2d_37 (Conv2D)             (None, 19, 19, 198)  12672       ['add_17[0][0]']                 \n","                                                                                                  \n"," batch_normalization_55 (BatchN  (None, 19, 19, 198)  792        ['conv2d_37[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_36 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_55[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_18 (Depthwise  (None, 19, 19, 198)  1782       ['activation_36[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_56 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_18[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_37 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_56[0][0]'] \n","                                                                                                  \n"," conv2d_38 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_37[0][0]']          \n","                                                                                                  \n"," batch_normalization_57 (BatchN  (None, 19, 19, 64)  256         ['conv2d_38[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_18 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_57[0][0]', \n","                                                                  'add_17[0][0]']                 \n","                                                                                                  \n"," conv2d_39 (Conv2D)             (None, 19, 19, 198)  12672       ['add_18[0][0]']                 \n","                                                                                                  \n"," batch_normalization_58 (BatchN  (None, 19, 19, 198)  792        ['conv2d_39[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_38 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_58[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_19 (Depthwise  (None, 19, 19, 198)  1782       ['activation_38[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_59 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_19[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_39 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_59[0][0]'] \n","                                                                                                  \n"," conv2d_40 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_39[0][0]']          \n","                                                                                                  \n"," batch_normalization_60 (BatchN  (None, 19, 19, 64)  256         ['conv2d_40[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_19 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_60[0][0]', \n","                                                                  'add_18[0][0]']                 \n","                                                                                                  \n"," conv2d_41 (Conv2D)             (None, 19, 19, 198)  12672       ['add_19[0][0]']                 \n","                                                                                                  \n"," batch_normalization_61 (BatchN  (None, 19, 19, 198)  792        ['conv2d_41[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_40 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_61[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_20 (Depthwise  (None, 19, 19, 198)  1782       ['activation_40[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_62 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_20[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_41 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_62[0][0]'] \n","                                                                                                  \n"," conv2d_42 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_41[0][0]']          \n","                                                                                                  \n"," batch_normalization_63 (BatchN  (None, 19, 19, 64)  256         ['conv2d_42[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_20 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_63[0][0]', \n","                                                                  'add_19[0][0]']                 \n","                                                                                                  \n"," conv2d_43 (Conv2D)             (None, 19, 19, 198)  12672       ['add_20[0][0]']                 \n","                                                                                                  \n"," batch_normalization_64 (BatchN  (None, 19, 19, 198)  792        ['conv2d_43[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_42 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_64[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_21 (Depthwise  (None, 19, 19, 198)  1782       ['activation_42[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_65 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_21[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_43 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_65[0][0]'] \n","                                                                                                  \n"," conv2d_44 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_43[0][0]']          \n","                                                                                                  \n"," batch_normalization_66 (BatchN  (None, 19, 19, 64)  256         ['conv2d_44[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_21 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_66[0][0]', \n","                                                                  'add_20[0][0]']                 \n","                                                                                                  \n"," conv2d_45 (Conv2D)             (None, 19, 19, 198)  12672       ['add_21[0][0]']                 \n","                                                                                                  \n"," batch_normalization_67 (BatchN  (None, 19, 19, 198)  792        ['conv2d_45[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_44 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_67[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_22 (Depthwise  (None, 19, 19, 198)  1782       ['activation_44[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_68 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_22[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_45 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_68[0][0]'] \n","                                                                                                  \n"," conv2d_46 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_45[0][0]']          \n","                                                                                                  \n"," batch_normalization_69 (BatchN  (None, 19, 19, 64)  256         ['conv2d_46[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_22 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_69[0][0]', \n","                                                                  'add_21[0][0]']                 \n","                                                                                                  \n"," conv2d_47 (Conv2D)             (None, 19, 19, 198)  12672       ['add_22[0][0]']                 \n","                                                                                                  \n"," batch_normalization_70 (BatchN  (None, 19, 19, 198)  792        ['conv2d_47[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_46 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_70[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_23 (Depthwise  (None, 19, 19, 198)  1782       ['activation_46[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_71 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_23[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_47 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_71[0][0]'] \n","                                                                                                  \n"," conv2d_48 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_47[0][0]']          \n","                                                                                                  \n"," batch_normalization_72 (BatchN  (None, 19, 19, 64)  256         ['conv2d_48[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_23 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_72[0][0]', \n","                                                                  'add_22[0][0]']                 \n","                                                                                                  \n"," conv2d_49 (Conv2D)             (None, 19, 19, 198)  12672       ['add_23[0][0]']                 \n","                                                                                                  \n"," batch_normalization_73 (BatchN  (None, 19, 19, 198)  792        ['conv2d_49[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_48 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_73[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_24 (Depthwise  (None, 19, 19, 198)  1782       ['activation_48[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_74 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_24[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_49 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_74[0][0]'] \n","                                                                                                  \n"," conv2d_50 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_49[0][0]']          \n","                                                                                                  \n"," batch_normalization_75 (BatchN  (None, 19, 19, 64)  256         ['conv2d_50[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_24 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_75[0][0]', \n","                                                                  'add_23[0][0]']                 \n","                                                                                                  \n"," conv2d_51 (Conv2D)             (None, 19, 19, 198)  12672       ['add_24[0][0]']                 \n","                                                                                                  \n"," batch_normalization_76 (BatchN  (None, 19, 19, 198)  792        ['conv2d_51[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_50 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_76[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_25 (Depthwise  (None, 19, 19, 198)  1782       ['activation_50[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_77 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_25[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_51 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_77[0][0]'] \n","                                                                                                  \n"," conv2d_52 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_51[0][0]']          \n","                                                                                                  \n"," batch_normalization_78 (BatchN  (None, 19, 19, 64)  256         ['conv2d_52[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_25 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_78[0][0]', \n","                                                                  'add_24[0][0]']                 \n","                                                                                                  \n"," conv2d_53 (Conv2D)             (None, 19, 19, 198)  12672       ['add_25[0][0]']                 \n","                                                                                                  \n"," batch_normalization_79 (BatchN  (None, 19, 19, 198)  792        ['conv2d_53[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_52 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_79[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_26 (Depthwise  (None, 19, 19, 198)  1782       ['activation_52[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_80 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_26[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_53 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_80[0][0]'] \n","                                                                                                  \n"," conv2d_54 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_53[0][0]']          \n","                                                                                                  \n"," batch_normalization_81 (BatchN  (None, 19, 19, 64)  256         ['conv2d_54[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_26 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_81[0][0]', \n","                                                                  'add_25[0][0]']                 \n","                                                                                                  \n"," conv2d_55 (Conv2D)             (None, 19, 19, 198)  12672       ['add_26[0][0]']                 \n","                                                                                                  \n"," batch_normalization_82 (BatchN  (None, 19, 19, 198)  792        ['conv2d_55[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_54 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_82[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_27 (Depthwise  (None, 19, 19, 198)  1782       ['activation_54[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_83 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_27[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_55 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_83[0][0]'] \n","                                                                                                  \n"," conv2d_56 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_55[0][0]']          \n","                                                                                                  \n"," batch_normalization_84 (BatchN  (None, 19, 19, 64)  256         ['conv2d_56[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_27 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_84[0][0]', \n","                                                                  'add_26[0][0]']                 \n","                                                                                                  \n"," conv2d_57 (Conv2D)             (None, 19, 19, 198)  12672       ['add_27[0][0]']                 \n","                                                                                                  \n"," batch_normalization_85 (BatchN  (None, 19, 19, 198)  792        ['conv2d_57[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_56 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_85[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_28 (Depthwise  (None, 19, 19, 198)  1782       ['activation_56[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_86 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_28[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_57 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_86[0][0]'] \n","                                                                                                  \n"," conv2d_58 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_57[0][0]']          \n","                                                                                                  \n"," batch_normalization_87 (BatchN  (None, 19, 19, 64)  256         ['conv2d_58[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_28 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_87[0][0]', \n","                                                                  'add_27[0][0]']                 \n","                                                                                                  \n"," conv2d_59 (Conv2D)             (None, 19, 19, 198)  12672       ['add_28[0][0]']                 \n","                                                                                                  \n"," batch_normalization_88 (BatchN  (None, 19, 19, 198)  792        ['conv2d_59[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_58 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_88[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_29 (Depthwise  (None, 19, 19, 198)  1782       ['activation_58[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_89 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_29[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_59 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_89[0][0]'] \n","                                                                                                  \n"," conv2d_60 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_59[0][0]']          \n","                                                                                                  \n"," batch_normalization_90 (BatchN  (None, 19, 19, 64)  256         ['conv2d_60[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_29 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_90[0][0]', \n","                                                                  'add_28[0][0]']                 \n","                                                                                                  \n"," conv2d_61 (Conv2D)             (None, 19, 19, 198)  12672       ['add_29[0][0]']                 \n","                                                                                                  \n"," batch_normalization_91 (BatchN  (None, 19, 19, 198)  792        ['conv2d_61[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_60 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_91[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_30 (Depthwise  (None, 19, 19, 198)  1782       ['activation_60[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_92 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_30[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_61 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_92[0][0]'] \n","                                                                                                  \n"," conv2d_62 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_61[0][0]']          \n","                                                                                                  \n"," batch_normalization_93 (BatchN  (None, 19, 19, 64)  256         ['conv2d_62[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_30 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_93[0][0]', \n","                                                                  'add_29[0][0]']                 \n","                                                                                                  \n"," conv2d_63 (Conv2D)             (None, 19, 19, 198)  12672       ['add_30[0][0]']                 \n","                                                                                                  \n"," batch_normalization_94 (BatchN  (None, 19, 19, 198)  792        ['conv2d_63[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_62 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_94[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_31 (Depthwise  (None, 19, 19, 198)  1782       ['activation_62[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_95 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_31[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_63 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_95[0][0]'] \n","                                                                                                  \n"," conv2d_64 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_63[0][0]']          \n","                                                                                                  \n"," batch_normalization_96 (BatchN  (None, 19, 19, 64)  256         ['conv2d_64[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_31 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_96[0][0]', \n","                                                                  'add_30[0][0]']                 \n","                                                                                                  \n"," conv2d_65 (Conv2D)             (None, 19, 19, 198)  12672       ['add_31[0][0]']                 \n","                                                                                                  \n"," batch_normalization_97 (BatchN  (None, 19, 19, 198)  792        ['conv2d_65[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_64 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_97[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_32 (Depthwise  (None, 19, 19, 198)  1782       ['activation_64[0][0]']          \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_98 (BatchN  (None, 19, 19, 198)  792        ['depthwise_conv2d_32[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_65 (Activation)     (None, 19, 19, 198)  0           ['batch_normalization_98[0][0]'] \n","                                                                                                  \n"," conv2d_66 (Conv2D)             (None, 19, 19, 64)   12672       ['activation_65[0][0]']          \n","                                                                                                  \n"," batch_normalization_99 (BatchN  (None, 19, 19, 64)  256         ['conv2d_66[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_32 (Add)                   (None, 19, 19, 64)   0           ['batch_normalization_99[0][0]', \n","                                                                  'add_31[0][0]']                 \n","                                                                                                  \n"," conv2d_67 (Conv2D)             (None, 19, 19, 1)    64          ['add_32[0][0]']                 \n","                                                                                                  \n"," global_average_pooling2d (Glob  (None, 64)          0           ['add_32[0][0]']                 \n"," alAveragePooling2D)                                                                              \n","                                                                                                  \n"," flatten (Flatten)              (None, 361)          0           ['conv2d_67[0][0]']              \n","                                                                                                  \n"," dense (Dense)                  (None, 50)           3250        ['global_average_pooling2d[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," policy (Activation)            (None, 361)          0           ['flatten[0][0]']                \n","                                                                                                  \n"," value (Dense)                  (None, 1)            51          ['dense[0][0]']                  \n","                                                                                                  \n","==================================================================================================\n","Total params: 961,547\n","Trainable params: 931,059\n","Non-trainable params: 30,488\n","__________________________________________________________________________________________________\n","epoch 1\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-11 22:38:42.541390: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","2023-01-11 22:38:42.854238: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 14440000 exceeds 10% of free system memory.\n","2023-01-11 22:38:59.290516: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n","2023-01-11 22:39:04.363221: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x11308bc00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-01-11 22:39:04.363570: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2023-01-11 22:39:04.629847: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","157/157 [==============================] - 56s 194ms/step - loss: 13.8134 - policy_loss: 6.1953 - value_loss: 0.7485 - policy_categorical_accuracy: 0.0049 - value_mse: 0.1395\n","epoch 2\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-11 22:39:40.331400: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","2023-01-11 22:39:40.636115: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 14440000 exceeds 10% of free system memory.\n","157/157 [==============================] - 31s 195ms/step - loss: 13.1467 - policy_loss: 5.8890 - value_loss: 0.6930 - policy_categorical_accuracy: 0.0050 - value_mse: 0.1186\n","epoch 3\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-11 22:40:12.760975: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","157/157 [==============================] - 31s 198ms/step - loss: 12.8353 - policy_loss: 5.7355 - value_loss: 0.6903 - policy_categorical_accuracy: 0.0167 - value_mse: 0.1187\n","epoch 4\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 31s 200ms/step - loss: 9.8143 - policy_loss: 4.2232 - value_loss: 0.6926 - policy_categorical_accuracy: 0.1500 - value_mse: 0.1204\n","epoch 5\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 8.7405 - policy_loss: 3.6866 - value_loss: 0.6912 - policy_categorical_accuracy: 0.2190 - value_mse: 0.1185\n","epoch 6\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 8.1874 - policy_loss: 3.4120 - value_loss: 0.6874 - policy_categorical_accuracy: 0.2562 - value_mse: 0.1151\n","epoch 7\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 7.9625 - policy_loss: 3.2989 - value_loss: 0.6891 - policy_categorical_accuracy: 0.2634 - value_mse: 0.1181\n","epoch 8\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 7.6916 - policy_loss: 3.1643 - value_loss: 0.6882 - policy_categorical_accuracy: 0.2825 - value_mse: 0.1174\n","epoch 9\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 7.4969 - policy_loss: 3.0671 - value_loss: 0.6886 - policy_categorical_accuracy: 0.3027 - value_mse: 0.1167\n","epoch 10\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 7.4670 - policy_loss: 3.0537 - value_loss: 0.6864 - policy_categorical_accuracy: 0.2962 - value_mse: 0.1157\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [7.567783355712891, 3.1017584800720215, 0.691696286201477, 0.29120001196861267, 0.11927900463342667]\n","epoch 11\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 7.3415 - policy_loss: 2.9912 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3037 - value_mse: 0.1181\n","epoch 12\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 7.2780 - policy_loss: 2.9606 - value_loss: 0.6857 - policy_categorical_accuracy: 0.3161 - value_mse: 0.1166\n","epoch 13\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 7.1913 - policy_loss: 2.9184 - value_loss: 0.6845 - policy_categorical_accuracy: 0.3186 - value_mse: 0.1148\n","epoch 14\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 7.1628 - policy_loss: 2.9043 - value_loss: 0.6853 - policy_categorical_accuracy: 0.3187 - value_mse: 0.1138\n","epoch 15\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 7.1772 - policy_loss: 2.9135 - value_loss: 0.6824 - policy_categorical_accuracy: 0.3179 - value_mse: 0.1150\n","epoch 16\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 205ms/step - loss: 7.1451 - policy_loss: 2.8996 - value_loss: 0.6794 - policy_categorical_accuracy: 0.3236 - value_mse: 0.1116\n","epoch 17\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 7.1155 - policy_loss: 2.8853 - value_loss: 0.6796 - policy_categorical_accuracy: 0.3183 - value_mse: 0.1117\n","epoch 18\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 7.0268 - policy_loss: 2.8430 - value_loss: 0.6765 - policy_categorical_accuracy: 0.3319 - value_mse: 0.1129\n","epoch 19\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 7.0283 - policy_loss: 2.8448 - value_loss: 0.6758 - policy_categorical_accuracy: 0.3311 - value_mse: 0.1090\n","epoch 20\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.9698 - policy_loss: 2.8160 - value_loss: 0.6760 - policy_categorical_accuracy: 0.3289 - value_mse: 0.1123\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.873331069946289, 2.7671499252319336, 0.6778835654258728, 0.34279999136924744, 0.11249610781669617]\n","epoch 21\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.9262 - policy_loss: 2.7977 - value_loss: 0.6702 - policy_categorical_accuracy: 0.3310 - value_mse: 0.1082\n","epoch 22\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.9081 - policy_loss: 2.7876 - value_loss: 0.6736 - policy_categorical_accuracy: 0.3312 - value_mse: 0.1107\n","epoch 23\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.9019 - policy_loss: 2.7864 - value_loss: 0.6710 - policy_categorical_accuracy: 0.3347 - value_mse: 0.1094\n","epoch 24\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.8965 - policy_loss: 2.7858 - value_loss: 0.6679 - policy_categorical_accuracy: 0.3414 - value_mse: 0.1079\n","epoch 25\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.8928 - policy_loss: 2.7806 - value_loss: 0.6759 - policy_categorical_accuracy: 0.3376 - value_mse: 0.1105\n","epoch 26\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.8811 - policy_loss: 2.7778 - value_loss: 0.6710 - policy_categorical_accuracy: 0.3339 - value_mse: 0.1077\n","epoch 27\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.7569 - policy_loss: 2.7161 - value_loss: 0.6716 - policy_categorical_accuracy: 0.3395 - value_mse: 0.1105\n","epoch 28\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.7715 - policy_loss: 2.7233 - value_loss: 0.6729 - policy_categorical_accuracy: 0.3499 - value_mse: 0.1094\n","epoch 29\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.7532 - policy_loss: 2.7159 - value_loss: 0.6707 - policy_categorical_accuracy: 0.3488 - value_mse: 0.1078\n","epoch 30\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.6636 - policy_loss: 2.6733 - value_loss: 0.6675 - policy_categorical_accuracy: 0.3486 - value_mse: 0.1074\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.679184436798096, 2.675283193588257, 0.6797719597816467, 0.35089999437332153, 0.11313921213150024]\n","epoch 31\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.7463 - policy_loss: 2.7149 - value_loss: 0.6683 - policy_categorical_accuracy: 0.3388 - value_mse: 0.1064\n","epoch 32\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.6988 - policy_loss: 2.6921 - value_loss: 0.6675 - policy_categorical_accuracy: 0.3498 - value_mse: 0.1061\n","epoch 33\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.7521 - policy_loss: 2.7175 - value_loss: 0.6713 - policy_categorical_accuracy: 0.3495 - value_mse: 0.1077\n","epoch 34\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.7032 - policy_loss: 2.6962 - value_loss: 0.6661 - policy_categorical_accuracy: 0.3449 - value_mse: 0.1071\n","epoch 35\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.6398 - policy_loss: 2.6639 - value_loss: 0.6687 - policy_categorical_accuracy: 0.3605 - value_mse: 0.1065\n","epoch 36\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.6827 - policy_loss: 2.6869 - value_loss: 0.6668 - policy_categorical_accuracy: 0.3521 - value_mse: 0.1079\n","epoch 37\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.6371 - policy_loss: 2.6670 - value_loss: 0.6623 - policy_categorical_accuracy: 0.3537 - value_mse: 0.1055\n","epoch 38\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.6987 - policy_loss: 2.6952 - value_loss: 0.6687 - policy_categorical_accuracy: 0.3493 - value_mse: 0.1088\n","epoch 39\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.6395 - policy_loss: 2.6665 - value_loss: 0.6683 - policy_categorical_accuracy: 0.3464 - value_mse: 0.1074\n","epoch 40\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.6206 - policy_loss: 2.6589 - value_loss: 0.6658 - policy_categorical_accuracy: 0.3562 - value_mse: 0.1041\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.543024063110352, 2.614337205886841, 0.6778697967529297, 0.36039999127388, 0.11271785944700241]\n","epoch 41\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.5907 - policy_loss: 2.6428 - value_loss: 0.6692 - policy_categorical_accuracy: 0.3528 - value_mse: 0.1073\n","epoch 42\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.5737 - policy_loss: 2.6372 - value_loss: 0.6646 - policy_categorical_accuracy: 0.3565 - value_mse: 0.1073\n","epoch 43\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.4523 - policy_loss: 2.5761 - value_loss: 0.6665 - policy_categorical_accuracy: 0.3683 - value_mse: 0.1063\n","epoch 44\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.4825 - policy_loss: 2.5914 - value_loss: 0.6674 - policy_categorical_accuracy: 0.3669 - value_mse: 0.1068\n","epoch 45\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.5312 - policy_loss: 2.6172 - value_loss: 0.6658 - policy_categorical_accuracy: 0.3627 - value_mse: 0.1060\n","epoch 46\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.5402 - policy_loss: 2.6224 - value_loss: 0.6656 - policy_categorical_accuracy: 0.3583 - value_mse: 0.1061\n","epoch 47\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.4642 - policy_loss: 2.5830 - value_loss: 0.6697 - policy_categorical_accuracy: 0.3710 - value_mse: 0.1097\n","epoch 48\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.5098 - policy_loss: 2.6071 - value_loss: 0.6682 - policy_categorical_accuracy: 0.3565 - value_mse: 0.1090\n","epoch 49\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.4771 - policy_loss: 2.5940 - value_loss: 0.6628 - policy_categorical_accuracy: 0.3620 - value_mse: 0.1063\n","epoch 50\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.4358 - policy_loss: 2.5738 - value_loss: 0.6632 - policy_categorical_accuracy: 0.3695 - value_mse: 0.1063\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.426992893218994, 2.5691425800323486, 0.6643555760383606, 0.3714999854564667, 0.10647504776716232]\n","epoch 51\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.5121 - policy_loss: 2.6139 - value_loss: 0.6607 - policy_categorical_accuracy: 0.3612 - value_mse: 0.1058\n","epoch 52\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.4888 - policy_loss: 2.6009 - value_loss: 0.6645 - policy_categorical_accuracy: 0.3587 - value_mse: 0.1037\n","epoch 53\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.5219 - policy_loss: 2.6184 - value_loss: 0.6638 - policy_categorical_accuracy: 0.3555 - value_mse: 0.1053\n","epoch 54\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.4387 - policy_loss: 2.5776 - value_loss: 0.6634 - policy_categorical_accuracy: 0.3619 - value_mse: 0.1047\n","epoch 55\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.4951 - policy_loss: 2.6065 - value_loss: 0.6632 - policy_categorical_accuracy: 0.3621 - value_mse: 0.1053\n","epoch 56\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.4698 - policy_loss: 2.5933 - value_loss: 0.6655 - policy_categorical_accuracy: 0.3619 - value_mse: 0.1070\n","epoch 57\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.4459 - policy_loss: 2.5810 - value_loss: 0.6673 - policy_categorical_accuracy: 0.3627 - value_mse: 0.1089\n","epoch 58\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.4548 - policy_loss: 2.5875 - value_loss: 0.6644 - policy_categorical_accuracy: 0.3628 - value_mse: 0.1063\n","epoch 59\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.4132 - policy_loss: 2.5661 - value_loss: 0.6669 - policy_categorical_accuracy: 0.3691 - value_mse: 0.1076\n","epoch 60\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.4168 - policy_loss: 2.5724 - value_loss: 0.6591 - policy_categorical_accuracy: 0.3681 - value_mse: 0.1037\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.332542419433594, 2.529021739959717, 0.6621779799461365, 0.3716999888420105, 0.10535650700330734]\n","epoch 61\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.4023 - policy_loss: 2.5638 - value_loss: 0.6629 - policy_categorical_accuracy: 0.3690 - value_mse: 0.1058\n","epoch 62\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.4017 - policy_loss: 2.5648 - value_loss: 0.6615 - policy_categorical_accuracy: 0.3672 - value_mse: 0.1048\n","epoch 63\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.3277 - policy_loss: 2.5272 - value_loss: 0.6639 - policy_categorical_accuracy: 0.3759 - value_mse: 0.1042\n","epoch 64\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.4316 - policy_loss: 2.5800 - value_loss: 0.6635 - policy_categorical_accuracy: 0.3645 - value_mse: 0.1059\n","epoch 65\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.4061 - policy_loss: 2.5691 - value_loss: 0.6609 - policy_categorical_accuracy: 0.3643 - value_mse: 0.1052\n","epoch 66\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.3439 - policy_loss: 2.5404 - value_loss: 0.6573 - policy_categorical_accuracy: 0.3726 - value_mse: 0.1021\n","epoch 67\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.3469 - policy_loss: 2.5383 - value_loss: 0.6656 - policy_categorical_accuracy: 0.3729 - value_mse: 0.1050\n","epoch 68\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.3599 - policy_loss: 2.5468 - value_loss: 0.6627 - policy_categorical_accuracy: 0.3675 - value_mse: 0.1049\n","epoch 69\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.3841 - policy_loss: 2.5621 - value_loss: 0.6574 - policy_categorical_accuracy: 0.3616 - value_mse: 0.1032\n","epoch 70\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.3457 - policy_loss: 2.5417 - value_loss: 0.6611 - policy_categorical_accuracy: 0.3714 - value_mse: 0.1045\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.324320316314697, 2.527895927429199, 0.6678664088249207, 0.36980000138282776, 0.10800597071647644]\n","epoch 71\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.3946 - policy_loss: 2.5662 - value_loss: 0.6620 - policy_categorical_accuracy: 0.3639 - value_mse: 0.1050\n","epoch 72\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.2944 - policy_loss: 2.5194 - value_loss: 0.6566 - policy_categorical_accuracy: 0.3735 - value_mse: 0.1025\n","epoch 73\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.3325 - policy_loss: 2.5361 - value_loss: 0.6626 - policy_categorical_accuracy: 0.3653 - value_mse: 0.1034\n","epoch 74\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.2756 - policy_loss: 2.5090 - value_loss: 0.6609 - policy_categorical_accuracy: 0.3791 - value_mse: 0.1023\n","epoch 75\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.2700 - policy_loss: 2.5057 - value_loss: 0.6630 - policy_categorical_accuracy: 0.3727 - value_mse: 0.1046\n","epoch 76\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.3045 - policy_loss: 2.5239 - value_loss: 0.6623 - policy_categorical_accuracy: 0.3803 - value_mse: 0.1032\n","epoch 77\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.3202 - policy_loss: 2.5316 - value_loss: 0.6636 - policy_categorical_accuracy: 0.3670 - value_mse: 0.1054\n","epoch 78\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.2223 - policy_loss: 2.4845 - value_loss: 0.6612 - policy_categorical_accuracy: 0.3741 - value_mse: 0.1043\n","epoch 79\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.3462 - policy_loss: 2.5501 - value_loss: 0.6549 - policy_categorical_accuracy: 0.3686 - value_mse: 0.1012\n","epoch 80\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.3026 - policy_loss: 2.5255 - value_loss: 0.6617 - policy_categorical_accuracy: 0.3726 - value_mse: 0.1051\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.326052188873291, 2.528611421585083, 0.6794325709342957, 0.3693000078201294, 0.11290891468524933]\n","epoch 81\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.2777 - policy_loss: 2.5150 - value_loss: 0.6589 - policy_categorical_accuracy: 0.3705 - value_mse: 0.1024\n","epoch 82\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.3366 - policy_loss: 2.5437 - value_loss: 0.6615 - policy_categorical_accuracy: 0.3685 - value_mse: 0.1033\n","epoch 83\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.2908 - policy_loss: 2.5208 - value_loss: 0.6626 - policy_categorical_accuracy: 0.3664 - value_mse: 0.1052\n","epoch 84\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.2646 - policy_loss: 2.5097 - value_loss: 0.6596 - policy_categorical_accuracy: 0.3746 - value_mse: 0.1025\n","epoch 85\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.2191 - policy_loss: 2.4882 - value_loss: 0.6583 - policy_categorical_accuracy: 0.3766 - value_mse: 0.1022\n","epoch 86\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.2261 - policy_loss: 2.4922 - value_loss: 0.6584 - policy_categorical_accuracy: 0.3760 - value_mse: 0.1037\n","epoch 87\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.1733 - policy_loss: 2.4670 - value_loss: 0.6571 - policy_categorical_accuracy: 0.3766 - value_mse: 0.1035\n","epoch 88\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.1696 - policy_loss: 2.4652 - value_loss: 0.6581 - policy_categorical_accuracy: 0.3749 - value_mse: 0.1044\n","epoch 89\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.2788 - policy_loss: 2.5206 - value_loss: 0.6575 - policy_categorical_accuracy: 0.3721 - value_mse: 0.1032\n","epoch 90\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.1723 - policy_loss: 2.4700 - value_loss: 0.6532 - policy_categorical_accuracy: 0.3828 - value_mse: 0.1025\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.132330894470215, 2.4505372047424316, 0.6528530120849609, 0.3815000057220459, 0.10129596292972565]\n","epoch 91\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.2548 - policy_loss: 2.5096 - value_loss: 0.6578 - policy_categorical_accuracy: 0.3727 - value_mse: 0.1034\n","epoch 92\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.2581 - policy_loss: 2.5114 - value_loss: 0.6586 - policy_categorical_accuracy: 0.3711 - value_mse: 0.1027\n","epoch 93\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.1507 - policy_loss: 2.4573 - value_loss: 0.6604 - policy_categorical_accuracy: 0.3827 - value_mse: 0.1040\n","epoch 94\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.1924 - policy_loss: 2.4817 - value_loss: 0.6542 - policy_categorical_accuracy: 0.3696 - value_mse: 0.1022\n","epoch 95\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.2277 - policy_loss: 2.4977 - value_loss: 0.6587 - policy_categorical_accuracy: 0.3682 - value_mse: 0.1031\n","epoch 96\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.2108 - policy_loss: 2.4916 - value_loss: 0.6550 - policy_categorical_accuracy: 0.3770 - value_mse: 0.1015\n","epoch 97\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.1732 - policy_loss: 2.4714 - value_loss: 0.6589 - policy_categorical_accuracy: 0.3756 - value_mse: 0.1038\n","epoch 98\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.2162 - policy_loss: 2.4962 - value_loss: 0.6533 - policy_categorical_accuracy: 0.3769 - value_mse: 0.1022\n","epoch 99\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.2038 - policy_loss: 2.4901 - value_loss: 0.6541 - policy_categorical_accuracy: 0.3739 - value_mse: 0.1017\n","epoch 100\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.1639 - policy_loss: 2.4689 - value_loss: 0.6577 - policy_categorical_accuracy: 0.3784 - value_mse: 0.1030\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.084719657897949, 2.427208423614502, 0.6625014543533325, 0.3822000026702881, 0.10493184626102448]\n","epoch 101\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.1540 - policy_loss: 2.4644 - value_loss: 0.6579 - policy_categorical_accuracy: 0.3725 - value_mse: 0.1029\n","epoch 102\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.1602 - policy_loss: 2.4670 - value_loss: 0.6599 - policy_categorical_accuracy: 0.3796 - value_mse: 0.1026\n","epoch 103\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.1206 - policy_loss: 2.4476 - value_loss: 0.6601 - policy_categorical_accuracy: 0.3811 - value_mse: 0.1040\n","epoch 104\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.1106 - policy_loss: 2.4462 - value_loss: 0.6540 - policy_categorical_accuracy: 0.3783 - value_mse: 0.1009\n","epoch 105\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.1593 - policy_loss: 2.4702 - value_loss: 0.6557 - policy_categorical_accuracy: 0.3738 - value_mse: 0.1017\n","epoch 106\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.1700 - policy_loss: 2.4758 - value_loss: 0.6562 - policy_categorical_accuracy: 0.3779 - value_mse: 0.1018\n","epoch 107\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.1327 - policy_loss: 2.4573 - value_loss: 0.6570 - policy_categorical_accuracy: 0.3777 - value_mse: 0.1045\n","epoch 108\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.1100 - policy_loss: 2.4461 - value_loss: 0.6577 - policy_categorical_accuracy: 0.3789 - value_mse: 0.1035\n","epoch 109\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.1841 - policy_loss: 2.4843 - value_loss: 0.6564 - policy_categorical_accuracy: 0.3728 - value_mse: 0.1031\n","epoch 110\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.0764 - policy_loss: 2.4307 - value_loss: 0.6570 - policy_categorical_accuracy: 0.3883 - value_mse: 0.1025\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [6.083718776702881, 2.4315130710601807, 0.6631518006324768, 0.3887999951839447, 0.10547018051147461]\n","epoch 111\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.1424 - policy_loss: 2.4651 - value_loss: 0.6552 - policy_categorical_accuracy: 0.3742 - value_mse: 0.0991\n","epoch 112\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.0808 - policy_loss: 2.4379 - value_loss: 0.6490 - policy_categorical_accuracy: 0.3831 - value_mse: 0.0997\n","epoch 113\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.0811 - policy_loss: 2.4379 - value_loss: 0.6501 - policy_categorical_accuracy: 0.3818 - value_mse: 0.1004\n","epoch 114\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.1097 - policy_loss: 2.4509 - value_loss: 0.6538 - policy_categorical_accuracy: 0.3841 - value_mse: 0.1004\n","epoch 115\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.1134 - policy_loss: 2.4527 - value_loss: 0.6549 - policy_categorical_accuracy: 0.3835 - value_mse: 0.0998\n","epoch 116\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.0190 - policy_loss: 2.4075 - value_loss: 0.6519 - policy_categorical_accuracy: 0.3892 - value_mse: 0.1016\n","epoch 117\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.1014 - policy_loss: 2.4501 - value_loss: 0.6500 - policy_categorical_accuracy: 0.3862 - value_mse: 0.1005\n","epoch 118\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.1118 - policy_loss: 2.4541 - value_loss: 0.6535 - policy_categorical_accuracy: 0.3837 - value_mse: 0.1000\n","epoch 119\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.0827 - policy_loss: 2.4406 - value_loss: 0.6523 - policy_categorical_accuracy: 0.3824 - value_mse: 0.0984\n","epoch 120\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 6.0372 - policy_loss: 2.4189 - value_loss: 0.6513 - policy_categorical_accuracy: 0.3849 - value_mse: 0.0992\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.959475040435791, 2.3815016746520996, 0.6487807631492615, 0.3910999894142151, 0.0993296205997467]\n","epoch 121\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.0838 - policy_loss: 2.4419 - value_loss: 0.6529 - policy_categorical_accuracy: 0.3871 - value_mse: 0.1003\n","epoch 122\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.0326 - policy_loss: 2.4162 - value_loss: 0.6540 - policy_categorical_accuracy: 0.3858 - value_mse: 0.1005\n","epoch 123\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.0290 - policy_loss: 2.4180 - value_loss: 0.6477 - policy_categorical_accuracy: 0.3827 - value_mse: 0.0986\n","epoch 124\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.0724 - policy_loss: 2.4397 - value_loss: 0.6487 - policy_categorical_accuracy: 0.3850 - value_mse: 0.0985\n","epoch 125\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.0016 - policy_loss: 2.4037 - value_loss: 0.6506 - policy_categorical_accuracy: 0.3936 - value_mse: 0.1012\n","epoch 126\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.0559 - policy_loss: 2.4321 - value_loss: 0.6492 - policy_categorical_accuracy: 0.3858 - value_mse: 0.1001\n","epoch 127\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.9628 - policy_loss: 2.3839 - value_loss: 0.6536 - policy_categorical_accuracy: 0.3932 - value_mse: 0.1000\n","epoch 128\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 6.0104 - policy_loss: 2.4100 - value_loss: 0.6497 - policy_categorical_accuracy: 0.3880 - value_mse: 0.0996\n","epoch 129\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.0228 - policy_loss: 2.4159 - value_loss: 0.6513 - policy_categorical_accuracy: 0.3883 - value_mse: 0.0998\n","epoch 130\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.9932 - policy_loss: 2.4032 - value_loss: 0.6483 - policy_categorical_accuracy: 0.3919 - value_mse: 0.1000\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.979374408721924, 2.3967175483703613, 0.647814929485321, 0.39010000228881836, 0.09946852177381516]\n","epoch 131\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.9306 - policy_loss: 2.3717 - value_loss: 0.6494 - policy_categorical_accuracy: 0.3939 - value_mse: 0.1004\n","epoch 132\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 6.0349 - policy_loss: 2.4246 - value_loss: 0.6489 - policy_categorical_accuracy: 0.3834 - value_mse: 0.0995\n","epoch 133\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.9876 - policy_loss: 2.4003 - value_loss: 0.6511 - policy_categorical_accuracy: 0.3873 - value_mse: 0.0998\n","epoch 134\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.9963 - policy_loss: 2.4080 - value_loss: 0.6454 - policy_categorical_accuracy: 0.3853 - value_mse: 0.0962\n","epoch 135\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.9841 - policy_loss: 2.4026 - value_loss: 0.6450 - policy_categorical_accuracy: 0.3883 - value_mse: 0.0969\n","epoch 136\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.9810 - policy_loss: 2.4003 - value_loss: 0.6473 - policy_categorical_accuracy: 0.3858 - value_mse: 0.0975\n","epoch 137\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.9561 - policy_loss: 2.3886 - value_loss: 0.6468 - policy_categorical_accuracy: 0.3917 - value_mse: 0.0962\n","epoch 138\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.9590 - policy_loss: 2.3880 - value_loss: 0.6517 - policy_categorical_accuracy: 0.3875 - value_mse: 0.0995\n","epoch 139\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.9535 - policy_loss: 2.3893 - value_loss: 0.6445 - policy_categorical_accuracy: 0.3893 - value_mse: 0.0970\n","epoch 140\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.9159 - policy_loss: 2.3701 - value_loss: 0.6463 - policy_categorical_accuracy: 0.3964 - value_mse: 0.0989\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.888679504394531, 2.3483498096466064, 0.663033127784729, 0.3937000036239624, 0.10509567707777023]\n","epoch 141\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.9424 - policy_loss: 2.3839 - value_loss: 0.6460 - policy_categorical_accuracy: 0.3884 - value_mse: 0.0991\n","epoch 142\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.9672 - policy_loss: 2.3972 - value_loss: 0.6451 - policy_categorical_accuracy: 0.3881 - value_mse: 0.0987\n","epoch 143\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.9424 - policy_loss: 2.3848 - value_loss: 0.6461 - policy_categorical_accuracy: 0.3875 - value_mse: 0.0982\n","epoch 144\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.9510 - policy_loss: 2.3865 - value_loss: 0.6523 - policy_categorical_accuracy: 0.3897 - value_mse: 0.1013\n","epoch 145\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8910 - policy_loss: 2.3585 - value_loss: 0.6490 - policy_categorical_accuracy: 0.3942 - value_mse: 0.0984\n","epoch 146\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.9202 - policy_loss: 2.3751 - value_loss: 0.6459 - policy_categorical_accuracy: 0.3923 - value_mse: 0.0990\n","epoch 147\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.9492 - policy_loss: 2.3910 - value_loss: 0.6441 - policy_categorical_accuracy: 0.3934 - value_mse: 0.0982\n","epoch 148\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.8668 - policy_loss: 2.3500 - value_loss: 0.6444 - policy_categorical_accuracy: 0.3974 - value_mse: 0.0963\n","epoch 149\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.9684 - policy_loss: 2.3998 - value_loss: 0.6472 - policy_categorical_accuracy: 0.3893 - value_mse: 0.0988\n","epoch 150\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.9974 - policy_loss: 2.4143 - value_loss: 0.6483 - policy_categorical_accuracy: 0.3891 - value_mse: 0.0991\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.879202842712402, 2.356961250305176, 0.6451098918914795, 0.40049999952316284, 0.0980134978890419]\n","epoch 151\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.9150 - policy_loss: 2.3769 - value_loss: 0.6415 - policy_categorical_accuracy: 0.3942 - value_mse: 0.0949\n","epoch 152\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.9033 - policy_loss: 2.3696 - value_loss: 0.6453 - policy_categorical_accuracy: 0.3914 - value_mse: 0.0975\n","epoch 153\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8750 - policy_loss: 2.3580 - value_loss: 0.6410 - policy_categorical_accuracy: 0.3911 - value_mse: 0.0977\n","epoch 154\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.9053 - policy_loss: 2.3672 - value_loss: 0.6537 - policy_categorical_accuracy: 0.3971 - value_mse: 0.1010\n","epoch 155\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.9268 - policy_loss: 2.3841 - value_loss: 0.6422 - policy_categorical_accuracy: 0.3921 - value_mse: 0.0965\n","epoch 156\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8829 - policy_loss: 2.3589 - value_loss: 0.6496 - policy_categorical_accuracy: 0.3939 - value_mse: 0.0998\n","epoch 157\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8479 - policy_loss: 2.3460 - value_loss: 0.6413 - policy_categorical_accuracy: 0.3974 - value_mse: 0.0954\n","epoch 158\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8995 - policy_loss: 2.3711 - value_loss: 0.6435 - policy_categorical_accuracy: 0.3960 - value_mse: 0.0985\n","epoch 159\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.8693 - policy_loss: 2.3568 - value_loss: 0.6428 - policy_categorical_accuracy: 0.3994 - value_mse: 0.0974\n","epoch 160\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8574 - policy_loss: 2.3507 - value_loss: 0.6440 - policy_categorical_accuracy: 0.4015 - value_mse: 0.0956\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.860736846923828, 2.3501312732696533, 0.6487792730331421, 0.40209999680519104, 0.09967663139104843]\n","epoch 161\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8512 - policy_loss: 2.3487 - value_loss: 0.6425 - policy_categorical_accuracy: 0.3998 - value_mse: 0.0958\n","epoch 162\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8894 - policy_loss: 2.3700 - value_loss: 0.6388 - policy_categorical_accuracy: 0.3938 - value_mse: 0.0952\n","epoch 163\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8114 - policy_loss: 2.3300 - value_loss: 0.6418 - policy_categorical_accuracy: 0.4025 - value_mse: 0.0981\n","epoch 164\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.9318 - policy_loss: 2.3917 - value_loss: 0.6396 - policy_categorical_accuracy: 0.3860 - value_mse: 0.0931\n","epoch 165\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8282 - policy_loss: 2.3396 - value_loss: 0.6409 - policy_categorical_accuracy: 0.3935 - value_mse: 0.0965\n","epoch 166\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7903 - policy_loss: 2.3204 - value_loss: 0.6423 - policy_categorical_accuracy: 0.4071 - value_mse: 0.0962\n","epoch 167\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8584 - policy_loss: 2.3532 - value_loss: 0.6456 - policy_categorical_accuracy: 0.3942 - value_mse: 0.0973\n","epoch 168\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8833 - policy_loss: 2.3694 - value_loss: 0.6389 - policy_categorical_accuracy: 0.3987 - value_mse: 0.0951\n","epoch 169\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.8472 - policy_loss: 2.3488 - value_loss: 0.6447 - policy_categorical_accuracy: 0.3988 - value_mse: 0.0970\n","epoch 170\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.9043 - policy_loss: 2.3767 - value_loss: 0.6469 - policy_categorical_accuracy: 0.3903 - value_mse: 0.0964\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.84359884262085, 2.3439338207244873, 0.6521183252334595, 0.40299999713897705, 0.10066579282283783]\n","epoch 171\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8481 - policy_loss: 2.3511 - value_loss: 0.6426 - policy_categorical_accuracy: 0.3940 - value_mse: 0.0958\n","epoch 172\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.8214 - policy_loss: 2.3374 - value_loss: 0.6442 - policy_categorical_accuracy: 0.3998 - value_mse: 0.0980\n","epoch 173\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8698 - policy_loss: 2.3621 - value_loss: 0.6439 - policy_categorical_accuracy: 0.3919 - value_mse: 0.0963\n","epoch 174\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7292 - policy_loss: 2.2904 - value_loss: 0.6475 - policy_categorical_accuracy: 0.4059 - value_mse: 0.0993\n","epoch 175\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8421 - policy_loss: 2.3475 - value_loss: 0.6470 - policy_categorical_accuracy: 0.4001 - value_mse: 0.0995\n","epoch 176\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.8392 - policy_loss: 2.3481 - value_loss: 0.6437 - policy_categorical_accuracy: 0.3998 - value_mse: 0.0959\n","epoch 177\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.8514 - policy_loss: 2.3557 - value_loss: 0.6415 - policy_categorical_accuracy: 0.3938 - value_mse: 0.0950\n","epoch 178\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.8893 - policy_loss: 2.3750 - value_loss: 0.6416 - policy_categorical_accuracy: 0.3870 - value_mse: 0.0953\n","epoch 179\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8608 - policy_loss: 2.3626 - value_loss: 0.6387 - policy_categorical_accuracy: 0.3972 - value_mse: 0.0950\n","epoch 180\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.8218 - policy_loss: 2.3432 - value_loss: 0.6393 - policy_categorical_accuracy: 0.4029 - value_mse: 0.0962\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.799378871917725, 2.3080782890319824, 0.687495231628418, 0.4025000035762787, 0.11232401430606842]\n","epoch 181\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.8048 - policy_loss: 2.3350 - value_loss: 0.6395 - policy_categorical_accuracy: 0.4004 - value_mse: 0.0950\n","epoch 182\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8655 - policy_loss: 2.3658 - value_loss: 0.6394 - policy_categorical_accuracy: 0.3918 - value_mse: 0.0966\n","epoch 183\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.7571 - policy_loss: 2.3102 - value_loss: 0.6428 - policy_categorical_accuracy: 0.4077 - value_mse: 0.0966\n","epoch 184\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.8269 - policy_loss: 2.3469 - value_loss: 0.6401 - policy_categorical_accuracy: 0.3938 - value_mse: 0.0954\n","epoch 185\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8191 - policy_loss: 2.3423 - value_loss: 0.6423 - policy_categorical_accuracy: 0.3968 - value_mse: 0.0968\n","epoch 186\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7793 - policy_loss: 2.3238 - value_loss: 0.6402 - policy_categorical_accuracy: 0.3992 - value_mse: 0.0953\n","epoch 187\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.8069 - policy_loss: 2.3362 - value_loss: 0.6438 - policy_categorical_accuracy: 0.3958 - value_mse: 0.0974\n","epoch 188\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.7358 - policy_loss: 2.3042 - value_loss: 0.6374 - policy_categorical_accuracy: 0.4078 - value_mse: 0.0935\n","epoch 189\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.7879 - policy_loss: 2.3318 - value_loss: 0.6349 - policy_categorical_accuracy: 0.3992 - value_mse: 0.0950\n","epoch 190\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7327 - policy_loss: 2.3011 - value_loss: 0.6418 - policy_categorical_accuracy: 0.4113 - value_mse: 0.0979\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.789831638336182, 2.315086603164673, 0.6714068651199341, 0.4007999897003174, 0.10757888108491898]\n","epoch 191\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7937 - policy_loss: 2.3329 - value_loss: 0.6400 - policy_categorical_accuracy: 0.3983 - value_mse: 0.0954\n","epoch 192\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.7714 - policy_loss: 2.3206 - value_loss: 0.6430 - policy_categorical_accuracy: 0.4027 - value_mse: 0.0951\n","epoch 193\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.7681 - policy_loss: 2.3192 - value_loss: 0.6432 - policy_categorical_accuracy: 0.4054 - value_mse: 0.0967\n","epoch 194\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.8146 - policy_loss: 2.3485 - value_loss: 0.6319 - policy_categorical_accuracy: 0.3998 - value_mse: 0.0925\n","epoch 195\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7729 - policy_loss: 2.3217 - value_loss: 0.6446 - policy_categorical_accuracy: 0.4026 - value_mse: 0.0988\n","epoch 196\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7569 - policy_loss: 2.3171 - value_loss: 0.6386 - policy_categorical_accuracy: 0.4016 - value_mse: 0.0938\n","epoch 197\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7388 - policy_loss: 2.3086 - value_loss: 0.6382 - policy_categorical_accuracy: 0.3984 - value_mse: 0.0935\n","epoch 198\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7603 - policy_loss: 2.3196 - value_loss: 0.6382 - policy_categorical_accuracy: 0.4001 - value_mse: 0.0932\n","epoch 199\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.7955 - policy_loss: 2.3373 - value_loss: 0.6388 - policy_categorical_accuracy: 0.3983 - value_mse: 0.0969\n","epoch 200\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.8306 - policy_loss: 2.3548 - value_loss: 0.6397 - policy_categorical_accuracy: 0.3926 - value_mse: 0.0938\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.719925403594971, 2.2801454067230225, 0.678680956363678, 0.40939998626708984, 0.10841057449579239]\n","epoch 201\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7313 - policy_loss: 2.3052 - value_loss: 0.6402 - policy_categorical_accuracy: 0.4041 - value_mse: 0.0942\n","epoch 202\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7068 - policy_loss: 2.2953 - value_loss: 0.6362 - policy_categorical_accuracy: 0.4082 - value_mse: 0.0942\n","epoch 203\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7434 - policy_loss: 2.3160 - value_loss: 0.6321 - policy_categorical_accuracy: 0.4036 - value_mse: 0.0934\n","epoch 204\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7325 - policy_loss: 2.3077 - value_loss: 0.6387 - policy_categorical_accuracy: 0.4028 - value_mse: 0.0961\n","epoch 205\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.7672 - policy_loss: 2.3234 - value_loss: 0.6427 - policy_categorical_accuracy: 0.3979 - value_mse: 0.0941\n","epoch 206\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7575 - policy_loss: 2.3201 - value_loss: 0.6402 - policy_categorical_accuracy: 0.3969 - value_mse: 0.0930\n","epoch 207\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7377 - policy_loss: 2.3132 - value_loss: 0.6350 - policy_categorical_accuracy: 0.4028 - value_mse: 0.0951\n","epoch 208\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.8048 - policy_loss: 2.3448 - value_loss: 0.6394 - policy_categorical_accuracy: 0.3975 - value_mse: 0.0937\n","epoch 209\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.7085 - policy_loss: 2.2990 - value_loss: 0.6355 - policy_categorical_accuracy: 0.4070 - value_mse: 0.0955\n","epoch 210\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.7491 - policy_loss: 2.3177 - value_loss: 0.6393 - policy_categorical_accuracy: 0.4003 - value_mse: 0.0957\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.677948951721191, 2.2862741947174072, 0.631401538848877, 0.4081000089645386, 0.09251313656568527]\n","epoch 211\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6563 - policy_loss: 2.2717 - value_loss: 0.6393 - policy_categorical_accuracy: 0.4119 - value_mse: 0.0957\n","epoch 212\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6977 - policy_loss: 2.2906 - value_loss: 0.6436 - policy_categorical_accuracy: 0.4047 - value_mse: 0.0963\n","epoch 213\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7060 - policy_loss: 2.2987 - value_loss: 0.6364 - policy_categorical_accuracy: 0.4082 - value_mse: 0.0968\n","epoch 214\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7184 - policy_loss: 2.3029 - value_loss: 0.6410 - policy_categorical_accuracy: 0.4046 - value_mse: 0.0946\n","epoch 215\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6902 - policy_loss: 2.2911 - value_loss: 0.6371 - policy_categorical_accuracy: 0.4102 - value_mse: 0.0931\n","epoch 216\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6699 - policy_loss: 2.2793 - value_loss: 0.6411 - policy_categorical_accuracy: 0.4052 - value_mse: 0.0961\n","epoch 217\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6929 - policy_loss: 2.2929 - value_loss: 0.6374 - policy_categorical_accuracy: 0.4119 - value_mse: 0.0940\n","epoch 218\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7491 - policy_loss: 2.3235 - value_loss: 0.6332 - policy_categorical_accuracy: 0.3947 - value_mse: 0.0925\n","epoch 219\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6984 - policy_loss: 2.2952 - value_loss: 0.6398 - policy_categorical_accuracy: 0.4051 - value_mse: 0.0946\n","epoch 220\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6571 - policy_loss: 2.2764 - value_loss: 0.6368 - policy_categorical_accuracy: 0.4030 - value_mse: 0.0951\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.748539447784424, 2.3202908039093018, 0.6407107710838318, 0.3986000120639801, 0.09632696211338043]\n","epoch 221\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7301 - policy_loss: 2.3145 - value_loss: 0.6340 - policy_categorical_accuracy: 0.4015 - value_mse: 0.0930\n","epoch 222\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6782 - policy_loss: 2.2885 - value_loss: 0.6349 - policy_categorical_accuracy: 0.4033 - value_mse: 0.0919\n","epoch 223\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7562 - policy_loss: 2.3293 - value_loss: 0.6319 - policy_categorical_accuracy: 0.3964 - value_mse: 0.0926\n","epoch 224\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6484 - policy_loss: 2.2741 - value_loss: 0.6351 - policy_categorical_accuracy: 0.4047 - value_mse: 0.0941\n","epoch 225\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6323 - policy_loss: 2.2641 - value_loss: 0.6398 - policy_categorical_accuracy: 0.4135 - value_mse: 0.0949\n","epoch 226\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6540 - policy_loss: 2.2763 - value_loss: 0.6378 - policy_categorical_accuracy: 0.4089 - value_mse: 0.0952\n","epoch 227\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6895 - policy_loss: 2.2945 - value_loss: 0.6375 - policy_categorical_accuracy: 0.4024 - value_mse: 0.0950\n","epoch 228\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.7244 - policy_loss: 2.3135 - value_loss: 0.6351 - policy_categorical_accuracy: 0.3964 - value_mse: 0.0932\n","epoch 229\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6848 - policy_loss: 2.2941 - value_loss: 0.6349 - policy_categorical_accuracy: 0.4016 - value_mse: 0.0928\n","epoch 230\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6424 - policy_loss: 2.2685 - value_loss: 0.6444 - policy_categorical_accuracy: 0.4103 - value_mse: 0.0960\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.692237377166748, 2.2908828258514404, 0.6496723890304565, 0.4097000062465668, 0.09939440339803696]\n","epoch 231\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6602 - policy_loss: 2.2802 - value_loss: 0.6394 - policy_categorical_accuracy: 0.4039 - value_mse: 0.0932\n","epoch 232\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6904 - policy_loss: 2.2993 - value_loss: 0.6320 - policy_categorical_accuracy: 0.4032 - value_mse: 0.0918\n","epoch 233\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.7770 - policy_loss: 2.3416 - value_loss: 0.6347 - policy_categorical_accuracy: 0.3992 - value_mse: 0.0927\n","epoch 234\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6740 - policy_loss: 2.2891 - value_loss: 0.6372 - policy_categorical_accuracy: 0.4035 - value_mse: 0.0926\n","epoch 235\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6082 - policy_loss: 2.2569 - value_loss: 0.6363 - policy_categorical_accuracy: 0.4097 - value_mse: 0.0919\n","epoch 236\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6540 - policy_loss: 2.2791 - value_loss: 0.6384 - policy_categorical_accuracy: 0.4086 - value_mse: 0.0947\n","epoch 237\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6815 - policy_loss: 2.2923 - value_loss: 0.6401 - policy_categorical_accuracy: 0.4045 - value_mse: 0.0952\n","epoch 238\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6187 - policy_loss: 2.2617 - value_loss: 0.6391 - policy_categorical_accuracy: 0.4069 - value_mse: 0.0944\n","epoch 239\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6442 - policy_loss: 2.2758 - value_loss: 0.6370 - policy_categorical_accuracy: 0.4159 - value_mse: 0.0943\n","epoch 240\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6680 - policy_loss: 2.2886 - value_loss: 0.6359 - policy_categorical_accuracy: 0.4040 - value_mse: 0.0938\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.640130519866943, 2.261800765991211, 0.6619226336479187, 0.4156999886035919, 0.10254742205142975]\n","epoch 241\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6307 - policy_loss: 2.2718 - value_loss: 0.6328 - policy_categorical_accuracy: 0.4098 - value_mse: 0.0910\n","epoch 242\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6457 - policy_loss: 2.2794 - value_loss: 0.6331 - policy_categorical_accuracy: 0.4016 - value_mse: 0.0924\n","epoch 243\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6399 - policy_loss: 2.2742 - value_loss: 0.6383 - policy_categorical_accuracy: 0.4077 - value_mse: 0.0949\n","epoch 244\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6753 - policy_loss: 2.2947 - value_loss: 0.6334 - policy_categorical_accuracy: 0.4021 - value_mse: 0.0927\n","epoch 245\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6520 - policy_loss: 2.2827 - value_loss: 0.6346 - policy_categorical_accuracy: 0.4068 - value_mse: 0.0929\n","epoch 246\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6750 - policy_loss: 2.2946 - value_loss: 0.6345 - policy_categorical_accuracy: 0.4008 - value_mse: 0.0916\n","epoch 247\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6583 - policy_loss: 2.2878 - value_loss: 0.6320 - policy_categorical_accuracy: 0.4046 - value_mse: 0.0920\n","epoch 248\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5581 - policy_loss: 2.2378 - value_loss: 0.6323 - policy_categorical_accuracy: 0.4176 - value_mse: 0.0919\n","epoch 249\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5719 - policy_loss: 2.2453 - value_loss: 0.6316 - policy_categorical_accuracy: 0.4132 - value_mse: 0.0912\n","epoch 250\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6022 - policy_loss: 2.2600 - value_loss: 0.6333 - policy_categorical_accuracy: 0.4124 - value_mse: 0.0938\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.529862403869629, 2.2231245040893555, 0.6348735690116882, 0.41519999504089355, 0.09424161165952682]\n","epoch 251\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5907 - policy_loss: 2.2527 - value_loss: 0.6368 - policy_categorical_accuracy: 0.4158 - value_mse: 0.0928\n","epoch 252\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5926 - policy_loss: 2.2574 - value_loss: 0.6299 - policy_categorical_accuracy: 0.4053 - value_mse: 0.0904\n","epoch 253\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5942 - policy_loss: 2.2591 - value_loss: 0.6286 - policy_categorical_accuracy: 0.4105 - value_mse: 0.0926\n","epoch 254\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6165 - policy_loss: 2.2683 - value_loss: 0.6332 - policy_categorical_accuracy: 0.4058 - value_mse: 0.0926\n","epoch 255\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6213 - policy_loss: 2.2709 - value_loss: 0.6334 - policy_categorical_accuracy: 0.4067 - value_mse: 0.0939\n","epoch 256\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5973 - policy_loss: 2.2583 - value_loss: 0.6351 - policy_categorical_accuracy: 0.4080 - value_mse: 0.0927\n","epoch 257\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6015 - policy_loss: 2.2601 - value_loss: 0.6362 - policy_categorical_accuracy: 0.4106 - value_mse: 0.0948\n","epoch 258\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.6155 - policy_loss: 2.2683 - value_loss: 0.6346 - policy_categorical_accuracy: 0.4043 - value_mse: 0.0913\n","epoch 259\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6073 - policy_loss: 2.2650 - value_loss: 0.6335 - policy_categorical_accuracy: 0.4128 - value_mse: 0.0913\n","epoch 260\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6916 - policy_loss: 2.3067 - value_loss: 0.6348 - policy_categorical_accuracy: 0.3955 - value_mse: 0.0939\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.571985721588135, 2.2366819381713867, 0.6555838584899902, 0.413100004196167, 0.10255856812000275]\n","epoch 261\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5901 - policy_loss: 2.2561 - value_loss: 0.6352 - policy_categorical_accuracy: 0.4128 - value_mse: 0.0944\n","epoch 262\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5714 - policy_loss: 2.2462 - value_loss: 0.6368 - policy_categorical_accuracy: 0.4101 - value_mse: 0.0934\n","epoch 263\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6032 - policy_loss: 2.2633 - value_loss: 0.6350 - policy_categorical_accuracy: 0.4026 - value_mse: 0.0930\n","epoch 264\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5565 - policy_loss: 2.2401 - value_loss: 0.6352 - policy_categorical_accuracy: 0.4132 - value_mse: 0.0924\n","epoch 265\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5746 - policy_loss: 2.2506 - value_loss: 0.6329 - policy_categorical_accuracy: 0.4141 - value_mse: 0.0929\n","epoch 266\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5700 - policy_loss: 2.2488 - value_loss: 0.6324 - policy_categorical_accuracy: 0.4154 - value_mse: 0.0916\n","epoch 267\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.4851 - policy_loss: 2.2075 - value_loss: 0.6306 - policy_categorical_accuracy: 0.4214 - value_mse: 0.0923\n","epoch 268\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5312 - policy_loss: 2.2291 - value_loss: 0.6341 - policy_categorical_accuracy: 0.4144 - value_mse: 0.0917\n","epoch 269\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5785 - policy_loss: 2.2522 - value_loss: 0.6357 - policy_categorical_accuracy: 0.4094 - value_mse: 0.0920\n","epoch 270\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.5832 - policy_loss: 2.2545 - value_loss: 0.6364 - policy_categorical_accuracy: 0.4116 - value_mse: 0.0916\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.559814453125, 2.2464957237243652, 0.6292031407356262, 0.41659998893737793, 0.0912102684378624]\n","epoch 271\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5696 - policy_loss: 2.2514 - value_loss: 0.6293 - policy_categorical_accuracy: 0.4099 - value_mse: 0.0909\n","epoch 272\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5132 - policy_loss: 2.2226 - value_loss: 0.6311 - policy_categorical_accuracy: 0.4177 - value_mse: 0.0911\n","epoch 273\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6233 - policy_loss: 2.2779 - value_loss: 0.6311 - policy_categorical_accuracy: 0.4043 - value_mse: 0.0916\n","epoch 274\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5315 - policy_loss: 2.2340 - value_loss: 0.6277 - policy_categorical_accuracy: 0.4145 - value_mse: 0.0906\n","epoch 275\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5683 - policy_loss: 2.2508 - value_loss: 0.6313 - policy_categorical_accuracy: 0.4162 - value_mse: 0.0924\n","epoch 276\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5156 - policy_loss: 2.2235 - value_loss: 0.6336 - policy_categorical_accuracy: 0.4113 - value_mse: 0.0934\n","epoch 277\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5870 - policy_loss: 2.2598 - value_loss: 0.6330 - policy_categorical_accuracy: 0.4061 - value_mse: 0.0918\n","epoch 278\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.6310 - policy_loss: 2.2808 - value_loss: 0.6356 - policy_categorical_accuracy: 0.4041 - value_mse: 0.0919\n","epoch 279\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5764 - policy_loss: 2.2558 - value_loss: 0.6315 - policy_categorical_accuracy: 0.4077 - value_mse: 0.0911\n","epoch 280\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.4876 - policy_loss: 2.2128 - value_loss: 0.6292 - policy_categorical_accuracy: 0.4202 - value_mse: 0.0913\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.5018720626831055, 2.2177746295928955, 0.6337869763374329, 0.4237000048160553, 0.09322087466716766]\n","epoch 281\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.4905 - policy_loss: 2.2127 - value_loss: 0.6329 - policy_categorical_accuracy: 0.4149 - value_mse: 0.0926\n","epoch 282\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5791 - policy_loss: 2.2570 - value_loss: 0.6335 - policy_categorical_accuracy: 0.4167 - value_mse: 0.0926\n","epoch 283\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5709 - policy_loss: 2.2527 - value_loss: 0.6342 - policy_categorical_accuracy: 0.4111 - value_mse: 0.0921\n","epoch 284\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5799 - policy_loss: 2.2575 - value_loss: 0.6341 - policy_categorical_accuracy: 0.4123 - value_mse: 0.0918\n","epoch 285\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5751 - policy_loss: 2.2571 - value_loss: 0.6308 - policy_categorical_accuracy: 0.4117 - value_mse: 0.0926\n","epoch 286\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.4586 - policy_loss: 2.1977 - value_loss: 0.6335 - policy_categorical_accuracy: 0.4248 - value_mse: 0.0920\n","epoch 287\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.4779 - policy_loss: 2.2085 - value_loss: 0.6317 - policy_categorical_accuracy: 0.4192 - value_mse: 0.0913\n","epoch 288\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5250 - policy_loss: 2.2339 - value_loss: 0.6285 - policy_categorical_accuracy: 0.4064 - value_mse: 0.0899\n","epoch 289\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5532 - policy_loss: 2.2486 - value_loss: 0.6278 - policy_categorical_accuracy: 0.4134 - value_mse: 0.0880\n","epoch 290\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5323 - policy_loss: 2.2358 - value_loss: 0.6330 - policy_categorical_accuracy: 0.4121 - value_mse: 0.0931\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.5394816398620605, 2.2372825145721436, 0.6374675035476685, 0.41179999709129333, 0.09485256671905518]\n","epoch 291\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5318 - policy_loss: 2.2380 - value_loss: 0.6285 - policy_categorical_accuracy: 0.4182 - value_mse: 0.0900\n","epoch 292\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5745 - policy_loss: 2.2565 - value_loss: 0.6348 - policy_categorical_accuracy: 0.4080 - value_mse: 0.0933\n","epoch 293\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5084 - policy_loss: 2.2260 - value_loss: 0.6302 - policy_categorical_accuracy: 0.4140 - value_mse: 0.0923\n","epoch 294\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5517 - policy_loss: 2.2485 - value_loss: 0.6291 - policy_categorical_accuracy: 0.4157 - value_mse: 0.0888\n","epoch 295\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.4977 - policy_loss: 2.2215 - value_loss: 0.6294 - policy_categorical_accuracy: 0.4215 - value_mse: 0.0902\n","epoch 296\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5368 - policy_loss: 2.2395 - value_loss: 0.6330 - policy_categorical_accuracy: 0.4200 - value_mse: 0.0926\n","epoch 297\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5510 - policy_loss: 2.2492 - value_loss: 0.6284 - policy_categorical_accuracy: 0.4086 - value_mse: 0.0897\n","epoch 298\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.4934 - policy_loss: 2.2198 - value_loss: 0.6300 - policy_categorical_accuracy: 0.4179 - value_mse: 0.0933\n","epoch 299\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5012 - policy_loss: 2.2231 - value_loss: 0.6317 - policy_categorical_accuracy: 0.4075 - value_mse: 0.0916\n","epoch 300\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5578 - policy_loss: 2.2513 - value_loss: 0.6323 - policy_categorical_accuracy: 0.4093 - value_mse: 0.0924\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.486499786376953, 2.204218864440918, 0.6554880142211914, 0.4196000099182129, 0.10130959749221802]\n","epoch 301\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5237 - policy_loss: 2.2357 - value_loss: 0.6299 - policy_categorical_accuracy: 0.4141 - value_mse: 0.0913\n","epoch 302\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.4493 - policy_loss: 2.1988 - value_loss: 0.6298 - policy_categorical_accuracy: 0.4269 - value_mse: 0.0916\n","epoch 303\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5069 - policy_loss: 2.2294 - value_loss: 0.6267 - policy_categorical_accuracy: 0.4177 - value_mse: 0.0894\n","epoch 304\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5043 - policy_loss: 2.2261 - value_loss: 0.6312 - policy_categorical_accuracy: 0.4114 - value_mse: 0.0915\n","epoch 305\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5225 - policy_loss: 2.2355 - value_loss: 0.6311 - policy_categorical_accuracy: 0.4131 - value_mse: 0.0910\n","epoch 306\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.4613 - policy_loss: 2.2051 - value_loss: 0.6311 - policy_categorical_accuracy: 0.4144 - value_mse: 0.0906\n","epoch 307\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.4804 - policy_loss: 2.2196 - value_loss: 0.6216 - policy_categorical_accuracy: 0.4135 - value_mse: 0.0898\n","epoch 308\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5252 - policy_loss: 2.2390 - value_loss: 0.6280 - policy_categorical_accuracy: 0.4135 - value_mse: 0.0907\n","epoch 309\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5206 - policy_loss: 2.2386 - value_loss: 0.6248 - policy_categorical_accuracy: 0.4102 - value_mse: 0.0904\n","epoch 310\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.4743 - policy_loss: 2.2147 - value_loss: 0.6268 - policy_categorical_accuracy: 0.4168 - value_mse: 0.0890\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.439387798309326, 2.193862199783325, 0.6336634755134583, 0.4226999878883362, 0.09341378509998322]\n","epoch 311\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 204ms/step - loss: 5.5053 - policy_loss: 2.2272 - value_loss: 0.6330 - policy_categorical_accuracy: 0.4127 - value_mse: 0.0914\n","epoch 312\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.4711 - policy_loss: 2.2118 - value_loss: 0.6300 - policy_categorical_accuracy: 0.4207 - value_mse: 0.0914\n","epoch 313\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.4867 - policy_loss: 2.2224 - value_loss: 0.6251 - policy_categorical_accuracy: 0.4140 - value_mse: 0.0908\n","epoch 314\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5273 - policy_loss: 2.2437 - value_loss: 0.6235 - policy_categorical_accuracy: 0.4088 - value_mse: 0.0888\n","epoch 315\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.4704 - policy_loss: 2.2151 - value_loss: 0.6243 - policy_categorical_accuracy: 0.4169 - value_mse: 0.0899\n","epoch 316\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.4967 - policy_loss: 2.2233 - value_loss: 0.6344 - policy_categorical_accuracy: 0.4147 - value_mse: 0.0907\n","epoch 317\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.4641 - policy_loss: 2.2125 - value_loss: 0.6240 - policy_categorical_accuracy: 0.4184 - value_mse: 0.0887\n","epoch 318\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.5417 - policy_loss: 2.2480 - value_loss: 0.6309 - policy_categorical_accuracy: 0.4068 - value_mse: 0.0923\n","epoch 319\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.5256 - policy_loss: 2.2403 - value_loss: 0.6308 - policy_categorical_accuracy: 0.4156 - value_mse: 0.0918\n","epoch 320\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.4436 - policy_loss: 2.2005 - value_loss: 0.6288 - policy_categorical_accuracy: 0.4207 - value_mse: 0.0898\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [5.432208061218262, 2.187011241912842, 0.6445462703704834, 0.424699991941452, 0.09781605750322342]\n","epoch 321\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 203ms/step - loss: 5.4275 - policy_loss: 2.1931 - value_loss: 0.6278 - policy_categorical_accuracy: 0.4221 - value_mse: 0.0891\n","epoch 322\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","157/157 [==============================] - 32s 202ms/step - loss: 5.4533 - policy_loss: 2.2058 - value_loss: 0.6288 - policy_categorical_accuracy: 0.4113 - value_mse: 0.0894\n","epoch 323\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n"," 51/157 [========>.....................] - ETA: 21s - loss: 5.5756 - policy_loss: 2.2641 - value_loss: 0.6347 - policy_categorical_accuracy: 0.4179 - value_mse: 0.0903"]}]},{"cell_type":"code","source":[],"metadata":{"id":"-eB96fdEBfR6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hnfHpAn3Blnf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rOSK8T23BmAo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uxC_y167Bt8Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wgo9D6C3RcOf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3WFj7CSnVh15"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VpqW22XGVozY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Y71XXrsNVs1f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6_pRvFrlVwfp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nMmS6obgV3Sn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wCU1FgQFV3dG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"baeF4jndV7fN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sRU5hXZzV_JX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Kcx7lvEOWF8W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PEaA693nWGHI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"B_WsEAeYWKI2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cR4qjDjoWNy7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oJ97k_yNWUl-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"24oWD-8cWUw2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AbhRUTSWWYyV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xzSZhfvVWccg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xfuiQ4ctWjPe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Qn4f-npDWjac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mf-sEBSiWncF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"n_gRD-ZEWrGL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5Fd-7RQjWx5L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1Pz58v1_WyEH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oOaHdXi5W2Fk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CncMqi9ZW5v3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Zr_UJ63mXAiz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AevNKdunXAtw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xC9ai9Q-XEvN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RZ9tPi-lXIZd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xp440_Q5XPMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"idwgAeI2XPXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JIEH0Y4IXTY0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QNzq6aomXXDI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SosZL7Y0Xd2B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ab-aFfbYXeA7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CMJJDISoXiCb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IPrWVAtwXls0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HlU7IPRVXsfh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"L8Lvk1P0Xsqi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tPlCB1YPXwsG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0_NcWMR2X0WX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-6Rz3DtGX7JG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VCYrmJJpX7UF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JruBcq2EX_Vo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sKNE8xiKYDAF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"P26XSqQWYJyq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3B6bZLR8YJ9q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"g_S6Ih7KYN_K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CXg5MMjCYRps"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Lfu1zRfxYYcX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mAYZHAqYYYnU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uGh-ps7rYcou"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nwkvE2TCYgTL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"c83M41A_YnGA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XozMc5u1YnQ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hkVdaE9UYrSZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5CmgcRcFYu84"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"F4-LK7TKY1vm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UGrrPgZYps1W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JqIDVANqpxTV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"48Gr0UMJp3A5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Cy7AHwPzp7u9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jCEtYH6dqAsm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"z6UQipi2qF6F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QavQSJH_qKoF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wQ9tibBnqPl4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PDqP6GiuqUzj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fJZTOBMvqZxZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lt7mxnFlqefB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jXrXWyvQqkMY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"__zuymcRqpJ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"14eqEqbSquH9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"p32GlKv8qzVj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rlioxZTLq4D3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DSpcUQF3q8yP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ighi3CArrCgS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_PM_9iN9rHeD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LWmcMMEtrMsc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7fuu5Xp8rR6N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"m87XvrsXrWoI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zbvsBMVarbm9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XQsIrLAbrhFW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eAdtJtzorljY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ty1x4CvOrqSC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5DCQP-Qzrvfn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MrLBNfdVr0tp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8WxZWeDQr48S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tWb9hRuMr-q_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SM6y0bs0sDoh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"B1jJZFuQsImp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rNaVs1oosOEw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bvnA-UUysSyc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uLoV9ecGsXxK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"T694AwsLsc_g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"x_vrOOkxsh9X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TzjKoVFYsmrL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kED9N1HGssJB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zmPppkGMsw2_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mcEqsvIws11J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-JXDqdxds6y3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EQVyTmams_go"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7dHA1N_VtEeN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nZuA3-owtJ8V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"betldECVtOqJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"M9MW-t10tTYN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"F6SiCkghtY1o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"s5Qv40lctdDu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"u7NHAnWJtiBl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"okxo9FjHtm_X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8pWccWWNtsNJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DLDvpzF2twbM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VCwD01cKt14w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rC3OFChEt6XG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QeTAgFjrt_U1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vc7kXg9WuECV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KGE77o4suJAU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"e6GQkfiJuNuO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lyI7CeOAuS7m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UxAJ8U8TuXpp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wEFkm2xgucnT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ft9WXiVauhk_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kc6KtjYoumS9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"G9GJLzj-urAz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Axy9cVmVuwjQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"v3JoMzmbu1xM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8-4w-m1fu6vv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IL2T0NUfvAxO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AMme1FsNvF-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WiFiM1vHvLgZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Di9EG24yq8y1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"w2e8KttJq-v3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wkC6bwCXq-0n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"C9RIBO2xq-4L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EDOPF-gbrLcb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9Eg6p5NArNah"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"h2__TD_zrNm6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XrFRZgDdrNqZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lnurQJH1Ri6f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RqZMnos5RoFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xdGgbIl9Rq4M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gJ9oVS0aRxkD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NszAu0QKR4QJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"j3w6V2mbSDCv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lp9DsutZSIg5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aApQrH32SQT7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RRE4onh7SdI5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DHfeV-XnSmHW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zee-j0vnSrXm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EGiKEZVzS4I8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MuK-afMyTCV6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"km_h-lq5THFW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6GMa0xyyTTGT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PG5PgaVaTdYQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1iakx-94Tdag"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4YBMzHRVThv8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RGa4xoCyTv93"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eZtP-ixbTz-5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"myFBuEA3T7Mh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SlzaOy79UHcf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Pg3wmA1SUKDg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BzHWg9A8USoz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KzcUjF72Ufjd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tXqCoVB2Ujj6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bbT5iLdHUnPS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ARnvt0ASUuM9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"clM5dzAfUyNi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7iO1Wc5nU15D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9nypyrkkU82q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Zq756108VA3D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"swjTCN1TVEiu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xPrqlHSGVLgW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"q99r5sJtVPgx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bRIpPaJuVTMZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aS9mcY2QVaJ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Y93klI1wVeL9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nD1nDI3HJqCb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CPBfqC_fJybK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qSn8YswvJ5Zg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"j17kvHcCJ9A8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lH9BWg58KBE2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RMxsluhoKLQ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"L8D2I-zDKOtg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2zRHfKTYKQOK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iV09xU-ZKbIF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TkdWx63FKfbu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"l8sVMVSLKfdc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RXTt-3WMKs-n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yJKd-jlUK3eB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rFBS_vuJK78j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9_bDfF9eLFEW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UM8_57TxLQ28"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"M4Ce__OVLYzX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rmNjSzKsLeDI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MeqTe4YiLpRF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pRLkId2xLyf9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"i068_Dh3L3zC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IXuUM5rPL36s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Iry6JtIbMFzE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Wzt0lZyCMLD0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tKaJoPYAMPCu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"O2ebBOiyMZI9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AZRnxyXeMi5F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gp3-HwHDMqTQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7rlbblvYMygc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jtW-s77vM0Q-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Fpryf9_IAHba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"M7ZP0xT5AWFF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sHwRBwKqAi3R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"D0pbFsgZAjUS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_be66h_iAmuF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"H8_UlmuaA01Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_qVq2OOcA5Dn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Nziad_o1A-AX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1gNRAd8-BDe-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xRR11KTQBHtQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EWAWHKtcBPLp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"N8WPok9cBS1o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"B9j_m9Ni_Ur0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"C939RZCJ_mEt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pUHhb0IL_2c2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7bil6sOM_GCM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test mobile net 1000 epochs\n","!python mobile_net_v3_1000epochs.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HwgFqIOxrgqM","executionInfo":{"status":"ok","timestamp":1673131399156,"user_tz":-60,"elapsed":10465378,"user":{"displayName":"Adrien","userId":"14922326483433512417"}},"outputId":"a39439ff-ba8f-4ce6-bcab-2a7f40172fcd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-07 19:48:55.117734: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-07 19:48:56.163818: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-01-07 19:48:56.163934: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-01-07 19:48:56.163952: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","getValidation\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","tcmalloc: large alloc 2400002048 bytes == 0x55688000 @  0x7fdd8b707887 0x7fdd389020d9 0x7fdd3890785f 0x7fdd3891c06f 0x58e314 0x514581 0x5a5fb6 0x607433 0x601066 0x60112c 0x6015f6 0x64faa2 0x64fc4e 0x7fdd8b302c87 0x5b64ca\n","nbPositionsSGF = 29425326\n","nbPositionsSGF = 29425326\n","loading validation.data\n","2023-01-07 19:49:23.055718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 19:49:23.061552: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 19:49:23.062191: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 19:49:23.063050: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-07 19:49:23.063313: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 19:49:23.063904: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 19:49:23.064493: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 19:49:23.621249: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 19:49:23.621911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 19:49:23.622524: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 19:49:23.623071: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-01-07 19:49:23.623141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13779 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," board (InputLayer)             [(None, 19, 19, 31)  0           []                               \n","                                ]                                                                 \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 19, 19, 32)   992         ['board[0][0]']                  \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 19, 19, 32)  128         ['conv2d[0][0]']                 \n"," alization)                                                                                       \n","                                                                                                  \n"," activation (Activation)        (None, 19, 19, 32)   0           ['batch_normalization[0][0]']    \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 19, 19, 16)   512         ['activation[0][0]']             \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 19, 19, 16)  64          ['conv2d_1[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_1 (Activation)      (None, 19, 19, 16)   0           ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," depthwise_conv2d (DepthwiseCon  (None, 19, 19, 16)  144         ['activation_1[0][0]']           \n"," v2D)                                                                                             \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 19, 19, 16)  64          ['depthwise_conv2d[0][0]']       \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_2 (Activation)      (None, 19, 19, 16)   0           ['batch_normalization_2[0][0]']  \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 19, 19, 16)   256         ['activation_2[0][0]']           \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 19, 19, 16)  64          ['conv2d_2[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 19, 19, 48)   768         ['batch_normalization_3[0][0]']  \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 19, 19, 48)  192         ['conv2d_3[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_3 (Activation)      (None, 19, 19, 48)   0           ['batch_normalization_4[0][0]']  \n","                                                                                                  \n"," depthwise_conv2d_1 (DepthwiseC  (None, 19, 19, 48)  432         ['activation_3[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 19, 19, 48)  192         ['depthwise_conv2d_1[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_4 (Activation)      (None, 19, 19, 48)   0           ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 19, 19, 24)   1152        ['activation_4[0][0]']           \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 19, 19, 24)  96          ['conv2d_4[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 19, 19, 48)   1152        ['batch_normalization_6[0][0]']  \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 19, 19, 48)  192         ['conv2d_5[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_5 (Activation)      (None, 19, 19, 48)   0           ['batch_normalization_7[0][0]']  \n","                                                                                                  \n"," depthwise_conv2d_2 (DepthwiseC  (None, 19, 19, 48)  432         ['activation_5[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 19, 19, 48)  192         ['depthwise_conv2d_2[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_6 (Activation)      (None, 19, 19, 48)   0           ['batch_normalization_8[0][0]']  \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 19, 19, 24)   1152        ['activation_6[0][0]']           \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 19, 19, 24)  96          ['conv2d_6[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," global_average_pooling2d (Glob  (None, 24)          0           ['batch_normalization_9[0][0]']  \n"," alAveragePooling2D)                                                                              \n","                                                                                                  \n"," reshape (Reshape)              (None, 1, 1, 24)     0           ['global_average_pooling2d[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," dense (Dense)                  (None, 1, 1, 1)      24          ['reshape[0][0]']                \n","                                                                                                  \n"," dense_1 (Dense)                (None, 1, 1, 24)     24          ['dense[0][0]']                  \n","                                                                                                  \n"," multiply (Multiply)            (None, 19, 19, 24)   0           ['batch_normalization_9[0][0]',  \n","                                                                  'dense_1[0][0]']                \n","                                                                                                  \n"," add (Add)                      (None, 19, 19, 24)   0           ['multiply[0][0]',               \n","                                                                  'batch_normalization_6[0][0]']  \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 19, 19, 64)   1536        ['add[0][0]']                    \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 19, 19, 64)  256         ['conv2d_7[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_7 (Activation)      (None, 19, 19, 64)   0           ['batch_normalization_10[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 64)  576         ['activation_7[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_11 (BatchN  (None, 19, 19, 64)  256         ['depthwise_conv2d_3[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_8 (Activation)      (None, 19, 19, 64)   0           ['batch_normalization_11[0][0]'] \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 19, 19, 32)   2048        ['activation_8[0][0]']           \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 19, 19, 32)  128         ['conv2d_8[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 19, 19, 64)   2048        ['batch_normalization_12[0][0]'] \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 19, 19, 64)  256         ['conv2d_9[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_9 (Activation)      (None, 19, 19, 64)   0           ['batch_normalization_13[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 64)  576         ['activation_9[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 19, 19, 64)  256         ['depthwise_conv2d_4[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_10 (Activation)     (None, 19, 19, 64)   0           ['batch_normalization_14[0][0]'] \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 19, 19, 32)   2048        ['activation_10[0][0]']          \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 19, 19, 32)  128         ['conv2d_10[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," global_average_pooling2d_1 (Gl  (None, 32)          0           ['batch_normalization_15[0][0]'] \n"," obalAveragePooling2D)                                                                            \n","                                                                                                  \n"," reshape_1 (Reshape)            (None, 1, 1, 32)     0           ['global_average_pooling2d_1[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dense_2 (Dense)                (None, 1, 1, 2)      64          ['reshape_1[0][0]']              \n","                                                                                                  \n"," dense_3 (Dense)                (None, 1, 1, 32)     64          ['dense_2[0][0]']                \n","                                                                                                  \n"," multiply_1 (Multiply)          (None, 19, 19, 32)   0           ['batch_normalization_15[0][0]', \n","                                                                  'dense_3[0][0]']                \n","                                                                                                  \n"," add_1 (Add)                    (None, 19, 19, 32)   0           ['multiply_1[0][0]',             \n","                                                                  'batch_normalization_12[0][0]'] \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 19, 19, 64)   2048        ['add_1[0][0]']                  \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 19, 19, 64)  256         ['conv2d_11[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_11 (Activation)     (None, 19, 19, 64)   0           ['batch_normalization_16[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_5 (DepthwiseC  (None, 19, 19, 64)  576         ['activation_11[0][0]']          \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 19, 19, 64)  256         ['depthwise_conv2d_5[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_12 (Activation)     (None, 19, 19, 64)   0           ['batch_normalization_17[0][0]'] \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 19, 19, 32)   2048        ['activation_12[0][0]']          \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 19, 19, 32)  128         ['conv2d_12[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," global_average_pooling2d_2 (Gl  (None, 32)          0           ['batch_normalization_18[0][0]'] \n"," obalAveragePooling2D)                                                                            \n","                                                                                                  \n"," reshape_2 (Reshape)            (None, 1, 1, 32)     0           ['global_average_pooling2d_2[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dense_4 (Dense)                (None, 1, 1, 2)      64          ['reshape_2[0][0]']              \n","                                                                                                  \n"," dense_5 (Dense)                (None, 1, 1, 32)     64          ['dense_4[0][0]']                \n","                                                                                                  \n"," multiply_2 (Multiply)          (None, 19, 19, 32)   0           ['batch_normalization_18[0][0]', \n","                                                                  'dense_5[0][0]']                \n","                                                                                                  \n"," add_2 (Add)                    (None, 19, 19, 32)   0           ['multiply_2[0][0]',             \n","                                                                  'add_1[0][0]']                  \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 19, 19, 850)  27200       ['add_2[0][0]']                  \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 19, 19, 850)  3400       ['conv2d_13[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_13 (Activation)     (None, 19, 19, 850)  0           ['batch_normalization_19[0][0]'] \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 19, 19, 1)    850         ['activation_13[0][0]']          \n","                                                                                                  \n"," global_average_pooling2d_3 (Gl  (None, 850)         0           ['activation_13[0][0]']          \n"," obalAveragePooling2D)                                                                            \n","                                                                                                  \n"," flatten (Flatten)              (None, 361)          0           ['conv2d_14[0][0]']              \n","                                                                                                  \n"," dense_6 (Dense)                (None, 50)           42550       ['global_average_pooling2d_3[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," policy (Activation)            (None, 361)          0           ['flatten[0][0]']                \n","                                                                                                  \n"," value (Dense)                  (None, 1)            51          ['dense_6[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 98,051\n","Trainable params: 94,751\n","Non-trainable params: 3,300\n","__________________________________________________________________________________________________\n","epoch 1\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-07 19:49:25.906918: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","2023-01-07 19:49:34.250841: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n","2023-01-07 19:49:40.293282: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0xe78c6100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-01-07 19:49:40.293368: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2023-01-07 19:49:40.331519: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2023-01-07 19:49:40.814264: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","79/79 [==============================] - 29s 78ms/step - loss: 6.3181 - policy_loss: 5.6180 - value_loss: 0.6912 - policy_categorical_accuracy: 0.0223 - value_mse: 0.1205\n","epoch 2\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-07 19:49:56.521374: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","79/79 [==============================] - 6s 75ms/step - loss: 5.1188 - policy_loss: 4.4190 - value_loss: 0.6927 - policy_categorical_accuracy: 0.1200 - value_mse: 0.1192\n","epoch 3\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-07 19:50:04.353118: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","79/79 [==============================] - 6s 75ms/step - loss: 4.7276 - policy_loss: 4.0298 - value_loss: 0.6918 - policy_categorical_accuracy: 0.1652 - value_mse: 0.1198\n","epoch 4\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-07 19:50:12.237942: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","79/79 [==============================] - 6s 75ms/step - loss: 4.5125 - policy_loss: 3.8172 - value_loss: 0.6899 - policy_categorical_accuracy: 0.1938 - value_mse: 0.1192\n","epoch 5\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-07 19:50:19.874709: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","79/79 [==============================] - 6s 75ms/step - loss: 4.4145 - policy_loss: 3.7194 - value_loss: 0.6902 - policy_categorical_accuracy: 0.1997 - value_mse: 0.1180\n","epoch 6\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 75ms/step - loss: 4.2652 - policy_loss: 3.5717 - value_loss: 0.6890 - policy_categorical_accuracy: 0.2254 - value_mse: 0.1160\n","epoch 7\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 75ms/step - loss: 4.1796 - policy_loss: 3.4873 - value_loss: 0.6883 - policy_categorical_accuracy: 0.2300 - value_mse: 0.1178\n","epoch 8\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 4.0523 - policy_loss: 3.3596 - value_loss: 0.6889 - policy_categorical_accuracy: 0.2478 - value_mse: 0.1177\n","epoch 9\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 75ms/step - loss: 3.9816 - policy_loss: 3.2902 - value_loss: 0.6879 - policy_categorical_accuracy: 0.2577 - value_mse: 0.1164\n","epoch 10\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.9326 - policy_loss: 3.2443 - value_loss: 0.6851 - policy_categorical_accuracy: 0.2646 - value_mse: 0.1151\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.899120330810547, 3.210848331451416, 0.6851084232330322, 0.27480000257492065, 0.11612249910831451]\n","epoch 11\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.8646 - policy_loss: 3.1758 - value_loss: 0.6857 - policy_categorical_accuracy: 0.2755 - value_mse: 0.1175\n","epoch 12\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.8131 - policy_loss: 3.1260 - value_loss: 0.6841 - policy_categorical_accuracy: 0.2834 - value_mse: 0.1159\n","epoch 13\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.7688 - policy_loss: 3.0861 - value_loss: 0.6799 - policy_categorical_accuracy: 0.2882 - value_mse: 0.1125\n","epoch 14\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.7591 - policy_loss: 3.0740 - value_loss: 0.6825 - policy_categorical_accuracy: 0.2948 - value_mse: 0.1124\n","epoch 15\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 87ms/step - loss: 3.7659 - policy_loss: 3.0866 - value_loss: 0.6768 - policy_categorical_accuracy: 0.2884 - value_mse: 0.1124\n","epoch 16\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.7113 - policy_loss: 3.0319 - value_loss: 0.6769 - policy_categorical_accuracy: 0.2979 - value_mse: 0.1105\n","epoch 17\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.7235 - policy_loss: 3.0447 - value_loss: 0.6764 - policy_categorical_accuracy: 0.2908 - value_mse: 0.1103\n","epoch 18\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.6813 - policy_loss: 3.0041 - value_loss: 0.6749 - policy_categorical_accuracy: 0.3033 - value_mse: 0.1122\n","epoch 19\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.6773 - policy_loss: 2.9998 - value_loss: 0.6753 - policy_categorical_accuracy: 0.3074 - value_mse: 0.1089\n","epoch 20\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.6181 - policy_loss: 2.9427 - value_loss: 0.6731 - policy_categorical_accuracy: 0.3055 - value_mse: 0.1110\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.672600507736206, 2.9771323204040527, 0.6932841539382935, 0.3052999973297119, 0.11966778337955475]\n","epoch 21\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.5933 - policy_loss: 2.9199 - value_loss: 0.6712 - policy_categorical_accuracy: 0.3068 - value_mse: 0.1086\n","epoch 22\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.6199 - policy_loss: 2.9417 - value_loss: 0.6761 - policy_categorical_accuracy: 0.3087 - value_mse: 0.1119\n","epoch 23\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.6026 - policy_loss: 2.9314 - value_loss: 0.6691 - policy_categorical_accuracy: 0.3110 - value_mse: 0.1084\n","epoch 24\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.6000 - policy_loss: 2.9323 - value_loss: 0.6656 - policy_categorical_accuracy: 0.3105 - value_mse: 0.1071\n","epoch 25\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.5899 - policy_loss: 2.9154 - value_loss: 0.6725 - policy_categorical_accuracy: 0.3159 - value_mse: 0.1090\n","epoch 26\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.5862 - policy_loss: 2.9134 - value_loss: 0.6708 - policy_categorical_accuracy: 0.3125 - value_mse: 0.1077\n","epoch 27\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.5385 - policy_loss: 2.8670 - value_loss: 0.6695 - policy_categorical_accuracy: 0.3221 - value_mse: 0.1096\n","epoch 28\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.5343 - policy_loss: 2.8582 - value_loss: 0.6742 - policy_categorical_accuracy: 0.3299 - value_mse: 0.1099\n","epoch 29\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.5322 - policy_loss: 2.8621 - value_loss: 0.6681 - policy_categorical_accuracy: 0.3233 - value_mse: 0.1069\n","epoch 30\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.4813 - policy_loss: 2.8140 - value_loss: 0.6654 - policy_categorical_accuracy: 0.3271 - value_mse: 0.1065\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.483177661895752, 2.8154258728027344, 0.6657904982566833, 0.3292999863624573, 0.10706266015768051]\n","epoch 31\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.5203 - policy_loss: 2.8542 - value_loss: 0.6641 - policy_categorical_accuracy: 0.3185 - value_mse: 0.1046\n","epoch 32\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.5178 - policy_loss: 2.8456 - value_loss: 0.6703 - policy_categorical_accuracy: 0.3264 - value_mse: 0.1075\n","epoch 33\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.5036 - policy_loss: 2.8361 - value_loss: 0.6656 - policy_categorical_accuracy: 0.3263 - value_mse: 0.1054\n","epoch 34\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.4946 - policy_loss: 2.8289 - value_loss: 0.6637 - policy_categorical_accuracy: 0.3221 - value_mse: 0.1060\n","epoch 35\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 81ms/step - loss: 3.4778 - policy_loss: 2.8095 - value_loss: 0.6664 - policy_categorical_accuracy: 0.3364 - value_mse: 0.1054\n","epoch 36\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 79ms/step - loss: 3.4593 - policy_loss: 2.7927 - value_loss: 0.6647 - policy_categorical_accuracy: 0.3312 - value_mse: 0.1069\n","epoch 37\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.4533 - policy_loss: 2.7899 - value_loss: 0.6615 - policy_categorical_accuracy: 0.3337 - value_mse: 0.1051\n","epoch 38\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.5059 - policy_loss: 2.8377 - value_loss: 0.6662 - policy_categorical_accuracy: 0.3262 - value_mse: 0.1077\n","epoch 39\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.4799 - policy_loss: 2.8124 - value_loss: 0.6656 - policy_categorical_accuracy: 0.3291 - value_mse: 0.1062\n","epoch 40\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.4571 - policy_loss: 2.7915 - value_loss: 0.6637 - policy_categorical_accuracy: 0.3325 - value_mse: 0.1032\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.4168293476104736, 2.75100040435791, 0.6639079451560974, 0.33880001306533813, 0.10618195682764053]\n","epoch 41\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.4512 - policy_loss: 2.7876 - value_loss: 0.6617 - policy_categorical_accuracy: 0.3285 - value_mse: 0.1040\n","epoch 42\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.4222 - policy_loss: 2.7604 - value_loss: 0.6599 - policy_categorical_accuracy: 0.3336 - value_mse: 0.1052\n","epoch 43\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3861 - policy_loss: 2.7194 - value_loss: 0.6648 - policy_categorical_accuracy: 0.3380 - value_mse: 0.1055\n","epoch 44\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3873 - policy_loss: 2.7224 - value_loss: 0.6630 - policy_categorical_accuracy: 0.3423 - value_mse: 0.1048\n","epoch 45\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.4077 - policy_loss: 2.7465 - value_loss: 0.6593 - policy_categorical_accuracy: 0.3346 - value_mse: 0.1030\n","epoch 46\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.4159 - policy_loss: 2.7512 - value_loss: 0.6628 - policy_categorical_accuracy: 0.3365 - value_mse: 0.1049\n","epoch 47\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3909 - policy_loss: 2.7265 - value_loss: 0.6625 - policy_categorical_accuracy: 0.3513 - value_mse: 0.1064\n","epoch 48\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.4246 - policy_loss: 2.7612 - value_loss: 0.6615 - policy_categorical_accuracy: 0.3341 - value_mse: 0.1059\n","epoch 49\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3921 - policy_loss: 2.7309 - value_loss: 0.6593 - policy_categorical_accuracy: 0.3385 - value_mse: 0.1048\n","epoch 50\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3717 - policy_loss: 2.7112 - value_loss: 0.6586 - policy_categorical_accuracy: 0.3470 - value_mse: 0.1043\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.392162799835205, 2.728248357772827, 0.6619768738746643, 0.34459999203681946, 0.10545729100704193]\n","epoch 51\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.4036 - policy_loss: 2.7466 - value_loss: 0.6550 - policy_categorical_accuracy: 0.3375 - value_mse: 0.1034\n","epoch 52\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.4007 - policy_loss: 2.7403 - value_loss: 0.6585 - policy_categorical_accuracy: 0.3366 - value_mse: 0.1012\n","epoch 53\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.4278 - policy_loss: 2.7705 - value_loss: 0.6553 - policy_categorical_accuracy: 0.3246 - value_mse: 0.1016\n","epoch 54\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3846 - policy_loss: 2.7258 - value_loss: 0.6568 - policy_categorical_accuracy: 0.3397 - value_mse: 0.1018\n","epoch 55\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 84ms/step - loss: 3.4017 - policy_loss: 2.7413 - value_loss: 0.6584 - policy_categorical_accuracy: 0.3464 - value_mse: 0.1033\n","epoch 56\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 83ms/step - loss: 3.3851 - policy_loss: 2.7234 - value_loss: 0.6597 - policy_categorical_accuracy: 0.3404 - value_mse: 0.1045\n","epoch 57\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.3713 - policy_loss: 2.7087 - value_loss: 0.6607 - policy_categorical_accuracy: 0.3428 - value_mse: 0.1060\n","epoch 58\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3793 - policy_loss: 2.7223 - value_loss: 0.6550 - policy_categorical_accuracy: 0.3416 - value_mse: 0.1020\n","epoch 59\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3661 - policy_loss: 2.7056 - value_loss: 0.6584 - policy_categorical_accuracy: 0.3464 - value_mse: 0.1039\n","epoch 60\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.3820 - policy_loss: 2.7216 - value_loss: 0.6584 - policy_categorical_accuracy: 0.3430 - value_mse: 0.1035\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.3529112339019775, 2.681797981262207, 0.6691230535507202, 0.35429999232292175, 0.10874629020690918]\n","epoch 61\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3537 - policy_loss: 2.6935 - value_loss: 0.6581 - policy_categorical_accuracy: 0.3423 - value_mse: 0.1036\n","epoch 62\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3725 - policy_loss: 2.7124 - value_loss: 0.6581 - policy_categorical_accuracy: 0.3429 - value_mse: 0.1035\n","epoch 63\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3318 - policy_loss: 2.6731 - value_loss: 0.6567 - policy_categorical_accuracy: 0.3506 - value_mse: 0.1010\n","epoch 64\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3551 - policy_loss: 2.6995 - value_loss: 0.6535 - policy_categorical_accuracy: 0.3444 - value_mse: 0.1015\n","epoch 65\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3611 - policy_loss: 2.7015 - value_loss: 0.6575 - policy_categorical_accuracy: 0.3379 - value_mse: 0.1039\n","epoch 66\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.3440 - policy_loss: 2.6841 - value_loss: 0.6578 - policy_categorical_accuracy: 0.3515 - value_mse: 0.1023\n","epoch 67\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3505 - policy_loss: 2.6929 - value_loss: 0.6556 - policy_categorical_accuracy: 0.3497 - value_mse: 0.1006\n","epoch 68\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3387 - policy_loss: 2.6783 - value_loss: 0.6584 - policy_categorical_accuracy: 0.3500 - value_mse: 0.1031\n","epoch 69\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3691 - policy_loss: 2.7094 - value_loss: 0.6577 - policy_categorical_accuracy: 0.3433 - value_mse: 0.1035\n","epoch 70\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.3485 - policy_loss: 2.6916 - value_loss: 0.6549 - policy_categorical_accuracy: 0.3435 - value_mse: 0.1021\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.3186800479888916, 2.6602327823638916, 0.6564307808876038, 0.35420000553131104, 0.1028531864285469]\n","epoch 71\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3654 - policy_loss: 2.7088 - value_loss: 0.6546 - policy_categorical_accuracy: 0.3444 - value_mse: 0.1018\n","epoch 72\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3229 - policy_loss: 2.6659 - value_loss: 0.6550 - policy_categorical_accuracy: 0.3521 - value_mse: 0.1018\n","epoch 73\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3335 - policy_loss: 2.6731 - value_loss: 0.6583 - policy_categorical_accuracy: 0.3491 - value_mse: 0.1018\n","epoch 74\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 85ms/step - loss: 3.3173 - policy_loss: 2.6587 - value_loss: 0.6566 - policy_categorical_accuracy: 0.3501 - value_mse: 0.1006\n","epoch 75\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 82ms/step - loss: 3.3213 - policy_loss: 2.6619 - value_loss: 0.6573 - policy_categorical_accuracy: 0.3460 - value_mse: 0.1022\n","epoch 76\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.3265 - policy_loss: 2.6695 - value_loss: 0.6550 - policy_categorical_accuracy: 0.3563 - value_mse: 0.1001\n","epoch 77\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3366 - policy_loss: 2.6766 - value_loss: 0.6580 - policy_categorical_accuracy: 0.3400 - value_mse: 0.1030\n","epoch 78\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2916 - policy_loss: 2.6351 - value_loss: 0.6544 - policy_categorical_accuracy: 0.3520 - value_mse: 0.1014\n","epoch 79\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3368 - policy_loss: 2.6816 - value_loss: 0.6531 - policy_categorical_accuracy: 0.3518 - value_mse: 0.1003\n","epoch 80\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3295 - policy_loss: 2.6720 - value_loss: 0.6555 - policy_categorical_accuracy: 0.3533 - value_mse: 0.1025\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.2964043617248535, 2.6410555839538574, 0.6532782316207886, 0.35589998960494995, 0.10154671967029572]\n","epoch 81\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3115 - policy_loss: 2.6558 - value_loss: 0.6536 - policy_categorical_accuracy: 0.3498 - value_mse: 0.1002\n","epoch 82\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3441 - policy_loss: 2.6842 - value_loss: 0.6578 - policy_categorical_accuracy: 0.3488 - value_mse: 0.1018\n","epoch 83\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.3288 - policy_loss: 2.6716 - value_loss: 0.6551 - policy_categorical_accuracy: 0.3436 - value_mse: 0.1021\n","epoch 84\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3162 - policy_loss: 2.6625 - value_loss: 0.6516 - policy_categorical_accuracy: 0.3489 - value_mse: 0.0992\n","epoch 85\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.2916 - policy_loss: 2.6312 - value_loss: 0.6582 - policy_categorical_accuracy: 0.3600 - value_mse: 0.1022\n","epoch 86\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3004 - policy_loss: 2.6462 - value_loss: 0.6521 - policy_categorical_accuracy: 0.3562 - value_mse: 0.1008\n","epoch 87\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2726 - policy_loss: 2.6197 - value_loss: 0.6508 - policy_categorical_accuracy: 0.3582 - value_mse: 0.1007\n","epoch 88\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2673 - policy_loss: 2.6120 - value_loss: 0.6532 - policy_categorical_accuracy: 0.3569 - value_mse: 0.1023\n","epoch 89\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3272 - policy_loss: 2.6718 - value_loss: 0.6533 - policy_categorical_accuracy: 0.3440 - value_mse: 0.1014\n","epoch 90\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.2821 - policy_loss: 2.6315 - value_loss: 0.6484 - policy_categorical_accuracy: 0.3545 - value_mse: 0.1004\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.274519443511963, 2.618419647216797, 0.6539719104766846, 0.36010000109672546, 0.1019027978181839]\n","epoch 91\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3389 - policy_loss: 2.6836 - value_loss: 0.6531 - policy_categorical_accuracy: 0.3489 - value_mse: 0.1017\n","epoch 92\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3213 - policy_loss: 2.6631 - value_loss: 0.6560 - policy_categorical_accuracy: 0.3474 - value_mse: 0.1017\n","epoch 93\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.2782 - policy_loss: 2.6180 - value_loss: 0.6581 - policy_categorical_accuracy: 0.3603 - value_mse: 0.1031\n","epoch 94\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.3031 - policy_loss: 2.6471 - value_loss: 0.6539 - policy_categorical_accuracy: 0.3474 - value_mse: 0.1023\n","epoch 95\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 85ms/step - loss: 3.2947 - policy_loss: 2.6379 - value_loss: 0.6547 - policy_categorical_accuracy: 0.3495 - value_mse: 0.1017\n","epoch 96\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 79ms/step - loss: 3.2969 - policy_loss: 2.6443 - value_loss: 0.6505 - policy_categorical_accuracy: 0.3550 - value_mse: 0.0995\n","epoch 97\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.2593 - policy_loss: 2.6013 - value_loss: 0.6559 - policy_categorical_accuracy: 0.3557 - value_mse: 0.1027\n","epoch 98\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2962 - policy_loss: 2.6391 - value_loss: 0.6550 - policy_categorical_accuracy: 0.3496 - value_mse: 0.1030\n","epoch 99\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2842 - policy_loss: 2.6319 - value_loss: 0.6501 - policy_categorical_accuracy: 0.3523 - value_mse: 0.1000\n","epoch 100\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2993 - policy_loss: 2.6434 - value_loss: 0.6538 - policy_categorical_accuracy: 0.3547 - value_mse: 0.1016\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.2502522468566895, 2.5925211906433105, 0.655566930770874, 0.359499990940094, 0.102568618953228]\n","epoch 101\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2739 - policy_loss: 2.6202 - value_loss: 0.6515 - policy_categorical_accuracy: 0.3544 - value_mse: 0.1002\n","epoch 102\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2743 - policy_loss: 2.6203 - value_loss: 0.6518 - policy_categorical_accuracy: 0.3564 - value_mse: 0.0993\n","epoch 103\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2605 - policy_loss: 2.6031 - value_loss: 0.6553 - policy_categorical_accuracy: 0.3623 - value_mse: 0.1020\n","epoch 104\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2461 - policy_loss: 2.5963 - value_loss: 0.6476 - policy_categorical_accuracy: 0.3587 - value_mse: 0.0982\n","epoch 105\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2843 - policy_loss: 2.6305 - value_loss: 0.6516 - policy_categorical_accuracy: 0.3485 - value_mse: 0.1001\n","epoch 106\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2762 - policy_loss: 2.6210 - value_loss: 0.6530 - policy_categorical_accuracy: 0.3526 - value_mse: 0.1005\n","epoch 107\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2624 - policy_loss: 2.6052 - value_loss: 0.6550 - policy_categorical_accuracy: 0.3614 - value_mse: 0.1036\n","epoch 108\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2460 - policy_loss: 2.5908 - value_loss: 0.6530 - policy_categorical_accuracy: 0.3548 - value_mse: 0.1016\n","epoch 109\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2983 - policy_loss: 2.6448 - value_loss: 0.6513 - policy_categorical_accuracy: 0.3543 - value_mse: 0.1012\n","epoch 110\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2472 - policy_loss: 2.5914 - value_loss: 0.6536 - policy_categorical_accuracy: 0.3580 - value_mse: 0.1012\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.248460054397583, 2.5899314880371094, 0.6563515663146973, 0.3603000044822693, 0.10306163132190704]\n","epoch 111\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2729 - policy_loss: 2.6187 - value_loss: 0.6521 - policy_categorical_accuracy: 0.3626 - value_mse: 0.0978\n","epoch 112\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2498 - policy_loss: 2.6006 - value_loss: 0.6470 - policy_categorical_accuracy: 0.3594 - value_mse: 0.0992\n","epoch 113\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 85ms/step - loss: 3.2520 - policy_loss: 2.6023 - value_loss: 0.6475 - policy_categorical_accuracy: 0.3564 - value_mse: 0.0995\n","epoch 114\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2492 - policy_loss: 2.5932 - value_loss: 0.6538 - policy_categorical_accuracy: 0.3619 - value_mse: 0.1004\n","epoch 115\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.2612 - policy_loss: 2.6087 - value_loss: 0.6503 - policy_categorical_accuracy: 0.3572 - value_mse: 0.0980\n","epoch 116\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2217 - policy_loss: 2.5684 - value_loss: 0.6510 - policy_categorical_accuracy: 0.3657 - value_mse: 0.1012\n","epoch 117\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2599 - policy_loss: 2.6079 - value_loss: 0.6498 - policy_categorical_accuracy: 0.3586 - value_mse: 0.1006\n","epoch 118\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2698 - policy_loss: 2.6145 - value_loss: 0.6531 - policy_categorical_accuracy: 0.3575 - value_mse: 0.1001\n","epoch 119\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2554 - policy_loss: 2.6042 - value_loss: 0.6490 - policy_categorical_accuracy: 0.3600 - value_mse: 0.0969\n","epoch 120\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.2288 - policy_loss: 2.5801 - value_loss: 0.6465 - policy_categorical_accuracy: 0.3615 - value_mse: 0.0973\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.2069766521453857, 2.5565805435180664, 0.6481255292892456, 0.3662000000476837, 0.09919381886720657]\n","epoch 121\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.2577 - policy_loss: 2.6054 - value_loss: 0.6500 - policy_categorical_accuracy: 0.3643 - value_mse: 0.0991\n","epoch 122\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2328 - policy_loss: 2.5767 - value_loss: 0.6539 - policy_categorical_accuracy: 0.3598 - value_mse: 0.1005\n","epoch 123\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2236 - policy_loss: 2.5713 - value_loss: 0.6500 - policy_categorical_accuracy: 0.3626 - value_mse: 0.0996\n","epoch 124\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2439 - policy_loss: 2.5922 - value_loss: 0.6495 - policy_categorical_accuracy: 0.3597 - value_mse: 0.0990\n","epoch 125\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.2124 - policy_loss: 2.5606 - value_loss: 0.6495 - policy_categorical_accuracy: 0.3667 - value_mse: 0.1009\n","epoch 126\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2395 - policy_loss: 2.5878 - value_loss: 0.6495 - policy_categorical_accuracy: 0.3604 - value_mse: 0.1004\n","epoch 127\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1990 - policy_loss: 2.5462 - value_loss: 0.6506 - policy_categorical_accuracy: 0.3710 - value_mse: 0.0986\n","epoch 128\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2077 - policy_loss: 2.5560 - value_loss: 0.6495 - policy_categorical_accuracy: 0.3690 - value_mse: 0.0995\n","epoch 129\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2299 - policy_loss: 2.5776 - value_loss: 0.6500 - policy_categorical_accuracy: 0.3668 - value_mse: 0.0995\n","epoch 130\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.2020 - policy_loss: 2.5534 - value_loss: 0.6463 - policy_categorical_accuracy: 0.3674 - value_mse: 0.0993\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.1938328742980957, 2.531445026397705, 0.6600974202156067, 0.37290000915527344, 0.10463041812181473]\n","epoch 131\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1898 - policy_loss: 2.5369 - value_loss: 0.6506 - policy_categorical_accuracy: 0.3653 - value_mse: 0.1013\n","epoch 132\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 82ms/step - loss: 3.2297 - policy_loss: 2.5799 - value_loss: 0.6475 - policy_categorical_accuracy: 0.3584 - value_mse: 0.0992\n","epoch 133\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 84ms/step - loss: 3.2267 - policy_loss: 2.5736 - value_loss: 0.6508 - policy_categorical_accuracy: 0.3622 - value_mse: 0.0997\n","epoch 134\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.2174 - policy_loss: 2.5660 - value_loss: 0.6491 - policy_categorical_accuracy: 0.3602 - value_mse: 0.0980\n","epoch 135\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.2042 - policy_loss: 2.5517 - value_loss: 0.6501 - policy_categorical_accuracy: 0.3680 - value_mse: 0.0990\n","epoch 136\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2024 - policy_loss: 2.5521 - value_loss: 0.6480 - policy_categorical_accuracy: 0.3640 - value_mse: 0.0981\n","epoch 137\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1955 - policy_loss: 2.5439 - value_loss: 0.6493 - policy_categorical_accuracy: 0.3717 - value_mse: 0.0973\n","epoch 138\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2056 - policy_loss: 2.5508 - value_loss: 0.6526 - policy_categorical_accuracy: 0.3669 - value_mse: 0.1002\n","epoch 139\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2098 - policy_loss: 2.5620 - value_loss: 0.6456 - policy_categorical_accuracy: 0.3640 - value_mse: 0.0975\n","epoch 140\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1816 - policy_loss: 2.5340 - value_loss: 0.6452 - policy_categorical_accuracy: 0.3711 - value_mse: 0.0986\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.1945202350616455, 2.527068853378296, 0.665131151676178, 0.36880001425743103, 0.106601782143116]\n","epoch 141\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1996 - policy_loss: 2.5517 - value_loss: 0.6455 - policy_categorical_accuracy: 0.3665 - value_mse: 0.0990\n","epoch 142\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2226 - policy_loss: 2.5732 - value_loss: 0.6470 - policy_categorical_accuracy: 0.3610 - value_mse: 0.0996\n","epoch 143\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2051 - policy_loss: 2.5491 - value_loss: 0.6537 - policy_categorical_accuracy: 0.3636 - value_mse: 0.1014\n","epoch 144\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.2099 - policy_loss: 2.5558 - value_loss: 0.6518 - policy_categorical_accuracy: 0.3627 - value_mse: 0.1011\n","epoch 145\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.1906 - policy_loss: 2.5340 - value_loss: 0.6543 - policy_categorical_accuracy: 0.3651 - value_mse: 0.1008\n","epoch 146\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1933 - policy_loss: 2.5441 - value_loss: 0.6469 - policy_categorical_accuracy: 0.3685 - value_mse: 0.0994\n","epoch 147\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.1999 - policy_loss: 2.5523 - value_loss: 0.6453 - policy_categorical_accuracy: 0.3692 - value_mse: 0.0991\n","epoch 148\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1671 - policy_loss: 2.5178 - value_loss: 0.6470 - policy_categorical_accuracy: 0.3736 - value_mse: 0.0972\n","epoch 149\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.2075 - policy_loss: 2.5570 - value_loss: 0.6481 - policy_categorical_accuracy: 0.3656 - value_mse: 0.0992\n","epoch 150\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.2393 - policy_loss: 2.5899 - value_loss: 0.6471 - policy_categorical_accuracy: 0.3595 - value_mse: 0.0986\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.1946988105773926, 2.496814727783203, 0.6955363750457764, 0.37450000643730164, 0.11917424201965332]\n","epoch 151\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.1905 - policy_loss: 2.5434 - value_loss: 0.6448 - policy_categorical_accuracy: 0.3709 - value_mse: 0.0964\n","epoch 152\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 85ms/step - loss: 3.1935 - policy_loss: 2.5397 - value_loss: 0.6514 - policy_categorical_accuracy: 0.3669 - value_mse: 0.1006\n","epoch 153\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.1773 - policy_loss: 2.5273 - value_loss: 0.6477 - policy_categorical_accuracy: 0.3689 - value_mse: 0.1005\n","epoch 154\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1787 - policy_loss: 2.5285 - value_loss: 0.6480 - policy_categorical_accuracy: 0.3691 - value_mse: 0.0985\n","epoch 155\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.1782 - policy_loss: 2.5309 - value_loss: 0.6450 - policy_categorical_accuracy: 0.3688 - value_mse: 0.0977\n","epoch 156\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1904 - policy_loss: 2.5394 - value_loss: 0.6487 - policy_categorical_accuracy: 0.3656 - value_mse: 0.0996\n","epoch 157\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.1584 - policy_loss: 2.5130 - value_loss: 0.6431 - policy_categorical_accuracy: 0.3710 - value_mse: 0.0962\n","epoch 158\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1884 - policy_loss: 2.5385 - value_loss: 0.6475 - policy_categorical_accuracy: 0.3700 - value_mse: 0.1001\n","epoch 159\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1775 - policy_loss: 2.5272 - value_loss: 0.6480 - policy_categorical_accuracy: 0.3707 - value_mse: 0.0997\n","epoch 160\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1770 - policy_loss: 2.5267 - value_loss: 0.6480 - policy_categorical_accuracy: 0.3728 - value_mse: 0.0979\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.1882293224334717, 2.499363660812378, 0.686522364616394, 0.37459999322891235, 0.11507188528776169]\n","epoch 161\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1704 - policy_loss: 2.5233 - value_loss: 0.6448 - policy_categorical_accuracy: 0.3769 - value_mse: 0.0973\n","epoch 162\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1746 - policy_loss: 2.5296 - value_loss: 0.6426 - policy_categorical_accuracy: 0.3747 - value_mse: 0.0970\n","epoch 163\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1517 - policy_loss: 2.5050 - value_loss: 0.6443 - policy_categorical_accuracy: 0.3789 - value_mse: 0.0993\n","epoch 164\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.2015 - policy_loss: 2.5505 - value_loss: 0.6487 - policy_categorical_accuracy: 0.3596 - value_mse: 0.0969\n","epoch 165\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.1601 - policy_loss: 2.5100 - value_loss: 0.6478 - policy_categorical_accuracy: 0.3744 - value_mse: 0.0993\n","epoch 166\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1229 - policy_loss: 2.4750 - value_loss: 0.6456 - policy_categorical_accuracy: 0.3840 - value_mse: 0.0980\n","epoch 167\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.1842 - policy_loss: 2.5356 - value_loss: 0.6462 - policy_categorical_accuracy: 0.3675 - value_mse: 0.0979\n","epoch 168\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 75ms/step - loss: 3.1823 - policy_loss: 2.5375 - value_loss: 0.6425 - policy_categorical_accuracy: 0.3696 - value_mse: 0.0966\n","epoch 169\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1788 - policy_loss: 2.5286 - value_loss: 0.6479 - policy_categorical_accuracy: 0.3755 - value_mse: 0.0984\n","epoch 170\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1786 - policy_loss: 2.5267 - value_loss: 0.6496 - policy_categorical_accuracy: 0.3705 - value_mse: 0.0976\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.1639559268951416, 2.4975979328155518, 0.6640498638153076, 0.37770000100135803, 0.1061137244105339]\n","epoch 171\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1737 - policy_loss: 2.5283 - value_loss: 0.6431 - policy_categorical_accuracy: 0.3667 - value_mse: 0.0961\n","epoch 172\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.1482 - policy_loss: 2.4986 - value_loss: 0.6472 - policy_categorical_accuracy: 0.3753 - value_mse: 0.0994\n","epoch 173\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 84ms/step - loss: 3.1793 - policy_loss: 2.5303 - value_loss: 0.6466 - policy_categorical_accuracy: 0.3658 - value_mse: 0.0973\n","epoch 174\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 80ms/step - loss: 3.0962 - policy_loss: 2.4481 - value_loss: 0.6457 - policy_categorical_accuracy: 0.3829 - value_mse: 0.0989\n","epoch 175\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1658 - policy_loss: 2.5120 - value_loss: 0.6515 - policy_categorical_accuracy: 0.3699 - value_mse: 0.1018\n","epoch 176\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1690 - policy_loss: 2.5195 - value_loss: 0.6472 - policy_categorical_accuracy: 0.3764 - value_mse: 0.0979\n","epoch 177\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1841 - policy_loss: 2.5363 - value_loss: 0.6454 - policy_categorical_accuracy: 0.3708 - value_mse: 0.0968\n","epoch 178\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1976 - policy_loss: 2.5482 - value_loss: 0.6471 - policy_categorical_accuracy: 0.3625 - value_mse: 0.0976\n","epoch 179\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1812 - policy_loss: 2.5318 - value_loss: 0.6470 - policy_categorical_accuracy: 0.3747 - value_mse: 0.0986\n","epoch 180\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1596 - policy_loss: 2.5109 - value_loss: 0.6464 - policy_categorical_accuracy: 0.3711 - value_mse: 0.0989\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.1637277603149414, 2.477473735809326, 0.6838797926902771, 0.37869998812675476, 0.11277759075164795]\n","epoch 181\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.1589 - policy_loss: 2.5099 - value_loss: 0.6467 - policy_categorical_accuracy: 0.3728 - value_mse: 0.0980\n","epoch 182\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1897 - policy_loss: 2.5407 - value_loss: 0.6466 - policy_categorical_accuracy: 0.3623 - value_mse: 0.0998\n","epoch 183\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1324 - policy_loss: 2.4821 - value_loss: 0.6479 - policy_categorical_accuracy: 0.3816 - value_mse: 0.0989\n","epoch 184\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1694 - policy_loss: 2.5211 - value_loss: 0.6459 - policy_categorical_accuracy: 0.3709 - value_mse: 0.0979\n","epoch 185\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.1569 - policy_loss: 2.5065 - value_loss: 0.6480 - policy_categorical_accuracy: 0.3738 - value_mse: 0.0989\n","epoch 186\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1382 - policy_loss: 2.4936 - value_loss: 0.6423 - policy_categorical_accuracy: 0.3759 - value_mse: 0.0962\n","epoch 187\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1707 - policy_loss: 2.5203 - value_loss: 0.6481 - policy_categorical_accuracy: 0.3714 - value_mse: 0.0995\n","epoch 188\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1182 - policy_loss: 2.4714 - value_loss: 0.6444 - policy_categorical_accuracy: 0.3786 - value_mse: 0.0967\n","epoch 189\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1407 - policy_loss: 2.4961 - value_loss: 0.6422 - policy_categorical_accuracy: 0.3761 - value_mse: 0.0981\n","epoch 190\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.1110 - policy_loss: 2.4627 - value_loss: 0.6459 - policy_categorical_accuracy: 0.3801 - value_mse: 0.0998\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.1483800411224365, 2.488414764404297, 0.6575556993484497, 0.3736000061035156, 0.10366561263799667]\n","epoch 191\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1632 - policy_loss: 2.5181 - value_loss: 0.6427 - policy_categorical_accuracy: 0.3674 - value_mse: 0.0969\n","epoch 192\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1366 - policy_loss: 2.4865 - value_loss: 0.6477 - policy_categorical_accuracy: 0.3776 - value_mse: 0.0973\n","epoch 193\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1293 - policy_loss: 2.4775 - value_loss: 0.6495 - policy_categorical_accuracy: 0.3836 - value_mse: 0.0993\n","epoch 194\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 82ms/step - loss: 3.1597 - policy_loss: 2.5200 - value_loss: 0.6373 - policy_categorical_accuracy: 0.3662 - value_mse: 0.0946\n","epoch 195\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 78ms/step - loss: 3.1616 - policy_loss: 2.5074 - value_loss: 0.6518 - policy_categorical_accuracy: 0.3708 - value_mse: 0.1018\n","epoch 196\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1525 - policy_loss: 2.5024 - value_loss: 0.6477 - policy_categorical_accuracy: 0.3718 - value_mse: 0.0978\n","epoch 197\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1215 - policy_loss: 2.4715 - value_loss: 0.6477 - policy_categorical_accuracy: 0.3752 - value_mse: 0.0978\n","epoch 198\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1396 - policy_loss: 2.4921 - value_loss: 0.6451 - policy_categorical_accuracy: 0.3727 - value_mse: 0.0962\n","epoch 199\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1602 - policy_loss: 2.5077 - value_loss: 0.6500 - policy_categorical_accuracy: 0.3721 - value_mse: 0.1021\n","epoch 200\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1722 - policy_loss: 2.5260 - value_loss: 0.6438 - policy_categorical_accuracy: 0.3683 - value_mse: 0.0954\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.2836155891418457, 2.5740787982940674, 0.7071437239646912, 0.37380000948905945, 0.12226352840662003]\n","epoch 201\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1200 - policy_loss: 2.4714 - value_loss: 0.6462 - policy_categorical_accuracy: 0.3785 - value_mse: 0.0967\n","epoch 202\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1190 - policy_loss: 2.4718 - value_loss: 0.6448 - policy_categorical_accuracy: 0.3813 - value_mse: 0.0979\n","epoch 203\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1260 - policy_loss: 2.4778 - value_loss: 0.6458 - policy_categorical_accuracy: 0.3821 - value_mse: 0.0991\n","epoch 204\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1215 - policy_loss: 2.4777 - value_loss: 0.6414 - policy_categorical_accuracy: 0.3809 - value_mse: 0.0972\n","epoch 205\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.1393 - policy_loss: 2.4850 - value_loss: 0.6519 - policy_categorical_accuracy: 0.3800 - value_mse: 0.0984\n","epoch 206\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1371 - policy_loss: 2.4921 - value_loss: 0.6426 - policy_categorical_accuracy: 0.3762 - value_mse: 0.0943\n","epoch 207\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1254 - policy_loss: 2.4810 - value_loss: 0.6419 - policy_categorical_accuracy: 0.3763 - value_mse: 0.0979\n","epoch 208\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1599 - policy_loss: 2.5119 - value_loss: 0.6455 - policy_categorical_accuracy: 0.3738 - value_mse: 0.0961\n","epoch 209\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1104 - policy_loss: 2.4621 - value_loss: 0.6459 - policy_categorical_accuracy: 0.3775 - value_mse: 0.0998\n","epoch 210\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1361 - policy_loss: 2.4879 - value_loss: 0.6457 - policy_categorical_accuracy: 0.3708 - value_mse: 0.0986\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.1005475521087646, 2.4475772380828857, 0.6505395770072937, 0.38690000772476196, 0.10056179016828537]\n","epoch 211\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0970 - policy_loss: 2.4493 - value_loss: 0.6453 - policy_categorical_accuracy: 0.3840 - value_mse: 0.0984\n","epoch 212\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1098 - policy_loss: 2.4640 - value_loss: 0.6434 - policy_categorical_accuracy: 0.3805 - value_mse: 0.0964\n","epoch 213\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1118 - policy_loss: 2.4628 - value_loss: 0.6466 - policy_categorical_accuracy: 0.3786 - value_mse: 0.1011\n","epoch 214\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 81ms/step - loss: 3.1298 - policy_loss: 2.4843 - value_loss: 0.6431 - policy_categorical_accuracy: 0.3775 - value_mse: 0.0959\n","epoch 215\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 79ms/step - loss: 3.1284 - policy_loss: 2.4779 - value_loss: 0.6480 - policy_categorical_accuracy: 0.3765 - value_mse: 0.0978\n","epoch 216\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1109 - policy_loss: 2.4596 - value_loss: 0.6488 - policy_categorical_accuracy: 0.3785 - value_mse: 0.0993\n","epoch 217\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1063 - policy_loss: 2.4599 - value_loss: 0.6440 - policy_categorical_accuracy: 0.3783 - value_mse: 0.0968\n","epoch 218\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1253 - policy_loss: 2.4831 - value_loss: 0.6398 - policy_categorical_accuracy: 0.3780 - value_mse: 0.0951\n","epoch 219\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1271 - policy_loss: 2.4819 - value_loss: 0.6428 - policy_categorical_accuracy: 0.3784 - value_mse: 0.0960\n","epoch 220\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0892 - policy_loss: 2.4470 - value_loss: 0.6398 - policy_categorical_accuracy: 0.3772 - value_mse: 0.0965\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.096224784851074, 2.4468538761138916, 0.6468995809555054, 0.38260000944137573, 0.09904447942972183]\n","epoch 221\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1230 - policy_loss: 2.4786 - value_loss: 0.6420 - policy_categorical_accuracy: 0.3762 - value_mse: 0.0963\n","epoch 222\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0998 - policy_loss: 2.4532 - value_loss: 0.6441 - policy_categorical_accuracy: 0.3849 - value_mse: 0.0958\n","epoch 223\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1451 - policy_loss: 2.5052 - value_loss: 0.6374 - policy_categorical_accuracy: 0.3672 - value_mse: 0.0952\n","epoch 224\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1004 - policy_loss: 2.4534 - value_loss: 0.6446 - policy_categorical_accuracy: 0.3834 - value_mse: 0.0983\n","epoch 225\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0793 - policy_loss: 2.4287 - value_loss: 0.6482 - policy_categorical_accuracy: 0.3877 - value_mse: 0.0986\n","epoch 226\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0962 - policy_loss: 2.4473 - value_loss: 0.6464 - policy_categorical_accuracy: 0.3792 - value_mse: 0.0991\n","epoch 227\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1170 - policy_loss: 2.4656 - value_loss: 0.6490 - policy_categorical_accuracy: 0.3778 - value_mse: 0.1002\n","epoch 228\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1243 - policy_loss: 2.4807 - value_loss: 0.6412 - policy_categorical_accuracy: 0.3748 - value_mse: 0.0958\n","epoch 229\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1164 - policy_loss: 2.4716 - value_loss: 0.6424 - policy_categorical_accuracy: 0.3782 - value_mse: 0.0960\n","epoch 230\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0955 - policy_loss: 2.4453 - value_loss: 0.6477 - policy_categorical_accuracy: 0.3844 - value_mse: 0.0977\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.1115665435791016, 2.436685085296631, 0.6724497079849243, 0.3840000033378601, 0.10834990441799164]\n","epoch 231\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1063 - policy_loss: 2.4586 - value_loss: 0.6452 - policy_categorical_accuracy: 0.3835 - value_mse: 0.0958\n","epoch 232\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1171 - policy_loss: 2.4720 - value_loss: 0.6427 - policy_categorical_accuracy: 0.3750 - value_mse: 0.0964\n","epoch 233\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1524 - policy_loss: 2.5060 - value_loss: 0.6439 - policy_categorical_accuracy: 0.3678 - value_mse: 0.0965\n","epoch 234\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 80ms/step - loss: 3.1042 - policy_loss: 2.4587 - value_loss: 0.6430 - policy_categorical_accuracy: 0.3825 - value_mse: 0.0953\n","epoch 235\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 83ms/step - loss: 3.0772 - policy_loss: 2.4322 - value_loss: 0.6425 - policy_categorical_accuracy: 0.3871 - value_mse: 0.0946\n","epoch 236\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1048 - policy_loss: 2.4577 - value_loss: 0.6446 - policy_categorical_accuracy: 0.3738 - value_mse: 0.0973\n","epoch 237\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1336 - policy_loss: 2.4831 - value_loss: 0.6481 - policy_categorical_accuracy: 0.3764 - value_mse: 0.0987\n","epoch 238\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0892 - policy_loss: 2.4385 - value_loss: 0.6483 - policy_categorical_accuracy: 0.3841 - value_mse: 0.0985\n","epoch 239\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1001 - policy_loss: 2.4525 - value_loss: 0.6452 - policy_categorical_accuracy: 0.3856 - value_mse: 0.0979\n","epoch 240\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1101 - policy_loss: 2.4597 - value_loss: 0.6480 - policy_categorical_accuracy: 0.3762 - value_mse: 0.0991\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.1036322116851807, 2.4603676795959473, 0.640878438949585, 0.38989999890327454, 0.09614954888820648]\n","epoch 241\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1054 - policy_loss: 2.4579 - value_loss: 0.6452 - policy_categorical_accuracy: 0.3797 - value_mse: 0.0966\n","epoch 242\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1044 - policy_loss: 2.4612 - value_loss: 0.6409 - policy_categorical_accuracy: 0.3748 - value_mse: 0.0962\n","epoch 243\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0999 - policy_loss: 2.4538 - value_loss: 0.6437 - policy_categorical_accuracy: 0.3843 - value_mse: 0.0972\n","epoch 244\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1029 - policy_loss: 2.4570 - value_loss: 0.6435 - policy_categorical_accuracy: 0.3723 - value_mse: 0.0971\n","epoch 245\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.1198 - policy_loss: 2.4749 - value_loss: 0.6425 - policy_categorical_accuracy: 0.3751 - value_mse: 0.0965\n","epoch 246\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1133 - policy_loss: 2.4711 - value_loss: 0.6398 - policy_categorical_accuracy: 0.3820 - value_mse: 0.0940\n","epoch 247\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1113 - policy_loss: 2.4557 - value_loss: 0.6532 - policy_categorical_accuracy: 0.3851 - value_mse: 0.1007\n","epoch 248\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0505 - policy_loss: 2.4062 - value_loss: 0.6419 - policy_categorical_accuracy: 0.3916 - value_mse: 0.0959\n","epoch 249\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0806 - policy_loss: 2.4373 - value_loss: 0.6409 - policy_categorical_accuracy: 0.3861 - value_mse: 0.0954\n","epoch 250\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0832 - policy_loss: 2.4390 - value_loss: 0.6418 - policy_categorical_accuracy: 0.3791 - value_mse: 0.0971\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.136993408203125, 2.4283204078674316, 0.706247091293335, 0.38280001282691956, 0.1228155791759491]\n","epoch 251\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0812 - policy_loss: 2.4348 - value_loss: 0.6439 - policy_categorical_accuracy: 0.3890 - value_mse: 0.0961\n","epoch 252\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0696 - policy_loss: 2.4279 - value_loss: 0.6393 - policy_categorical_accuracy: 0.3841 - value_mse: 0.0943\n","epoch 253\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0705 - policy_loss: 2.4279 - value_loss: 0.6401 - policy_categorical_accuracy: 0.3845 - value_mse: 0.0977\n","epoch 254\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1007 - policy_loss: 2.4559 - value_loss: 0.6423 - policy_categorical_accuracy: 0.3787 - value_mse: 0.0969\n","epoch 255\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1022 - policy_loss: 2.4591 - value_loss: 0.6406 - policy_categorical_accuracy: 0.3768 - value_mse: 0.0967\n","epoch 256\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 84ms/step - loss: 3.0912 - policy_loss: 2.4402 - value_loss: 0.6485 - policy_categorical_accuracy: 0.3854 - value_mse: 0.0985\n","epoch 257\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 83ms/step - loss: 3.0926 - policy_loss: 2.4403 - value_loss: 0.6499 - policy_categorical_accuracy: 0.3813 - value_mse: 0.1006\n","epoch 258\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0960 - policy_loss: 2.4530 - value_loss: 0.6405 - policy_categorical_accuracy: 0.3735 - value_mse: 0.0941\n","epoch 259\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0981 - policy_loss: 2.4582 - value_loss: 0.6374 - policy_categorical_accuracy: 0.3836 - value_mse: 0.0931\n","epoch 260\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1244 - policy_loss: 2.4849 - value_loss: 0.6370 - policy_categorical_accuracy: 0.3744 - value_mse: 0.0948\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.0755112171173096, 2.433642864227295, 0.639333963394165, 0.38690000772476196, 0.09560534358024597]\n","epoch 261\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0620 - policy_loss: 2.4151 - value_loss: 0.6444 - policy_categorical_accuracy: 0.3865 - value_mse: 0.0985\n","epoch 262\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0708 - policy_loss: 2.4258 - value_loss: 0.6425 - policy_categorical_accuracy: 0.3827 - value_mse: 0.0957\n","epoch 263\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1020 - policy_loss: 2.4543 - value_loss: 0.6452 - policy_categorical_accuracy: 0.3765 - value_mse: 0.0975\n","epoch 264\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0676 - policy_loss: 2.4189 - value_loss: 0.6462 - policy_categorical_accuracy: 0.3879 - value_mse: 0.0972\n","epoch 265\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0847 - policy_loss: 2.4379 - value_loss: 0.6442 - policy_categorical_accuracy: 0.3852 - value_mse: 0.0975\n","epoch 266\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0820 - policy_loss: 2.4371 - value_loss: 0.6425 - policy_categorical_accuracy: 0.3809 - value_mse: 0.0958\n","epoch 267\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0485 - policy_loss: 2.4055 - value_loss: 0.6405 - policy_categorical_accuracy: 0.3920 - value_mse: 0.0965\n","epoch 268\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0599 - policy_loss: 2.4104 - value_loss: 0.6471 - policy_categorical_accuracy: 0.3873 - value_mse: 0.0972\n","epoch 269\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0779 - policy_loss: 2.4309 - value_loss: 0.6445 - policy_categorical_accuracy: 0.3831 - value_mse: 0.0959\n","epoch 270\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0794 - policy_loss: 2.4297 - value_loss: 0.6473 - policy_categorical_accuracy: 0.3896 - value_mse: 0.0968\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.0599327087402344, 2.4146997928619385, 0.6427651047706604, 0.38760000467300415, 0.09698197990655899]\n","epoch 271\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0780 - policy_loss: 2.4315 - value_loss: 0.6440 - policy_categorical_accuracy: 0.3873 - value_mse: 0.0972\n","epoch 272\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0574 - policy_loss: 2.4116 - value_loss: 0.6433 - policy_categorical_accuracy: 0.3901 - value_mse: 0.0962\n","epoch 273\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.1006 - policy_loss: 2.4572 - value_loss: 0.6409 - policy_categorical_accuracy: 0.3787 - value_mse: 0.0957\n","epoch 274\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 85ms/step - loss: 3.0762 - policy_loss: 2.4298 - value_loss: 0.6439 - policy_categorical_accuracy: 0.3871 - value_mse: 0.0975\n","epoch 275\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0787 - policy_loss: 2.4353 - value_loss: 0.6409 - policy_categorical_accuracy: 0.3864 - value_mse: 0.0966\n","epoch 276\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0661 - policy_loss: 2.4210 - value_loss: 0.6426 - policy_categorical_accuracy: 0.3791 - value_mse: 0.0971\n","epoch 277\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0866 - policy_loss: 2.4443 - value_loss: 0.6398 - policy_categorical_accuracy: 0.3784 - value_mse: 0.0947\n","epoch 278\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0924 - policy_loss: 2.4479 - value_loss: 0.6420 - policy_categorical_accuracy: 0.3809 - value_mse: 0.0948\n","epoch 279\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0701 - policy_loss: 2.4254 - value_loss: 0.6422 - policy_categorical_accuracy: 0.3857 - value_mse: 0.0957\n","epoch 280\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0440 - policy_loss: 2.4025 - value_loss: 0.6390 - policy_categorical_accuracy: 0.3880 - value_mse: 0.0953\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.0480973720550537, 2.404491901397705, 0.641083300113678, 0.39259999990463257, 0.0963621735572815]\n","epoch 281\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0200 - policy_loss: 2.3770 - value_loss: 0.6405 - policy_categorical_accuracy: 0.3918 - value_mse: 0.0958\n","epoch 282\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0673 - policy_loss: 2.4235 - value_loss: 0.6412 - policy_categorical_accuracy: 0.3902 - value_mse: 0.0959\n","epoch 283\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0933 - policy_loss: 2.4454 - value_loss: 0.6454 - policy_categorical_accuracy: 0.3801 - value_mse: 0.0969\n","epoch 284\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0814 - policy_loss: 2.4356 - value_loss: 0.6433 - policy_categorical_accuracy: 0.3830 - value_mse: 0.0957\n","epoch 285\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0819 - policy_loss: 2.4386 - value_loss: 0.6408 - policy_categorical_accuracy: 0.3871 - value_mse: 0.0966\n","epoch 286\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0159 - policy_loss: 2.3734 - value_loss: 0.6400 - policy_categorical_accuracy: 0.4015 - value_mse: 0.0949\n","epoch 287\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0427 - policy_loss: 2.3999 - value_loss: 0.6402 - policy_categorical_accuracy: 0.3839 - value_mse: 0.0949\n","epoch 288\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0734 - policy_loss: 2.4306 - value_loss: 0.6403 - policy_categorical_accuracy: 0.3866 - value_mse: 0.0950\n","epoch 289\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0603 - policy_loss: 2.4203 - value_loss: 0.6374 - policy_categorical_accuracy: 0.3852 - value_mse: 0.0922\n","epoch 290\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0689 - policy_loss: 2.4246 - value_loss: 0.6418 - policy_categorical_accuracy: 0.3851 - value_mse: 0.0971\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.058305025100708, 2.4076008796691895, 0.6481541991233826, 0.38850000500679016, 0.09911222010850906]\n","epoch 291\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0860 - policy_loss: 2.4394 - value_loss: 0.6440 - policy_categorical_accuracy: 0.3842 - value_mse: 0.0966\n","epoch 292\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0909 - policy_loss: 2.4433 - value_loss: 0.6450 - policy_categorical_accuracy: 0.3813 - value_mse: 0.0979\n","epoch 293\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 84ms/step - loss: 3.0447 - policy_loss: 2.4055 - value_loss: 0.6366 - policy_categorical_accuracy: 0.3844 - value_mse: 0.0948\n","epoch 294\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 83ms/step - loss: 3.0738 - policy_loss: 2.4268 - value_loss: 0.6445 - policy_categorical_accuracy: 0.3880 - value_mse: 0.0952\n","epoch 295\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0356 - policy_loss: 2.3883 - value_loss: 0.6447 - policy_categorical_accuracy: 0.3881 - value_mse: 0.0968\n","epoch 296\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0700 - policy_loss: 2.4208 - value_loss: 0.6467 - policy_categorical_accuracy: 0.3842 - value_mse: 0.0983\n","epoch 297\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0820 - policy_loss: 2.4407 - value_loss: 0.6387 - policy_categorical_accuracy: 0.3868 - value_mse: 0.0943\n","epoch 298\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0588 - policy_loss: 2.4126 - value_loss: 0.6436 - policy_categorical_accuracy: 0.3839 - value_mse: 0.0993\n","epoch 299\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0528 - policy_loss: 2.4081 - value_loss: 0.6422 - policy_categorical_accuracy: 0.3856 - value_mse: 0.0964\n","epoch 300\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0670 - policy_loss: 2.4208 - value_loss: 0.6437 - policy_categorical_accuracy: 0.3865 - value_mse: 0.0974\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.0428097248077393, 2.3963654041290283, 0.6439276337623596, 0.3944999873638153, 0.09753645956516266]\n","epoch 301\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0530 - policy_loss: 2.4106 - value_loss: 0.6399 - policy_categorical_accuracy: 0.3843 - value_mse: 0.0954\n","epoch 302\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0485 - policy_loss: 2.4029 - value_loss: 0.6431 - policy_categorical_accuracy: 0.3932 - value_mse: 0.0975\n","epoch 303\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0626 - policy_loss: 2.4160 - value_loss: 0.6441 - policy_categorical_accuracy: 0.3880 - value_mse: 0.0966\n","epoch 304\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0497 - policy_loss: 2.4033 - value_loss: 0.6439 - policy_categorical_accuracy: 0.3918 - value_mse: 0.0969\n","epoch 305\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0571 - policy_loss: 2.4174 - value_loss: 0.6371 - policy_categorical_accuracy: 0.3781 - value_mse: 0.0935\n","epoch 306\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0421 - policy_loss: 2.3975 - value_loss: 0.6421 - policy_categorical_accuracy: 0.3889 - value_mse: 0.0953\n","epoch 307\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0412 - policy_loss: 2.4002 - value_loss: 0.6384 - policy_categorical_accuracy: 0.3878 - value_mse: 0.0969\n","epoch 308\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0803 - policy_loss: 2.4319 - value_loss: 0.6459 - policy_categorical_accuracy: 0.3860 - value_mse: 0.0982\n","epoch 309\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0533 - policy_loss: 2.4120 - value_loss: 0.6388 - policy_categorical_accuracy: 0.3839 - value_mse: 0.0964\n","epoch 310\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0328 - policy_loss: 2.3896 - value_loss: 0.6407 - policy_categorical_accuracy: 0.3894 - value_mse: 0.0948\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.0447332859039307, 2.37736177444458, 0.6648569107055664, 0.3912000060081482, 0.10534629225730896]\n","epoch 311\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0479 - policy_loss: 2.4024 - value_loss: 0.6429 - policy_categorical_accuracy: 0.3869 - value_mse: 0.0957\n","epoch 312\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 78ms/step - loss: 3.0319 - policy_loss: 2.3888 - value_loss: 0.6406 - policy_categorical_accuracy: 0.3914 - value_mse: 0.0959\n","epoch 313\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 84ms/step - loss: 3.0261 - policy_loss: 2.3850 - value_loss: 0.6386 - policy_categorical_accuracy: 0.3873 - value_mse: 0.0964\n","epoch 314\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0699 - policy_loss: 2.4297 - value_loss: 0.6376 - policy_categorical_accuracy: 0.3815 - value_mse: 0.0949\n","epoch 315\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0465 - policy_loss: 2.4042 - value_loss: 0.6398 - policy_categorical_accuracy: 0.3858 - value_mse: 0.0961\n","epoch 316\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0558 - policy_loss: 2.4102 - value_loss: 0.6430 - policy_categorical_accuracy: 0.3817 - value_mse: 0.0948\n","epoch 317\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0382 - policy_loss: 2.3965 - value_loss: 0.6391 - policy_categorical_accuracy: 0.3912 - value_mse: 0.0952\n","epoch 318\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0673 - policy_loss: 2.4238 - value_loss: 0.6410 - policy_categorical_accuracy: 0.3797 - value_mse: 0.0966\n","epoch 319\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0757 - policy_loss: 2.4315 - value_loss: 0.6416 - policy_categorical_accuracy: 0.3764 - value_mse: 0.0964\n","epoch 320\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0196 - policy_loss: 2.3761 - value_loss: 0.6410 - policy_categorical_accuracy: 0.3920 - value_mse: 0.0950\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.0365405082702637, 2.3884875774383545, 0.6454808115959167, 0.3903000056743622, 0.09857857972383499]\n","epoch 321\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0223 - policy_loss: 2.3798 - value_loss: 0.6400 - policy_categorical_accuracy: 0.3938 - value_mse: 0.0941\n","epoch 322\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0365 - policy_loss: 2.3962 - value_loss: 0.6378 - policy_categorical_accuracy: 0.3884 - value_mse: 0.0934\n","epoch 323\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0626 - policy_loss: 2.4183 - value_loss: 0.6416 - policy_categorical_accuracy: 0.3788 - value_mse: 0.0951\n","epoch 324\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0119 - policy_loss: 2.3712 - value_loss: 0.6382 - policy_categorical_accuracy: 0.3889 - value_mse: 0.0951\n","epoch 325\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0279 - policy_loss: 2.3863 - value_loss: 0.6390 - policy_categorical_accuracy: 0.3903 - value_mse: 0.0937\n","epoch 326\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0440 - policy_loss: 2.4054 - value_loss: 0.6360 - policy_categorical_accuracy: 0.3877 - value_mse: 0.0933\n","epoch 327\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0299 - policy_loss: 2.3861 - value_loss: 0.6412 - policy_categorical_accuracy: 0.3881 - value_mse: 0.0970\n","epoch 328\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0228 - policy_loss: 2.3799 - value_loss: 0.6403 - policy_categorical_accuracy: 0.3933 - value_mse: 0.0951\n","epoch 329\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0739 - policy_loss: 2.4281 - value_loss: 0.6432 - policy_categorical_accuracy: 0.3801 - value_mse: 0.0961\n","epoch 330\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0557 - policy_loss: 2.4108 - value_loss: 0.6423 - policy_categorical_accuracy: 0.3818 - value_mse: 0.0941\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.037605047225952, 2.3838791847229004, 0.6511472463607788, 0.39239999651908875, 0.10091470181941986]\n","epoch 331\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 83ms/step - loss: 3.0579 - policy_loss: 2.4180 - value_loss: 0.6374 - policy_categorical_accuracy: 0.3816 - value_mse: 0.0935\n","epoch 332\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0291 - policy_loss: 2.3807 - value_loss: 0.6458 - policy_categorical_accuracy: 0.3887 - value_mse: 0.0971\n","epoch 333\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0444 - policy_loss: 2.4021 - value_loss: 0.6398 - policy_categorical_accuracy: 0.3905 - value_mse: 0.0958\n","epoch 334\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0441 - policy_loss: 2.3955 - value_loss: 0.6460 - policy_categorical_accuracy: 0.3840 - value_mse: 0.0970\n","epoch 335\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0384 - policy_loss: 2.3947 - value_loss: 0.6412 - policy_categorical_accuracy: 0.3865 - value_mse: 0.0969\n","epoch 336\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0273 - policy_loss: 2.3843 - value_loss: 0.6405 - policy_categorical_accuracy: 0.3895 - value_mse: 0.0988\n","epoch 337\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0195 - policy_loss: 2.3804 - value_loss: 0.6366 - policy_categorical_accuracy: 0.3899 - value_mse: 0.0963\n","epoch 338\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0234 - policy_loss: 2.3837 - value_loss: 0.6371 - policy_categorical_accuracy: 0.3929 - value_mse: 0.0956\n","epoch 339\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0407 - policy_loss: 2.3970 - value_loss: 0.6411 - policy_categorical_accuracy: 0.3897 - value_mse: 0.0947\n","epoch 340\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0401 - policy_loss: 2.3967 - value_loss: 0.6408 - policy_categorical_accuracy: 0.3892 - value_mse: 0.0947\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.026785373687744, 2.3542118072509766, 0.6700053811073303, 0.39160001277923584, 0.10791002213954926]\n","epoch 341\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0149 - policy_loss: 2.3689 - value_loss: 0.6434 - policy_categorical_accuracy: 0.3952 - value_mse: 0.0961\n","epoch 342\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0527 - policy_loss: 2.4082 - value_loss: 0.6419 - policy_categorical_accuracy: 0.3831 - value_mse: 0.0973\n","epoch 343\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0308 - policy_loss: 2.3894 - value_loss: 0.6388 - policy_categorical_accuracy: 0.3883 - value_mse: 0.0930\n","epoch 344\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0475 - policy_loss: 2.4087 - value_loss: 0.6363 - policy_categorical_accuracy: 0.3856 - value_mse: 0.0931\n","epoch 345\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0196 - policy_loss: 2.3747 - value_loss: 0.6424 - policy_categorical_accuracy: 0.3922 - value_mse: 0.0957\n","epoch 346\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0421 - policy_loss: 2.3976 - value_loss: 0.6419 - policy_categorical_accuracy: 0.3944 - value_mse: 0.0961\n","epoch 347\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 78ms/step - loss: 3.0351 - policy_loss: 2.3926 - value_loss: 0.6399 - policy_categorical_accuracy: 0.3882 - value_mse: 0.0957\n","epoch 348\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 82ms/step - loss: 3.0066 - policy_loss: 2.3717 - value_loss: 0.6324 - policy_categorical_accuracy: 0.3905 - value_mse: 0.0925\n","epoch 349\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0209 - policy_loss: 2.3772 - value_loss: 0.6411 - policy_categorical_accuracy: 0.3918 - value_mse: 0.0964\n","epoch 350\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0299 - policy_loss: 2.3892 - value_loss: 0.6382 - policy_categorical_accuracy: 0.3890 - value_mse: 0.0950\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.0453498363494873, 2.3674516677856445, 0.675319492816925, 0.3946000039577484, 0.11174458265304565]\n","epoch 351\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0271 - policy_loss: 2.3895 - value_loss: 0.6350 - policy_categorical_accuracy: 0.3883 - value_mse: 0.0930\n","epoch 352\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9927 - policy_loss: 2.3491 - value_loss: 0.6410 - policy_categorical_accuracy: 0.3943 - value_mse: 0.0965\n","epoch 353\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0154 - policy_loss: 2.3720 - value_loss: 0.6408 - policy_categorical_accuracy: 0.3979 - value_mse: 0.0945\n","epoch 354\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0510 - policy_loss: 2.4118 - value_loss: 0.6366 - policy_categorical_accuracy: 0.3772 - value_mse: 0.0933\n","epoch 355\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0282 - policy_loss: 2.3883 - value_loss: 0.6373 - policy_categorical_accuracy: 0.3926 - value_mse: 0.0942\n","epoch 356\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0225 - policy_loss: 2.3845 - value_loss: 0.6354 - policy_categorical_accuracy: 0.3888 - value_mse: 0.0937\n","epoch 357\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0378 - policy_loss: 2.3968 - value_loss: 0.6383 - policy_categorical_accuracy: 0.3874 - value_mse: 0.0958\n","epoch 358\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0177 - policy_loss: 2.3738 - value_loss: 0.6413 - policy_categorical_accuracy: 0.3931 - value_mse: 0.0975\n","epoch 359\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0226 - policy_loss: 2.3843 - value_loss: 0.6357 - policy_categorical_accuracy: 0.3843 - value_mse: 0.0947\n","epoch 360\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0234 - policy_loss: 2.3798 - value_loss: 0.6409 - policy_categorical_accuracy: 0.3931 - value_mse: 0.0962\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9945623874664307, 2.3536086082458496, 0.6382723450660706, 0.39980000257492065, 0.09526140987873077]\n","epoch 361\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0195 - policy_loss: 2.3795 - value_loss: 0.6373 - policy_categorical_accuracy: 0.3900 - value_mse: 0.0940\n","epoch 362\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0203 - policy_loss: 2.3794 - value_loss: 0.6382 - policy_categorical_accuracy: 0.3927 - value_mse: 0.0957\n","epoch 363\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0309 - policy_loss: 2.3876 - value_loss: 0.6406 - policy_categorical_accuracy: 0.3915 - value_mse: 0.0951\n","epoch 364\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 84ms/step - loss: 2.9923 - policy_loss: 2.3519 - value_loss: 0.6378 - policy_categorical_accuracy: 0.3923 - value_mse: 0.0945\n","epoch 365\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0254 - policy_loss: 2.3865 - value_loss: 0.6363 - policy_categorical_accuracy: 0.3881 - value_mse: 0.0961\n","epoch 366\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0553 - policy_loss: 2.4118 - value_loss: 0.6408 - policy_categorical_accuracy: 0.3858 - value_mse: 0.0968\n","epoch 367\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0364 - policy_loss: 2.3911 - value_loss: 0.6427 - policy_categorical_accuracy: 0.3832 - value_mse: 0.0955\n","epoch 368\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0204 - policy_loss: 2.3772 - value_loss: 0.6406 - policy_categorical_accuracy: 0.3926 - value_mse: 0.0954\n","epoch 369\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0230 - policy_loss: 2.3825 - value_loss: 0.6378 - policy_categorical_accuracy: 0.3932 - value_mse: 0.0961\n","epoch 370\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0090 - policy_loss: 2.3695 - value_loss: 0.6369 - policy_categorical_accuracy: 0.3966 - value_mse: 0.0965\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.014051675796509, 2.3404078483581543, 0.6710014939308167, 0.3959999978542328, 0.10855819284915924]\n","epoch 371\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0328 - policy_loss: 2.3889 - value_loss: 0.6412 - policy_categorical_accuracy: 0.3902 - value_mse: 0.0965\n","epoch 372\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0209 - policy_loss: 2.3820 - value_loss: 0.6363 - policy_categorical_accuracy: 0.3906 - value_mse: 0.0943\n","epoch 373\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0462 - policy_loss: 2.4011 - value_loss: 0.6425 - policy_categorical_accuracy: 0.3921 - value_mse: 0.0958\n","epoch 374\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0106 - policy_loss: 2.3672 - value_loss: 0.6408 - policy_categorical_accuracy: 0.3917 - value_mse: 0.0974\n","epoch 375\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9907 - policy_loss: 2.3500 - value_loss: 0.6381 - policy_categorical_accuracy: 0.3959 - value_mse: 0.0951\n","epoch 376\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0157 - policy_loss: 2.3767 - value_loss: 0.6363 - policy_categorical_accuracy: 0.3923 - value_mse: 0.0938\n","epoch 377\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0288 - policy_loss: 2.3874 - value_loss: 0.6388 - policy_categorical_accuracy: 0.3925 - value_mse: 0.0935\n","epoch 378\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0175 - policy_loss: 2.3735 - value_loss: 0.6413 - policy_categorical_accuracy: 0.3875 - value_mse: 0.0969\n","epoch 379\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0259 - policy_loss: 2.3805 - value_loss: 0.6428 - policy_categorical_accuracy: 0.3960 - value_mse: 0.0964\n","epoch 380\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9891 - policy_loss: 2.3530 - value_loss: 0.6334 - policy_categorical_accuracy: 0.3999 - value_mse: 0.0936\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.0382916927337646, 2.365431070327759, 0.6701573133468628, 0.4016000032424927, 0.10886666178703308]\n","epoch 381\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0146 - policy_loss: 2.3748 - value_loss: 0.6370 - policy_categorical_accuracy: 0.3944 - value_mse: 0.0951\n","epoch 382\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 81ms/step - loss: 3.0162 - policy_loss: 2.3753 - value_loss: 0.6382 - policy_categorical_accuracy: 0.3866 - value_mse: 0.0963\n","epoch 383\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0198 - policy_loss: 2.3824 - value_loss: 0.6347 - policy_categorical_accuracy: 0.3929 - value_mse: 0.0950\n","epoch 384\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0016 - policy_loss: 2.3607 - value_loss: 0.6382 - policy_categorical_accuracy: 0.3994 - value_mse: 0.0949\n","epoch 385\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9994 - policy_loss: 2.3538 - value_loss: 0.6429 - policy_categorical_accuracy: 0.3911 - value_mse: 0.0959\n","epoch 386\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0283 - policy_loss: 2.3830 - value_loss: 0.6427 - policy_categorical_accuracy: 0.3869 - value_mse: 0.0970\n","epoch 387\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0219 - policy_loss: 2.3757 - value_loss: 0.6436 - policy_categorical_accuracy: 0.3918 - value_mse: 0.0956\n","epoch 388\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9891 - policy_loss: 2.3388 - value_loss: 0.6476 - policy_categorical_accuracy: 0.3987 - value_mse: 0.0966\n","epoch 389\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0383 - policy_loss: 2.3934 - value_loss: 0.6423 - policy_categorical_accuracy: 0.3814 - value_mse: 0.0950\n","epoch 390\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0147 - policy_loss: 2.3727 - value_loss: 0.6394 - policy_categorical_accuracy: 0.3902 - value_mse: 0.0929\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.966754198074341, 2.323503017425537, 0.6406415700912476, 0.4025000035762787, 0.09598974138498306]\n","epoch 391\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9956 - policy_loss: 2.3593 - value_loss: 0.6336 - policy_categorical_accuracy: 0.3915 - value_mse: 0.0940\n","epoch 392\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0157 - policy_loss: 2.3800 - value_loss: 0.6330 - policy_categorical_accuracy: 0.3878 - value_mse: 0.0938\n","epoch 393\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0029 - policy_loss: 2.3569 - value_loss: 0.6433 - policy_categorical_accuracy: 0.3957 - value_mse: 0.0979\n","epoch 394\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0135 - policy_loss: 2.3709 - value_loss: 0.6399 - policy_categorical_accuracy: 0.3992 - value_mse: 0.0957\n","epoch 395\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0139 - policy_loss: 2.3755 - value_loss: 0.6357 - policy_categorical_accuracy: 0.3918 - value_mse: 0.0937\n","epoch 396\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9845 - policy_loss: 2.3428 - value_loss: 0.6390 - policy_categorical_accuracy: 0.4044 - value_mse: 0.0945\n","epoch 397\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0107 - policy_loss: 2.3681 - value_loss: 0.6399 - policy_categorical_accuracy: 0.3974 - value_mse: 0.0957\n","epoch 398\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9827 - policy_loss: 2.3454 - value_loss: 0.6346 - policy_categorical_accuracy: 0.3879 - value_mse: 0.0920\n","epoch 399\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9926 - policy_loss: 2.3500 - value_loss: 0.6400 - policy_categorical_accuracy: 0.3983 - value_mse: 0.0963\n","epoch 400\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9769 - policy_loss: 2.3352 - value_loss: 0.6390 - policy_categorical_accuracy: 0.3974 - value_mse: 0.0948\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9725093841552734, 2.3347008228302, 0.6350777745246887, 0.3991999924182892, 0.09376855194568634]\n","epoch 401\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 84ms/step - loss: 2.9742 - policy_loss: 2.3356 - value_loss: 0.6359 - policy_categorical_accuracy: 0.4000 - value_mse: 0.0921\n","epoch 402\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 82ms/step - loss: 3.0048 - policy_loss: 2.3624 - value_loss: 0.6397 - policy_categorical_accuracy: 0.3944 - value_mse: 0.0921\n","epoch 403\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9954 - policy_loss: 2.3533 - value_loss: 0.6394 - policy_categorical_accuracy: 0.3924 - value_mse: 0.0936\n","epoch 404\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0152 - policy_loss: 2.3706 - value_loss: 0.6419 - policy_categorical_accuracy: 0.3914 - value_mse: 0.0956\n","epoch 405\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0147 - policy_loss: 2.3750 - value_loss: 0.6370 - policy_categorical_accuracy: 0.3864 - value_mse: 0.0938\n","epoch 406\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9881 - policy_loss: 2.3502 - value_loss: 0.6351 - policy_categorical_accuracy: 0.4038 - value_mse: 0.0935\n","epoch 407\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0086 - policy_loss: 2.3720 - value_loss: 0.6338 - policy_categorical_accuracy: 0.3891 - value_mse: 0.0925\n","epoch 408\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0169 - policy_loss: 2.3721 - value_loss: 0.6421 - policy_categorical_accuracy: 0.3878 - value_mse: 0.0969\n","epoch 409\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0306 - policy_loss: 2.3854 - value_loss: 0.6424 - policy_categorical_accuracy: 0.3800 - value_mse: 0.0959\n","epoch 410\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9920 - policy_loss: 2.3468 - value_loss: 0.6424 - policy_categorical_accuracy: 0.3934 - value_mse: 0.0969\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.0169262886047363, 2.3593380451202393, 0.6548066139221191, 0.4016999900341034, 0.10251762717962265]\n","epoch 411\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0120 - policy_loss: 2.3660 - value_loss: 0.6433 - policy_categorical_accuracy: 0.3954 - value_mse: 0.0965\n","epoch 412\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0244 - policy_loss: 2.3857 - value_loss: 0.6359 - policy_categorical_accuracy: 0.3943 - value_mse: 0.0937\n","epoch 413\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0125 - policy_loss: 2.3731 - value_loss: 0.6367 - policy_categorical_accuracy: 0.3956 - value_mse: 0.0954\n","epoch 414\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0149 - policy_loss: 2.3678 - value_loss: 0.6443 - policy_categorical_accuracy: 0.3901 - value_mse: 0.0965\n","epoch 415\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9704 - policy_loss: 2.3314 - value_loss: 0.6363 - policy_categorical_accuracy: 0.4006 - value_mse: 0.0950\n","epoch 416\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9994 - policy_loss: 2.3625 - value_loss: 0.6340 - policy_categorical_accuracy: 0.3940 - value_mse: 0.0926\n","epoch 417\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9845 - policy_loss: 2.3442 - value_loss: 0.6375 - policy_categorical_accuracy: 0.3899 - value_mse: 0.0957\n","epoch 418\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9611 - policy_loss: 2.3234 - value_loss: 0.6349 - policy_categorical_accuracy: 0.3979 - value_mse: 0.0925\n","epoch 419\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9988 - policy_loss: 2.3550 - value_loss: 0.6410 - policy_categorical_accuracy: 0.3932 - value_mse: 0.0932\n","epoch 420\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0285 - policy_loss: 2.3843 - value_loss: 0.6414 - policy_categorical_accuracy: 0.3899 - value_mse: 0.0958\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.974376678466797, 2.32060170173645, 0.650993287563324, 0.3993000090122223, 0.1005568876862526]\n","epoch 421\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9955 - policy_loss: 2.3509 - value_loss: 0.6419 - policy_categorical_accuracy: 0.3932 - value_mse: 0.0970\n","epoch 422\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9948 - policy_loss: 2.3590 - value_loss: 0.6330 - policy_categorical_accuracy: 0.3967 - value_mse: 0.0928\n","epoch 423\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0170 - policy_loss: 2.3774 - value_loss: 0.6369 - policy_categorical_accuracy: 0.3964 - value_mse: 0.0946\n","epoch 424\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9933 - policy_loss: 2.3551 - value_loss: 0.6355 - policy_categorical_accuracy: 0.3923 - value_mse: 0.0957\n","epoch 425\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0371 - policy_loss: 2.3926 - value_loss: 0.6418 - policy_categorical_accuracy: 0.3859 - value_mse: 0.0962\n","epoch 426\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0309 - policy_loss: 2.3866 - value_loss: 0.6415 - policy_categorical_accuracy: 0.3939 - value_mse: 0.0955\n","epoch 427\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0133 - policy_loss: 2.3737 - value_loss: 0.6368 - policy_categorical_accuracy: 0.3894 - value_mse: 0.0942\n","epoch 428\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9916 - policy_loss: 2.3463 - value_loss: 0.6425 - policy_categorical_accuracy: 0.3990 - value_mse: 0.0965\n","epoch 429\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9921 - policy_loss: 2.3513 - value_loss: 0.6381 - policy_categorical_accuracy: 0.3967 - value_mse: 0.0933\n","epoch 430\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9553 - policy_loss: 2.3185 - value_loss: 0.6340 - policy_categorical_accuracy: 0.3939 - value_mse: 0.0938\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.988280773162842, 2.3461368083953857, 0.6393589973449707, 0.4034000039100647, 0.09564098715782166]\n","epoch 431\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9575 - policy_loss: 2.3225 - value_loss: 0.6322 - policy_categorical_accuracy: 0.4073 - value_mse: 0.0911\n","epoch 432\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9869 - policy_loss: 2.3434 - value_loss: 0.6407 - policy_categorical_accuracy: 0.3987 - value_mse: 0.0960\n","epoch 433\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9818 - policy_loss: 2.3415 - value_loss: 0.6375 - policy_categorical_accuracy: 0.3957 - value_mse: 0.0943\n","epoch 434\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9790 - policy_loss: 2.3430 - value_loss: 0.6332 - policy_categorical_accuracy: 0.3975 - value_mse: 0.0930\n","epoch 435\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9678 - policy_loss: 2.3302 - value_loss: 0.6348 - policy_categorical_accuracy: 0.3993 - value_mse: 0.0929\n","epoch 436\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9869 - policy_loss: 2.3461 - value_loss: 0.6380 - policy_categorical_accuracy: 0.3978 - value_mse: 0.0955\n","epoch 437\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9995 - policy_loss: 2.3583 - value_loss: 0.6383 - policy_categorical_accuracy: 0.3997 - value_mse: 0.0939\n","epoch 438\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0217 - policy_loss: 2.3829 - value_loss: 0.6359 - policy_categorical_accuracy: 0.3837 - value_mse: 0.0942\n","epoch 439\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 84ms/step - loss: 2.9865 - policy_loss: 2.3439 - value_loss: 0.6397 - policy_categorical_accuracy: 0.3961 - value_mse: 0.0925\n","epoch 440\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9916 - policy_loss: 2.3503 - value_loss: 0.6385 - policy_categorical_accuracy: 0.3939 - value_mse: 0.0946\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.982546329498291, 2.3405723571777344, 0.6391685605049133, 0.4018000066280365, 0.09572863578796387]\n","epoch 441\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9673 - policy_loss: 2.3294 - value_loss: 0.6351 - policy_categorical_accuracy: 0.3999 - value_mse: 0.0954\n","epoch 442\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9815 - policy_loss: 2.3427 - value_loss: 0.6359 - policy_categorical_accuracy: 0.3954 - value_mse: 0.0941\n","epoch 443\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0090 - policy_loss: 2.3682 - value_loss: 0.6380 - policy_categorical_accuracy: 0.3938 - value_mse: 0.0930\n","epoch 444\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9944 - policy_loss: 2.3509 - value_loss: 0.6406 - policy_categorical_accuracy: 0.3972 - value_mse: 0.0957\n","epoch 445\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9555 - policy_loss: 2.3152 - value_loss: 0.6375 - policy_categorical_accuracy: 0.4060 - value_mse: 0.0947\n","epoch 446\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9836 - policy_loss: 2.3377 - value_loss: 0.6431 - policy_categorical_accuracy: 0.3969 - value_mse: 0.0950\n","epoch 447\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0013 - policy_loss: 2.3619 - value_loss: 0.6365 - policy_categorical_accuracy: 0.3927 - value_mse: 0.0949\n","epoch 448\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9484 - policy_loss: 2.3092 - value_loss: 0.6363 - policy_categorical_accuracy: 0.4122 - value_mse: 0.0939\n","epoch 449\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9936 - policy_loss: 2.3524 - value_loss: 0.6383 - policy_categorical_accuracy: 0.4029 - value_mse: 0.0946\n","epoch 450\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9933 - policy_loss: 2.3566 - value_loss: 0.6337 - policy_categorical_accuracy: 0.3982 - value_mse: 0.0925\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.991239547729492, 2.3079593181610107, 0.6803240180015564, 0.4036000072956085, 0.11186923831701279]\n","epoch 451\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9723 - policy_loss: 2.3349 - value_loss: 0.6345 - policy_categorical_accuracy: 0.3956 - value_mse: 0.0938\n","epoch 452\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9720 - policy_loss: 2.3304 - value_loss: 0.6386 - policy_categorical_accuracy: 0.3934 - value_mse: 0.0945\n","epoch 453\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9789 - policy_loss: 2.3359 - value_loss: 0.6401 - policy_categorical_accuracy: 0.3976 - value_mse: 0.0936\n","epoch 454\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9712 - policy_loss: 2.3325 - value_loss: 0.6357 - policy_categorical_accuracy: 0.3923 - value_mse: 0.0925\n","epoch 455\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9993 - policy_loss: 2.3588 - value_loss: 0.6376 - policy_categorical_accuracy: 0.3894 - value_mse: 0.0936\n","epoch 456\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9615 - policy_loss: 2.3227 - value_loss: 0.6358 - policy_categorical_accuracy: 0.4012 - value_mse: 0.0936\n","epoch 457\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0037 - policy_loss: 2.3659 - value_loss: 0.6348 - policy_categorical_accuracy: 0.3964 - value_mse: 0.0925\n","epoch 458\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 82ms/step - loss: 2.9928 - policy_loss: 2.3560 - value_loss: 0.6339 - policy_categorical_accuracy: 0.3950 - value_mse: 0.0933\n","epoch 459\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9883 - policy_loss: 2.3475 - value_loss: 0.6378 - policy_categorical_accuracy: 0.4004 - value_mse: 0.0942\n","epoch 460\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9526 - policy_loss: 2.3119 - value_loss: 0.6378 - policy_categorical_accuracy: 0.4011 - value_mse: 0.0934\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.987809181213379, 2.3414182662963867, 0.6434382200241089, 0.4034999907016754, 0.09768862277269363]\n","epoch 461\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9800 - policy_loss: 2.3416 - value_loss: 0.6354 - policy_categorical_accuracy: 0.3981 - value_mse: 0.0934\n","epoch 462\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0336 - policy_loss: 2.3946 - value_loss: 0.6360 - policy_categorical_accuracy: 0.3968 - value_mse: 0.0940\n","epoch 463\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9881 - policy_loss: 2.3502 - value_loss: 0.6349 - policy_categorical_accuracy: 0.3904 - value_mse: 0.0929\n","epoch 464\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9602 - policy_loss: 2.3206 - value_loss: 0.6366 - policy_categorical_accuracy: 0.4031 - value_mse: 0.0939\n","epoch 465\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9821 - policy_loss: 2.3380 - value_loss: 0.6411 - policy_categorical_accuracy: 0.3997 - value_mse: 0.0953\n","epoch 466\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9654 - policy_loss: 2.3246 - value_loss: 0.6378 - policy_categorical_accuracy: 0.4024 - value_mse: 0.0956\n","epoch 467\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9917 - policy_loss: 2.3514 - value_loss: 0.6373 - policy_categorical_accuracy: 0.4019 - value_mse: 0.0950\n","epoch 468\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9822 - policy_loss: 2.3413 - value_loss: 0.6379 - policy_categorical_accuracy: 0.4017 - value_mse: 0.0941\n","epoch 469\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9303 - policy_loss: 2.2981 - value_loss: 0.6292 - policy_categorical_accuracy: 0.4046 - value_mse: 0.0912\n","epoch 470\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9841 - policy_loss: 2.3468 - value_loss: 0.6343 - policy_categorical_accuracy: 0.3949 - value_mse: 0.0932\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9675817489624023, 2.3123462200164795, 0.6522519588470459, 0.4004000127315521, 0.10118652135133743]\n","epoch 471\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9835 - policy_loss: 2.3452 - value_loss: 0.6354 - policy_categorical_accuracy: 0.3947 - value_mse: 0.0932\n","epoch 472\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9579 - policy_loss: 2.3251 - value_loss: 0.6298 - policy_categorical_accuracy: 0.4045 - value_mse: 0.0927\n","epoch 473\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 3.0069 - policy_loss: 2.3641 - value_loss: 0.6398 - policy_categorical_accuracy: 0.3919 - value_mse: 0.0948\n","epoch 474\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9999 - policy_loss: 2.3543 - value_loss: 0.6427 - policy_categorical_accuracy: 0.3908 - value_mse: 0.0959\n","epoch 475\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9749 - policy_loss: 2.3337 - value_loss: 0.6383 - policy_categorical_accuracy: 0.3957 - value_mse: 0.0962\n","epoch 476\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 84ms/step - loss: 2.9743 - policy_loss: 2.3352 - value_loss: 0.6362 - policy_categorical_accuracy: 0.4019 - value_mse: 0.0952\n","epoch 477\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9576 - policy_loss: 2.3165 - value_loss: 0.6381 - policy_categorical_accuracy: 0.4049 - value_mse: 0.0942\n","epoch 478\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9700 - policy_loss: 2.3317 - value_loss: 0.6353 - policy_categorical_accuracy: 0.3948 - value_mse: 0.0934\n","epoch 479\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9665 - policy_loss: 2.3286 - value_loss: 0.6350 - policy_categorical_accuracy: 0.3975 - value_mse: 0.0938\n","epoch 480\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9633 - policy_loss: 2.3253 - value_loss: 0.6351 - policy_categorical_accuracy: 0.3981 - value_mse: 0.0927\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.993533134460449, 2.3160603046417236, 0.6745210886001587, 0.40689998865127563, 0.11062788963317871]\n","epoch 481\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9405 - policy_loss: 2.3037 - value_loss: 0.6338 - policy_categorical_accuracy: 0.4037 - value_mse: 0.0947\n","epoch 482\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9627 - policy_loss: 2.3217 - value_loss: 0.6380 - policy_categorical_accuracy: 0.4106 - value_mse: 0.0940\n","epoch 483\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9799 - policy_loss: 2.3431 - value_loss: 0.6339 - policy_categorical_accuracy: 0.3994 - value_mse: 0.0935\n","epoch 484\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9943 - policy_loss: 2.3585 - value_loss: 0.6328 - policy_categorical_accuracy: 0.3933 - value_mse: 0.0909\n","epoch 485\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9844 - policy_loss: 2.3410 - value_loss: 0.6405 - policy_categorical_accuracy: 0.3967 - value_mse: 0.0955\n","epoch 486\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9649 - policy_loss: 2.3269 - value_loss: 0.6351 - policy_categorical_accuracy: 0.4056 - value_mse: 0.0942\n","epoch 487\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9492 - policy_loss: 2.3053 - value_loss: 0.6409 - policy_categorical_accuracy: 0.4002 - value_mse: 0.0959\n","epoch 488\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9558 - policy_loss: 2.3155 - value_loss: 0.6373 - policy_categorical_accuracy: 0.3966 - value_mse: 0.0949\n","epoch 489\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9953 - policy_loss: 2.3567 - value_loss: 0.6356 - policy_categorical_accuracy: 0.3963 - value_mse: 0.0941\n","epoch 490\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9227 - policy_loss: 2.2861 - value_loss: 0.6337 - policy_categorical_accuracy: 0.4122 - value_mse: 0.0916\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9789223670959473, 2.322213888168335, 0.6537571549415588, 0.40049999952316284, 0.10150474309921265]\n","epoch 491\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9273 - policy_loss: 2.2918 - value_loss: 0.6325 - policy_categorical_accuracy: 0.4070 - value_mse: 0.0930\n","epoch 492\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9934 - policy_loss: 2.3527 - value_loss: 0.6378 - policy_categorical_accuracy: 0.3953 - value_mse: 0.0949\n","epoch 493\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 82ms/step - loss: 2.9827 - policy_loss: 2.3419 - value_loss: 0.6379 - policy_categorical_accuracy: 0.4030 - value_mse: 0.0933\n","epoch 494\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9486 - policy_loss: 2.3111 - value_loss: 0.6346 - policy_categorical_accuracy: 0.4013 - value_mse: 0.0940\n","epoch 495\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9735 - policy_loss: 2.3347 - value_loss: 0.6359 - policy_categorical_accuracy: 0.3995 - value_mse: 0.0925\n","epoch 496\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9785 - policy_loss: 2.3358 - value_loss: 0.6398 - policy_categorical_accuracy: 0.4008 - value_mse: 0.0949\n","epoch 497\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9743 - policy_loss: 2.3383 - value_loss: 0.6332 - policy_categorical_accuracy: 0.3967 - value_mse: 0.0932\n","epoch 498\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9539 - policy_loss: 2.3153 - value_loss: 0.6356 - policy_categorical_accuracy: 0.4005 - value_mse: 0.0943\n","epoch 499\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9637 - policy_loss: 2.3228 - value_loss: 0.6379 - policy_categorical_accuracy: 0.3988 - value_mse: 0.0944\n","epoch 500\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9493 - policy_loss: 2.3085 - value_loss: 0.6379 - policy_categorical_accuracy: 0.4005 - value_mse: 0.0950\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9402692317962646, 2.3000824451446533, 0.6372171640396118, 0.41019999980926514, 0.09481064230203629]\n","epoch 501\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9416 - policy_loss: 2.3048 - value_loss: 0.6337 - policy_categorical_accuracy: 0.3990 - value_mse: 0.0916\n","epoch 502\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9788 - policy_loss: 2.3408 - value_loss: 0.6350 - policy_categorical_accuracy: 0.3957 - value_mse: 0.0931\n","epoch 503\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9372 - policy_loss: 2.2996 - value_loss: 0.6345 - policy_categorical_accuracy: 0.4031 - value_mse: 0.0905\n","epoch 504\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9480 - policy_loss: 2.3078 - value_loss: 0.6371 - policy_categorical_accuracy: 0.4012 - value_mse: 0.0943\n","epoch 505\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9709 - policy_loss: 2.3386 - value_loss: 0.6292 - policy_categorical_accuracy: 0.3979 - value_mse: 0.0912\n","epoch 506\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9542 - policy_loss: 2.3158 - value_loss: 0.6354 - policy_categorical_accuracy: 0.3994 - value_mse: 0.0930\n","epoch 507\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9264 - policy_loss: 2.2869 - value_loss: 0.6365 - policy_categorical_accuracy: 0.4085 - value_mse: 0.0944\n","epoch 508\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9533 - policy_loss: 2.3185 - value_loss: 0.6318 - policy_categorical_accuracy: 0.4009 - value_mse: 0.0916\n","epoch 509\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9664 - policy_loss: 2.3267 - value_loss: 0.6366 - policy_categorical_accuracy: 0.3950 - value_mse: 0.0951\n","epoch 510\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9343 - policy_loss: 2.2980 - value_loss: 0.6332 - policy_categorical_accuracy: 0.3999 - value_mse: 0.0926\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9865026473999023, 2.3055241107940674, 0.6779177784919739, 0.40860000252723694, 0.11178697645664215]\n","epoch 511\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 84ms/step - loss: 2.9827 - policy_loss: 2.3450 - value_loss: 0.6347 - policy_categorical_accuracy: 0.3989 - value_mse: 0.0939\n","epoch 512\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9678 - policy_loss: 2.3282 - value_loss: 0.6366 - policy_categorical_accuracy: 0.3942 - value_mse: 0.0950\n","epoch 513\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9591 - policy_loss: 2.3182 - value_loss: 0.6380 - policy_categorical_accuracy: 0.3991 - value_mse: 0.0940\n","epoch 514\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9470 - policy_loss: 2.3104 - value_loss: 0.6335 - policy_categorical_accuracy: 0.4033 - value_mse: 0.0921\n","epoch 515\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 3.0063 - policy_loss: 2.3695 - value_loss: 0.6338 - policy_categorical_accuracy: 0.3875 - value_mse: 0.0936\n","epoch 516\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9718 - policy_loss: 2.3307 - value_loss: 0.6380 - policy_categorical_accuracy: 0.4007 - value_mse: 0.0943\n","epoch 517\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9474 - policy_loss: 2.3073 - value_loss: 0.6370 - policy_categorical_accuracy: 0.4036 - value_mse: 0.0948\n","epoch 518\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9919 - policy_loss: 2.3565 - value_loss: 0.6323 - policy_categorical_accuracy: 0.3899 - value_mse: 0.0933\n","epoch 519\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9247 - policy_loss: 2.2865 - value_loss: 0.6351 - policy_categorical_accuracy: 0.4041 - value_mse: 0.0942\n","epoch 520\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9459 - policy_loss: 2.3116 - value_loss: 0.6312 - policy_categorical_accuracy: 0.4030 - value_mse: 0.0912\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.947864532470703, 2.29715633392334, 0.6476482152938843, 0.4025000035762787, 0.09952415525913239]\n","epoch 521\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9522 - policy_loss: 2.3140 - value_loss: 0.6352 - policy_categorical_accuracy: 0.4009 - value_mse: 0.0938\n","epoch 522\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9935 - policy_loss: 2.3529 - value_loss: 0.6375 - policy_categorical_accuracy: 0.3916 - value_mse: 0.0960\n","epoch 523\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9368 - policy_loss: 2.2948 - value_loss: 0.6390 - policy_categorical_accuracy: 0.4060 - value_mse: 0.0948\n","epoch 524\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9608 - policy_loss: 2.3225 - value_loss: 0.6353 - policy_categorical_accuracy: 0.4046 - value_mse: 0.0932\n","epoch 525\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9368 - policy_loss: 2.2997 - value_loss: 0.6341 - policy_categorical_accuracy: 0.4009 - value_mse: 0.0933\n","epoch 526\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9534 - policy_loss: 2.3155 - value_loss: 0.6349 - policy_categorical_accuracy: 0.3998 - value_mse: 0.0953\n","epoch 527\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9473 - policy_loss: 2.3045 - value_loss: 0.6398 - policy_categorical_accuracy: 0.4080 - value_mse: 0.0939\n","epoch 528\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9318 - policy_loss: 2.2972 - value_loss: 0.6317 - policy_categorical_accuracy: 0.4032 - value_mse: 0.0928\n","epoch 529\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9174 - policy_loss: 2.2818 - value_loss: 0.6326 - policy_categorical_accuracy: 0.4138 - value_mse: 0.0924\n","epoch 530\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9395 - policy_loss: 2.3078 - value_loss: 0.6287 - policy_categorical_accuracy: 0.4067 - value_mse: 0.0918\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.924135446548462, 2.2877116203308105, 0.633396565914154, 0.40709999203681946, 0.09338512271642685]\n","epoch 531\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 83ms/step - loss: 2.9421 - policy_loss: 2.3092 - value_loss: 0.6299 - policy_categorical_accuracy: 0.3998 - value_mse: 0.0924\n","epoch 532\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9814 - policy_loss: 2.3383 - value_loss: 0.6401 - policy_categorical_accuracy: 0.3988 - value_mse: 0.0939\n","epoch 533\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9509 - policy_loss: 2.3140 - value_loss: 0.6339 - policy_categorical_accuracy: 0.4019 - value_mse: 0.0938\n","epoch 534\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9579 - policy_loss: 2.3192 - value_loss: 0.6357 - policy_categorical_accuracy: 0.3960 - value_mse: 0.0919\n","epoch 535\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9229 - policy_loss: 2.2833 - value_loss: 0.6365 - policy_categorical_accuracy: 0.4093 - value_mse: 0.0927\n","epoch 536\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9478 - policy_loss: 2.3116 - value_loss: 0.6332 - policy_categorical_accuracy: 0.3997 - value_mse: 0.0931\n","epoch 537\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9590 - policy_loss: 2.3236 - value_loss: 0.6324 - policy_categorical_accuracy: 0.3974 - value_mse: 0.0938\n","epoch 538\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9427 - policy_loss: 2.3077 - value_loss: 0.6320 - policy_categorical_accuracy: 0.3948 - value_mse: 0.0929\n","epoch 539\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9410 - policy_loss: 2.3009 - value_loss: 0.6371 - policy_categorical_accuracy: 0.4006 - value_mse: 0.0927\n","epoch 540\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9604 - policy_loss: 2.3265 - value_loss: 0.6309 - policy_categorical_accuracy: 0.4000 - value_mse: 0.0920\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.943912982940674, 2.2999253273010254, 0.6409177184104919, 0.40689998865127563, 0.09655976295471191]\n","epoch 541\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9376 - policy_loss: 2.2992 - value_loss: 0.6353 - policy_categorical_accuracy: 0.4078 - value_mse: 0.0935\n","epoch 542\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9689 - policy_loss: 2.3294 - value_loss: 0.6365 - policy_categorical_accuracy: 0.3959 - value_mse: 0.0933\n","epoch 543\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9499 - policy_loss: 2.3150 - value_loss: 0.6319 - policy_categorical_accuracy: 0.4005 - value_mse: 0.0925\n","epoch 544\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9425 - policy_loss: 2.3079 - value_loss: 0.6316 - policy_categorical_accuracy: 0.4076 - value_mse: 0.0945\n","epoch 545\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9547 - policy_loss: 2.3194 - value_loss: 0.6323 - policy_categorical_accuracy: 0.4035 - value_mse: 0.0919\n","epoch 546\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9255 - policy_loss: 2.2909 - value_loss: 0.6315 - policy_categorical_accuracy: 0.4011 - value_mse: 0.0918\n","epoch 547\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9184 - policy_loss: 2.2813 - value_loss: 0.6341 - policy_categorical_accuracy: 0.4115 - value_mse: 0.0939\n","epoch 548\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9472 - policy_loss: 2.3136 - value_loss: 0.6306 - policy_categorical_accuracy: 0.4017 - value_mse: 0.0921\n","epoch 549\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 84ms/step - loss: 2.9817 - policy_loss: 2.3480 - value_loss: 0.6306 - policy_categorical_accuracy: 0.3976 - value_mse: 0.0924\n","epoch 550\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9700 - policy_loss: 2.3302 - value_loss: 0.6367 - policy_categorical_accuracy: 0.4066 - value_mse: 0.0951\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9632656574249268, 2.2840561866760254, 0.676121711730957, 0.4081999957561493, 0.1106397807598114]\n","epoch 551\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9510 - policy_loss: 2.3155 - value_loss: 0.6324 - policy_categorical_accuracy: 0.4038 - value_mse: 0.0915\n","epoch 552\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9341 - policy_loss: 2.2947 - value_loss: 0.6363 - policy_categorical_accuracy: 0.4084 - value_mse: 0.0943\n","epoch 553\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9536 - policy_loss: 2.3178 - value_loss: 0.6328 - policy_categorical_accuracy: 0.3965 - value_mse: 0.0940\n","epoch 554\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9406 - policy_loss: 2.3040 - value_loss: 0.6335 - policy_categorical_accuracy: 0.4035 - value_mse: 0.0935\n","epoch 555\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9329 - policy_loss: 2.2940 - value_loss: 0.6358 - policy_categorical_accuracy: 0.4047 - value_mse: 0.0944\n","epoch 556\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9627 - policy_loss: 2.3221 - value_loss: 0.6375 - policy_categorical_accuracy: 0.3906 - value_mse: 0.0933\n","epoch 557\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9188 - policy_loss: 2.2876 - value_loss: 0.6280 - policy_categorical_accuracy: 0.4061 - value_mse: 0.0923\n","epoch 558\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9440 - policy_loss: 2.3126 - value_loss: 0.6283 - policy_categorical_accuracy: 0.4031 - value_mse: 0.0911\n","epoch 559\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9468 - policy_loss: 2.3050 - value_loss: 0.6387 - policy_categorical_accuracy: 0.4074 - value_mse: 0.0961\n","epoch 560\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9554 - policy_loss: 2.3116 - value_loss: 0.6408 - policy_categorical_accuracy: 0.3979 - value_mse: 0.0949\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.991075038909912, 2.288750171661377, 0.6992720365524292, 0.40939998626708984, 0.11945787072181702]\n","epoch 561\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9690 - policy_loss: 2.3304 - value_loss: 0.6356 - policy_categorical_accuracy: 0.4003 - value_mse: 0.0923\n","epoch 562\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9537 - policy_loss: 2.3182 - value_loss: 0.6325 - policy_categorical_accuracy: 0.3981 - value_mse: 0.0913\n","epoch 563\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9325 - policy_loss: 2.2959 - value_loss: 0.6335 - policy_categorical_accuracy: 0.4043 - value_mse: 0.0930\n","epoch 564\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9488 - policy_loss: 2.3085 - value_loss: 0.6373 - policy_categorical_accuracy: 0.4001 - value_mse: 0.0947\n","epoch 565\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9837 - policy_loss: 2.3444 - value_loss: 0.6362 - policy_categorical_accuracy: 0.4012 - value_mse: 0.0935\n","epoch 566\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 84ms/step - loss: 2.9381 - policy_loss: 2.3074 - value_loss: 0.6275 - policy_categorical_accuracy: 0.3996 - value_mse: 0.0904\n","epoch 567\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 82ms/step - loss: 2.9266 - policy_loss: 2.2891 - value_loss: 0.6344 - policy_categorical_accuracy: 0.4073 - value_mse: 0.0923\n","epoch 568\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9388 - policy_loss: 2.3032 - value_loss: 0.6325 - policy_categorical_accuracy: 0.4089 - value_mse: 0.0935\n","epoch 569\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9188 - policy_loss: 2.2840 - value_loss: 0.6317 - policy_categorical_accuracy: 0.4066 - value_mse: 0.0912\n","epoch 570\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9022 - policy_loss: 2.2739 - value_loss: 0.6253 - policy_categorical_accuracy: 0.4108 - value_mse: 0.0915\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.936020612716675, 2.293912887573242, 0.6390084028244019, 0.4099000096321106, 0.09583378583192825]\n","epoch 571\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9620 - policy_loss: 2.3197 - value_loss: 0.6393 - policy_categorical_accuracy: 0.4034 - value_mse: 0.0956\n","epoch 572\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9199 - policy_loss: 2.2839 - value_loss: 0.6329 - policy_categorical_accuracy: 0.4052 - value_mse: 0.0928\n","epoch 573\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9597 - policy_loss: 2.3190 - value_loss: 0.6376 - policy_categorical_accuracy: 0.3984 - value_mse: 0.0936\n","epoch 574\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9319 - policy_loss: 2.2958 - value_loss: 0.6330 - policy_categorical_accuracy: 0.4033 - value_mse: 0.0948\n","epoch 575\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9467 - policy_loss: 2.3091 - value_loss: 0.6345 - policy_categorical_accuracy: 0.4039 - value_mse: 0.0922\n","epoch 576\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9216 - policy_loss: 2.2872 - value_loss: 0.6312 - policy_categorical_accuracy: 0.4112 - value_mse: 0.0924\n","epoch 577\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9407 - policy_loss: 2.3078 - value_loss: 0.6298 - policy_categorical_accuracy: 0.4015 - value_mse: 0.0923\n","epoch 578\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9849 - policy_loss: 2.3464 - value_loss: 0.6354 - policy_categorical_accuracy: 0.3960 - value_mse: 0.0919\n","epoch 579\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9249 - policy_loss: 2.2923 - value_loss: 0.6295 - policy_categorical_accuracy: 0.4115 - value_mse: 0.0914\n","epoch 580\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9486 - policy_loss: 2.3064 - value_loss: 0.6391 - policy_categorical_accuracy: 0.3961 - value_mse: 0.0940\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.922473192214966, 2.284475803375244, 0.6348926424980164, 0.4108999967575073, 0.09384489059448242]\n","epoch 581\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9652 - policy_loss: 2.3335 - value_loss: 0.6285 - policy_categorical_accuracy: 0.3964 - value_mse: 0.0914\n","epoch 582\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9444 - policy_loss: 2.3034 - value_loss: 0.6379 - policy_categorical_accuracy: 0.4052 - value_mse: 0.0937\n","epoch 583\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 84ms/step - loss: 2.9057 - policy_loss: 2.2690 - value_loss: 0.6335 - policy_categorical_accuracy: 0.4122 - value_mse: 0.0946\n","epoch 584\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 83ms/step - loss: 2.9681 - policy_loss: 2.3345 - value_loss: 0.6305 - policy_categorical_accuracy: 0.3956 - value_mse: 0.0898\n","epoch 585\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9153 - policy_loss: 2.2831 - value_loss: 0.6292 - policy_categorical_accuracy: 0.4000 - value_mse: 0.0906\n","epoch 586\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9633 - policy_loss: 2.3268 - value_loss: 0.6334 - policy_categorical_accuracy: 0.3985 - value_mse: 0.0917\n","epoch 587\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9201 - policy_loss: 2.2889 - value_loss: 0.6280 - policy_categorical_accuracy: 0.4042 - value_mse: 0.0918\n","epoch 588\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9684 - policy_loss: 2.3307 - value_loss: 0.6347 - policy_categorical_accuracy: 0.3961 - value_mse: 0.0922\n","epoch 589\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9550 - policy_loss: 2.3196 - value_loss: 0.6323 - policy_categorical_accuracy: 0.3977 - value_mse: 0.0913\n","epoch 590\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9276 - policy_loss: 2.2905 - value_loss: 0.6340 - policy_categorical_accuracy: 0.4119 - value_mse: 0.0939\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9457321166992188, 2.279039144515991, 0.6635841131210327, 0.41019999980926514, 0.10647659003734589]\n","epoch 591\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9126 - policy_loss: 2.2819 - value_loss: 0.6276 - policy_categorical_accuracy: 0.4050 - value_mse: 0.0924\n","epoch 592\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9560 - policy_loss: 2.3182 - value_loss: 0.6346 - policy_categorical_accuracy: 0.3956 - value_mse: 0.0931\n","epoch 593\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9371 - policy_loss: 2.3011 - value_loss: 0.6328 - policy_categorical_accuracy: 0.4066 - value_mse: 0.0934\n","epoch 594\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9402 - policy_loss: 2.2984 - value_loss: 0.6387 - policy_categorical_accuracy: 0.4007 - value_mse: 0.0958\n","epoch 595\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9500 - policy_loss: 2.3123 - value_loss: 0.6346 - policy_categorical_accuracy: 0.4008 - value_mse: 0.0926\n","epoch 596\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9224 - policy_loss: 2.2850 - value_loss: 0.6343 - policy_categorical_accuracy: 0.4040 - value_mse: 0.0928\n","epoch 597\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9323 - policy_loss: 2.2955 - value_loss: 0.6337 - policy_categorical_accuracy: 0.4098 - value_mse: 0.0942\n","epoch 598\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9350 - policy_loss: 2.2973 - value_loss: 0.6347 - policy_categorical_accuracy: 0.3995 - value_mse: 0.0935\n","epoch 599\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9363 - policy_loss: 2.2972 - value_loss: 0.6361 - policy_categorical_accuracy: 0.4080 - value_mse: 0.0928\n","epoch 600\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 78ms/step - loss: 2.9418 - policy_loss: 2.3043 - value_loss: 0.6344 - policy_categorical_accuracy: 0.4026 - value_mse: 0.0936\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9178593158721924, 2.276033639907837, 0.6387509703636169, 0.41290000081062317, 0.09553001821041107]\n","epoch 601\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9210 - policy_loss: 2.2885 - value_loss: 0.6295 - policy_categorical_accuracy: 0.4032 - value_mse: 0.0896\n","epoch 602\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9576 - policy_loss: 2.3199 - value_loss: 0.6346 - policy_categorical_accuracy: 0.3958 - value_mse: 0.0940\n","epoch 603\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9471 - policy_loss: 2.3117 - value_loss: 0.6323 - policy_categorical_accuracy: 0.4013 - value_mse: 0.0922\n","epoch 604\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9418 - policy_loss: 2.3033 - value_loss: 0.6355 - policy_categorical_accuracy: 0.3995 - value_mse: 0.0944\n","epoch 605\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9207 - policy_loss: 2.2873 - value_loss: 0.6303 - policy_categorical_accuracy: 0.4068 - value_mse: 0.0928\n","epoch 606\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9456 - policy_loss: 2.3067 - value_loss: 0.6357 - policy_categorical_accuracy: 0.3957 - value_mse: 0.0935\n","epoch 607\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9815 - policy_loss: 2.3452 - value_loss: 0.6331 - policy_categorical_accuracy: 0.3930 - value_mse: 0.0933\n","epoch 608\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9508 - policy_loss: 2.3158 - value_loss: 0.6318 - policy_categorical_accuracy: 0.3986 - value_mse: 0.0939\n","epoch 609\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9316 - policy_loss: 2.2998 - value_loss: 0.6286 - policy_categorical_accuracy: 0.4043 - value_mse: 0.0915\n","epoch 610\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9556 - policy_loss: 2.3107 - value_loss: 0.6418 - policy_categorical_accuracy: 0.4057 - value_mse: 0.0946\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.914125442504883, 2.2694613933563232, 0.6415719985961914, 0.4108000099658966, 0.09654455631971359]\n","epoch 611\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9179 - policy_loss: 2.2817 - value_loss: 0.6330 - policy_categorical_accuracy: 0.4078 - value_mse: 0.0934\n","epoch 612\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9127 - policy_loss: 2.2805 - value_loss: 0.6291 - policy_categorical_accuracy: 0.4045 - value_mse: 0.0903\n","epoch 613\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9440 - policy_loss: 2.3089 - value_loss: 0.6319 - policy_categorical_accuracy: 0.4022 - value_mse: 0.0922\n","epoch 614\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9239 - policy_loss: 2.2858 - value_loss: 0.6350 - policy_categorical_accuracy: 0.4093 - value_mse: 0.0932\n","epoch 615\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9552 - policy_loss: 2.3146 - value_loss: 0.6374 - policy_categorical_accuracy: 0.3991 - value_mse: 0.0920\n","epoch 616\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9323 - policy_loss: 2.2957 - value_loss: 0.6335 - policy_categorical_accuracy: 0.4048 - value_mse: 0.0923\n","epoch 617\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9188 - policy_loss: 2.2795 - value_loss: 0.6362 - policy_categorical_accuracy: 0.4086 - value_mse: 0.0931\n","epoch 618\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 79ms/step - loss: 2.9273 - policy_loss: 2.2929 - value_loss: 0.6313 - policy_categorical_accuracy: 0.4041 - value_mse: 0.0944\n","epoch 619\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 83ms/step - loss: 2.9547 - policy_loss: 2.3197 - value_loss: 0.6319 - policy_categorical_accuracy: 0.4032 - value_mse: 0.0911\n","epoch 620\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9322 - policy_loss: 2.2949 - value_loss: 0.6341 - policy_categorical_accuracy: 0.4013 - value_mse: 0.0923\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9296369552612305, 2.2789385318756104, 0.647577166557312, 0.4092000126838684, 0.09948093444108963]\n","epoch 621\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9311 - policy_loss: 2.2908 - value_loss: 0.6371 - policy_categorical_accuracy: 0.4037 - value_mse: 0.0954\n","epoch 622\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9297 - policy_loss: 2.2989 - value_loss: 0.6276 - policy_categorical_accuracy: 0.4000 - value_mse: 0.0922\n","epoch 623\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9381 - policy_loss: 2.3038 - value_loss: 0.6311 - policy_categorical_accuracy: 0.4011 - value_mse: 0.0932\n","epoch 624\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9062 - policy_loss: 2.2705 - value_loss: 0.6326 - policy_categorical_accuracy: 0.4119 - value_mse: 0.0921\n","epoch 625\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9353 - policy_loss: 2.3009 - value_loss: 0.6313 - policy_categorical_accuracy: 0.4044 - value_mse: 0.0899\n","epoch 626\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9227 - policy_loss: 2.2897 - value_loss: 0.6299 - policy_categorical_accuracy: 0.4015 - value_mse: 0.0922\n","epoch 627\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9215 - policy_loss: 2.2878 - value_loss: 0.6306 - policy_categorical_accuracy: 0.4058 - value_mse: 0.0914\n","epoch 628\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9442 - policy_loss: 2.3052 - value_loss: 0.6359 - policy_categorical_accuracy: 0.4049 - value_mse: 0.0938\n","epoch 629\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9118 - policy_loss: 2.2792 - value_loss: 0.6294 - policy_categorical_accuracy: 0.4069 - value_mse: 0.0913\n","epoch 630\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9169 - policy_loss: 2.2778 - value_loss: 0.6360 - policy_categorical_accuracy: 0.4062 - value_mse: 0.0924\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.922445297241211, 2.253265142440796, 0.6659963130950928, 0.41530001163482666, 0.10747513175010681]\n","epoch 631\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9289 - policy_loss: 2.2970 - value_loss: 0.6287 - policy_categorical_accuracy: 0.3980 - value_mse: 0.0935\n","epoch 632\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9549 - policy_loss: 2.3168 - value_loss: 0.6349 - policy_categorical_accuracy: 0.3982 - value_mse: 0.0936\n","epoch 633\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9227 - policy_loss: 2.2856 - value_loss: 0.6340 - policy_categorical_accuracy: 0.4060 - value_mse: 0.0922\n","epoch 634\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9280 - policy_loss: 2.2975 - value_loss: 0.6273 - policy_categorical_accuracy: 0.4040 - value_mse: 0.0905\n","epoch 635\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9398 - policy_loss: 2.3049 - value_loss: 0.6316 - policy_categorical_accuracy: 0.4053 - value_mse: 0.0913\n","epoch 636\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9297 - policy_loss: 2.2913 - value_loss: 0.6352 - policy_categorical_accuracy: 0.4042 - value_mse: 0.0942\n","epoch 637\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 78ms/step - loss: 2.9498 - policy_loss: 2.3171 - value_loss: 0.6295 - policy_categorical_accuracy: 0.4001 - value_mse: 0.0905\n","epoch 638\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 80ms/step - loss: 2.9142 - policy_loss: 2.2779 - value_loss: 0.6331 - policy_categorical_accuracy: 0.4095 - value_mse: 0.0935\n","epoch 639\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9181 - policy_loss: 2.2848 - value_loss: 0.6301 - policy_categorical_accuracy: 0.4139 - value_mse: 0.0925\n","epoch 640\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9085 - policy_loss: 2.2750 - value_loss: 0.6303 - policy_categorical_accuracy: 0.4123 - value_mse: 0.0936\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9327986240386963, 2.2633309364318848, 0.666181206703186, 0.41100001335144043, 0.10622826218605042]\n","epoch 641\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9279 - policy_loss: 2.2856 - value_loss: 0.6391 - policy_categorical_accuracy: 0.4005 - value_mse: 0.0942\n","epoch 642\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9412 - policy_loss: 2.3023 - value_loss: 0.6356 - policy_categorical_accuracy: 0.4045 - value_mse: 0.0937\n","epoch 643\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9252 - policy_loss: 2.2902 - value_loss: 0.6317 - policy_categorical_accuracy: 0.4020 - value_mse: 0.0930\n","epoch 644\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9285 - policy_loss: 2.2974 - value_loss: 0.6279 - policy_categorical_accuracy: 0.4113 - value_mse: 0.0905\n","epoch 645\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9160 - policy_loss: 2.2786 - value_loss: 0.6343 - policy_categorical_accuracy: 0.4078 - value_mse: 0.0950\n","epoch 646\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9071 - policy_loss: 2.2745 - value_loss: 0.6293 - policy_categorical_accuracy: 0.4047 - value_mse: 0.0908\n","epoch 647\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 75ms/step - loss: 2.8919 - policy_loss: 2.2561 - value_loss: 0.6326 - policy_categorical_accuracy: 0.4056 - value_mse: 0.0930\n","epoch 648\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9486 - policy_loss: 2.3089 - value_loss: 0.6364 - policy_categorical_accuracy: 0.3960 - value_mse: 0.0942\n","epoch 649\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9383 - policy_loss: 2.3046 - value_loss: 0.6304 - policy_categorical_accuracy: 0.3971 - value_mse: 0.0913\n","epoch 650\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9398 - policy_loss: 2.3036 - value_loss: 0.6330 - policy_categorical_accuracy: 0.4069 - value_mse: 0.0922\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.953352689743042, 2.276637554168701, 0.673460841178894, 0.4092999994754791, 0.11018119007349014]\n","epoch 651\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9352 - policy_loss: 2.3002 - value_loss: 0.6318 - policy_categorical_accuracy: 0.3985 - value_mse: 0.0927\n","epoch 652\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9046 - policy_loss: 2.2700 - value_loss: 0.6313 - policy_categorical_accuracy: 0.4093 - value_mse: 0.0908\n","epoch 653\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9074 - policy_loss: 2.2739 - value_loss: 0.6303 - policy_categorical_accuracy: 0.4131 - value_mse: 0.0916\n","epoch 654\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9659 - policy_loss: 2.3280 - value_loss: 0.6346 - policy_categorical_accuracy: 0.3998 - value_mse: 0.0927\n","epoch 655\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 83ms/step - loss: 2.9421 - policy_loss: 2.3044 - value_loss: 0.6345 - policy_categorical_accuracy: 0.4063 - value_mse: 0.0917\n","epoch 656\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9385 - policy_loss: 2.3020 - value_loss: 0.6333 - policy_categorical_accuracy: 0.3982 - value_mse: 0.0931\n","epoch 657\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9196 - policy_loss: 2.2855 - value_loss: 0.6309 - policy_categorical_accuracy: 0.4100 - value_mse: 0.0915\n","epoch 658\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9243 - policy_loss: 2.2887 - value_loss: 0.6323 - policy_categorical_accuracy: 0.4071 - value_mse: 0.0943\n","epoch 659\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9259 - policy_loss: 2.2923 - value_loss: 0.6304 - policy_categorical_accuracy: 0.4013 - value_mse: 0.0910\n","epoch 660\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9121 - policy_loss: 2.2790 - value_loss: 0.6299 - policy_categorical_accuracy: 0.4048 - value_mse: 0.0916\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.913228988647461, 2.2704246044158936, 0.6395605206489563, 0.41339999437332153, 0.09599096328020096]\n","epoch 661\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9083 - policy_loss: 2.2697 - value_loss: 0.6354 - policy_categorical_accuracy: 0.4032 - value_mse: 0.0945\n","epoch 662\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9398 - policy_loss: 2.3057 - value_loss: 0.6309 - policy_categorical_accuracy: 0.4034 - value_mse: 0.0915\n","epoch 663\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9173 - policy_loss: 2.2824 - value_loss: 0.6317 - policy_categorical_accuracy: 0.4051 - value_mse: 0.0940\n","epoch 664\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9332 - policy_loss: 2.3048 - value_loss: 0.6251 - policy_categorical_accuracy: 0.4063 - value_mse: 0.0923\n","epoch 665\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8815 - policy_loss: 2.2501 - value_loss: 0.6282 - policy_categorical_accuracy: 0.4182 - value_mse: 0.0916\n","epoch 666\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9557 - policy_loss: 2.3184 - value_loss: 0.6341 - policy_categorical_accuracy: 0.3955 - value_mse: 0.0933\n","epoch 667\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9028 - policy_loss: 2.2680 - value_loss: 0.6316 - policy_categorical_accuracy: 0.4053 - value_mse: 0.0918\n","epoch 668\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 81ms/step - loss: 2.8811 - policy_loss: 2.2459 - value_loss: 0.6320 - policy_categorical_accuracy: 0.4160 - value_mse: 0.0919\n","epoch 669\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9017 - policy_loss: 2.2671 - value_loss: 0.6313 - policy_categorical_accuracy: 0.4114 - value_mse: 0.0924\n","epoch 670\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9112 - policy_loss: 2.2751 - value_loss: 0.6329 - policy_categorical_accuracy: 0.4094 - value_mse: 0.0937\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.887321710586548, 2.251041889190674, 0.6330358386039734, 0.4138999879360199, 0.09293843060731888]\n","epoch 671\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9282 - policy_loss: 2.2911 - value_loss: 0.6338 - policy_categorical_accuracy: 0.4051 - value_mse: 0.0953\n","epoch 672\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9134 - policy_loss: 2.2800 - value_loss: 0.6301 - policy_categorical_accuracy: 0.4017 - value_mse: 0.0916\n","epoch 673\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9000 - policy_loss: 2.2650 - value_loss: 0.6318 - policy_categorical_accuracy: 0.4092 - value_mse: 0.0905\n","epoch 674\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9311 - policy_loss: 2.2946 - value_loss: 0.6333 - policy_categorical_accuracy: 0.4012 - value_mse: 0.0930\n","epoch 675\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 82ms/step - loss: 2.9017 - policy_loss: 2.2631 - value_loss: 0.6354 - policy_categorical_accuracy: 0.4102 - value_mse: 0.0933\n","epoch 676\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9217 - policy_loss: 2.2903 - value_loss: 0.6281 - policy_categorical_accuracy: 0.4045 - value_mse: 0.0911\n","epoch 677\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9200 - policy_loss: 2.2864 - value_loss: 0.6303 - policy_categorical_accuracy: 0.4071 - value_mse: 0.0926\n","epoch 678\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9218 - policy_loss: 2.2895 - value_loss: 0.6291 - policy_categorical_accuracy: 0.3998 - value_mse: 0.0906\n","epoch 679\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9104 - policy_loss: 2.2737 - value_loss: 0.6335 - policy_categorical_accuracy: 0.4062 - value_mse: 0.0928\n","epoch 680\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 78ms/step - loss: 2.9641 - policy_loss: 2.3277 - value_loss: 0.6331 - policy_categorical_accuracy: 0.3924 - value_mse: 0.0913\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9205803871154785, 2.2605862617492676, 0.6567540764808655, 0.41370001435279846, 0.10261491686105728]\n","epoch 681\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9052 - policy_loss: 2.2707 - value_loss: 0.6312 - policy_categorical_accuracy: 0.4117 - value_mse: 0.0919\n","epoch 682\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9209 - policy_loss: 2.2848 - value_loss: 0.6329 - policy_categorical_accuracy: 0.4057 - value_mse: 0.0932\n","epoch 683\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9332 - policy_loss: 2.2997 - value_loss: 0.6302 - policy_categorical_accuracy: 0.4033 - value_mse: 0.0888\n","epoch 684\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9284 - policy_loss: 2.2897 - value_loss: 0.6354 - policy_categorical_accuracy: 0.4098 - value_mse: 0.0932\n","epoch 685\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9099 - policy_loss: 2.2776 - value_loss: 0.6290 - policy_categorical_accuracy: 0.4128 - value_mse: 0.0917\n","epoch 686\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 82ms/step - loss: 2.8913 - policy_loss: 2.2602 - value_loss: 0.6278 - policy_categorical_accuracy: 0.4125 - value_mse: 0.0901\n","epoch 687\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9238 - policy_loss: 2.2886 - value_loss: 0.6319 - policy_categorical_accuracy: 0.4055 - value_mse: 0.0927\n","epoch 688\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9645 - policy_loss: 2.3321 - value_loss: 0.6292 - policy_categorical_accuracy: 0.4009 - value_mse: 0.0905\n","epoch 689\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9037 - policy_loss: 2.2676 - value_loss: 0.6328 - policy_categorical_accuracy: 0.4030 - value_mse: 0.0931\n","epoch 690\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8910 - policy_loss: 2.2570 - value_loss: 0.6307 - policy_categorical_accuracy: 0.4046 - value_mse: 0.0913\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.895397901535034, 2.2494444847106934, 0.6426295042037964, 0.41179999709129333, 0.09757353365421295]\n","epoch 691\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8903 - policy_loss: 2.2606 - value_loss: 0.6263 - policy_categorical_accuracy: 0.4119 - value_mse: 0.0910\n","epoch 692\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9325 - policy_loss: 2.2983 - value_loss: 0.6309 - policy_categorical_accuracy: 0.4031 - value_mse: 0.0931\n","epoch 693\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9410 - policy_loss: 2.3030 - value_loss: 0.6347 - policy_categorical_accuracy: 0.4050 - value_mse: 0.0932\n","epoch 694\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9309 - policy_loss: 2.2962 - value_loss: 0.6314 - policy_categorical_accuracy: 0.4015 - value_mse: 0.0911\n","epoch 695\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9180 - policy_loss: 2.2860 - value_loss: 0.6286 - policy_categorical_accuracy: 0.4091 - value_mse: 0.0911\n","epoch 696\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9097 - policy_loss: 2.2707 - value_loss: 0.6357 - policy_categorical_accuracy: 0.4105 - value_mse: 0.0928\n","epoch 697\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 79ms/step - loss: 2.9150 - policy_loss: 2.2749 - value_loss: 0.6367 - policy_categorical_accuracy: 0.4075 - value_mse: 0.0948\n","epoch 698\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8954 - policy_loss: 2.2598 - value_loss: 0.6323 - policy_categorical_accuracy: 0.4069 - value_mse: 0.0912\n","epoch 699\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9258 - policy_loss: 2.2826 - value_loss: 0.6400 - policy_categorical_accuracy: 0.4047 - value_mse: 0.0935\n","epoch 700\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9066 - policy_loss: 2.2694 - value_loss: 0.6339 - policy_categorical_accuracy: 0.4120 - value_mse: 0.0945\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.8833789825439453, 2.2433462142944336, 0.6367689967155457, 0.41609999537467957, 0.0945567712187767]\n","epoch 701\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9239 - policy_loss: 2.2896 - value_loss: 0.6311 - policy_categorical_accuracy: 0.4023 - value_mse: 0.0926\n","epoch 702\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8873 - policy_loss: 2.2502 - value_loss: 0.6338 - policy_categorical_accuracy: 0.4094 - value_mse: 0.0916\n","epoch 703\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8645 - policy_loss: 2.2297 - value_loss: 0.6316 - policy_categorical_accuracy: 0.4169 - value_mse: 0.0914\n","epoch 704\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9039 - policy_loss: 2.2675 - value_loss: 0.6332 - policy_categorical_accuracy: 0.4164 - value_mse: 0.0930\n","epoch 705\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9024 - policy_loss: 2.2644 - value_loss: 0.6348 - policy_categorical_accuracy: 0.4021 - value_mse: 0.0942\n","epoch 706\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8825 - policy_loss: 2.2471 - value_loss: 0.6322 - policy_categorical_accuracy: 0.4169 - value_mse: 0.0905\n","epoch 707\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9093 - policy_loss: 2.2784 - value_loss: 0.6276 - policy_categorical_accuracy: 0.4099 - value_mse: 0.0904\n","epoch 708\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 81ms/step - loss: 2.9188 - policy_loss: 2.2820 - value_loss: 0.6335 - policy_categorical_accuracy: 0.4086 - value_mse: 0.0927\n","epoch 709\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8943 - policy_loss: 2.2636 - value_loss: 0.6274 - policy_categorical_accuracy: 0.4109 - value_mse: 0.0912\n","epoch 710\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9040 - policy_loss: 2.2647 - value_loss: 0.6361 - policy_categorical_accuracy: 0.4094 - value_mse: 0.0954\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.888387441635132, 2.2516191005706787, 0.6334971189498901, 0.414900004863739, 0.0931364893913269]\n","epoch 711\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9137 - policy_loss: 2.2826 - value_loss: 0.6278 - policy_categorical_accuracy: 0.4042 - value_mse: 0.0907\n","epoch 712\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8812 - policy_loss: 2.2508 - value_loss: 0.6271 - policy_categorical_accuracy: 0.4163 - value_mse: 0.0925\n","epoch 713\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9620 - policy_loss: 2.3265 - value_loss: 0.6323 - policy_categorical_accuracy: 0.4014 - value_mse: 0.0949\n","epoch 714\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9191 - policy_loss: 2.2799 - value_loss: 0.6359 - policy_categorical_accuracy: 0.4074 - value_mse: 0.0923\n","epoch 715\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9211 - policy_loss: 2.2837 - value_loss: 0.6342 - policy_categorical_accuracy: 0.4022 - value_mse: 0.0923\n","epoch 716\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9294 - policy_loss: 2.2912 - value_loss: 0.6350 - policy_categorical_accuracy: 0.4060 - value_mse: 0.0933\n","epoch 717\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9199 - policy_loss: 2.2852 - value_loss: 0.6314 - policy_categorical_accuracy: 0.4026 - value_mse: 0.0922\n","epoch 718\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9097 - policy_loss: 2.2753 - value_loss: 0.6311 - policy_categorical_accuracy: 0.4053 - value_mse: 0.0915\n","epoch 719\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 78ms/step - loss: 2.9443 - policy_loss: 2.3022 - value_loss: 0.6389 - policy_categorical_accuracy: 0.4012 - value_mse: 0.0946\n","epoch 720\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 81ms/step - loss: 2.9012 - policy_loss: 2.2654 - value_loss: 0.6326 - policy_categorical_accuracy: 0.4066 - value_mse: 0.0924\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9073307514190674, 2.2465014457702637, 0.6575896739959717, 0.41670000553131104, 0.10280043631792068]\n","epoch 721\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9110 - policy_loss: 2.2789 - value_loss: 0.6288 - policy_categorical_accuracy: 0.4071 - value_mse: 0.0910\n","epoch 722\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8721 - policy_loss: 2.2403 - value_loss: 0.6285 - policy_categorical_accuracy: 0.4158 - value_mse: 0.0909\n","epoch 723\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8976 - policy_loss: 2.2640 - value_loss: 0.6304 - policy_categorical_accuracy: 0.4056 - value_mse: 0.0923\n","epoch 724\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9242 - policy_loss: 2.2931 - value_loss: 0.6278 - policy_categorical_accuracy: 0.4014 - value_mse: 0.0911\n","epoch 725\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8999 - policy_loss: 2.2686 - value_loss: 0.6280 - policy_categorical_accuracy: 0.4085 - value_mse: 0.0914\n","epoch 726\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9281 - policy_loss: 2.2951 - value_loss: 0.6297 - policy_categorical_accuracy: 0.4071 - value_mse: 0.0924\n","epoch 727\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8823 - policy_loss: 2.2461 - value_loss: 0.6329 - policy_categorical_accuracy: 0.4145 - value_mse: 0.0922\n","epoch 728\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9155 - policy_loss: 2.2793 - value_loss: 0.6328 - policy_categorical_accuracy: 0.4106 - value_mse: 0.0917\n","epoch 729\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9075 - policy_loss: 2.2726 - value_loss: 0.6316 - policy_categorical_accuracy: 0.4035 - value_mse: 0.0922\n","epoch 730\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8894 - policy_loss: 2.2548 - value_loss: 0.6313 - policy_categorical_accuracy: 0.4191 - value_mse: 0.0905\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.8822214603424072, 2.2385969161987305, 0.6403366923332214, 0.4169999957084656, 0.09567460417747498]\n","epoch 731\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9084 - policy_loss: 2.2767 - value_loss: 0.6285 - policy_categorical_accuracy: 0.4098 - value_mse: 0.0913\n","epoch 732\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 81ms/step - loss: 2.9201 - policy_loss: 2.2831 - value_loss: 0.6337 - policy_categorical_accuracy: 0.4054 - value_mse: 0.0926\n","epoch 733\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9202 - policy_loss: 2.2873 - value_loss: 0.6296 - policy_categorical_accuracy: 0.4021 - value_mse: 0.0897\n","epoch 734\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8817 - policy_loss: 2.2470 - value_loss: 0.6314 - policy_categorical_accuracy: 0.4088 - value_mse: 0.0934\n","epoch 735\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9010 - policy_loss: 2.2671 - value_loss: 0.6305 - policy_categorical_accuracy: 0.4099 - value_mse: 0.0924\n","epoch 736\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9285 - policy_loss: 2.2940 - value_loss: 0.6312 - policy_categorical_accuracy: 0.4010 - value_mse: 0.0912\n","epoch 737\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9016 - policy_loss: 2.2640 - value_loss: 0.6343 - policy_categorical_accuracy: 0.4177 - value_mse: 0.0943\n","epoch 738\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9005 - policy_loss: 2.2664 - value_loss: 0.6308 - policy_categorical_accuracy: 0.4089 - value_mse: 0.0930\n","epoch 739\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8874 - policy_loss: 2.2554 - value_loss: 0.6287 - policy_categorical_accuracy: 0.4135 - value_mse: 0.0918\n","epoch 740\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8974 - policy_loss: 2.2666 - value_loss: 0.6275 - policy_categorical_accuracy: 0.4084 - value_mse: 0.0889\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.886281728744507, 2.234222650527954, 0.6487069129943848, 0.4120999872684479, 0.09875421971082687]\n","epoch 741\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9103 - policy_loss: 2.2771 - value_loss: 0.6299 - policy_categorical_accuracy: 0.4030 - value_mse: 0.0930\n","epoch 742\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 81ms/step - loss: 2.8814 - policy_loss: 2.2490 - value_loss: 0.6291 - policy_categorical_accuracy: 0.4115 - value_mse: 0.0911\n","epoch 743\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9161 - policy_loss: 2.2795 - value_loss: 0.6332 - policy_categorical_accuracy: 0.4073 - value_mse: 0.0917\n","epoch 744\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8953 - policy_loss: 2.2656 - value_loss: 0.6263 - policy_categorical_accuracy: 0.4079 - value_mse: 0.0887\n","epoch 745\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8888 - policy_loss: 2.2559 - value_loss: 0.6295 - policy_categorical_accuracy: 0.4120 - value_mse: 0.0926\n","epoch 746\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9056 - policy_loss: 2.2737 - value_loss: 0.6286 - policy_categorical_accuracy: 0.4077 - value_mse: 0.0915\n","epoch 747\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9156 - policy_loss: 2.2816 - value_loss: 0.6307 - policy_categorical_accuracy: 0.4036 - value_mse: 0.0916\n","epoch 748\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9230 - policy_loss: 2.2901 - value_loss: 0.6296 - policy_categorical_accuracy: 0.4059 - value_mse: 0.0910\n","epoch 749\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9325 - policy_loss: 2.3031 - value_loss: 0.6260 - policy_categorical_accuracy: 0.4012 - value_mse: 0.0909\n","epoch 750\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9415 - policy_loss: 2.3060 - value_loss: 0.6321 - policy_categorical_accuracy: 0.3992 - value_mse: 0.0924\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.8827083110809326, 2.2447245121002197, 0.634652316570282, 0.41670000553131104, 0.09388145059347153]\n","epoch 751\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9500 - policy_loss: 2.3173 - value_loss: 0.6293 - policy_categorical_accuracy: 0.3971 - value_mse: 0.0898\n","epoch 752\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9100 - policy_loss: 2.2797 - value_loss: 0.6270 - policy_categorical_accuracy: 0.4041 - value_mse: 0.0881\n","epoch 753\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8876 - policy_loss: 2.2530 - value_loss: 0.6313 - policy_categorical_accuracy: 0.4122 - value_mse: 0.0912\n","epoch 754\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 80ms/step - loss: 2.8936 - policy_loss: 2.2560 - value_loss: 0.6343 - policy_categorical_accuracy: 0.4118 - value_mse: 0.0942\n","epoch 755\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8964 - policy_loss: 2.2591 - value_loss: 0.6339 - policy_categorical_accuracy: 0.4167 - value_mse: 0.0925\n","epoch 756\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8402 - policy_loss: 2.2127 - value_loss: 0.6241 - policy_categorical_accuracy: 0.4145 - value_mse: 0.0885\n","epoch 757\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8900 - policy_loss: 2.2504 - value_loss: 0.6363 - policy_categorical_accuracy: 0.4108 - value_mse: 0.0951\n","epoch 758\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9077 - policy_loss: 2.2741 - value_loss: 0.6303 - policy_categorical_accuracy: 0.4082 - value_mse: 0.0912\n","epoch 759\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9484 - policy_loss: 2.3103 - value_loss: 0.6348 - policy_categorical_accuracy: 0.4035 - value_mse: 0.0933\n","epoch 760\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8970 - policy_loss: 2.2639 - value_loss: 0.6297 - policy_categorical_accuracy: 0.4151 - value_mse: 0.0919\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.8683741092681885, 2.2320072650909424, 0.633026123046875, 0.41510000824928284, 0.0931234136223793]\n","epoch 761\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8788 - policy_loss: 2.2470 - value_loss: 0.6284 - policy_categorical_accuracy: 0.4058 - value_mse: 0.0908\n","epoch 762\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8734 - policy_loss: 2.2410 - value_loss: 0.6291 - policy_categorical_accuracy: 0.4122 - value_mse: 0.0920\n","epoch 763\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9119 - policy_loss: 2.2800 - value_loss: 0.6285 - policy_categorical_accuracy: 0.4102 - value_mse: 0.0903\n","epoch 764\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8678 - policy_loss: 2.2319 - value_loss: 0.6325 - policy_categorical_accuracy: 0.4139 - value_mse: 0.0920\n","epoch 765\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 79ms/step - loss: 2.8970 - policy_loss: 2.2640 - value_loss: 0.6296 - policy_categorical_accuracy: 0.4130 - value_mse: 0.0910\n","epoch 766\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9073 - policy_loss: 2.2683 - value_loss: 0.6356 - policy_categorical_accuracy: 0.4083 - value_mse: 0.0931\n","epoch 767\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9107 - policy_loss: 2.2791 - value_loss: 0.6282 - policy_categorical_accuracy: 0.4077 - value_mse: 0.0912\n","epoch 768\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9485 - policy_loss: 2.3130 - value_loss: 0.6322 - policy_categorical_accuracy: 0.3987 - value_mse: 0.0915\n","epoch 769\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8827 - policy_loss: 2.2505 - value_loss: 0.6289 - policy_categorical_accuracy: 0.4072 - value_mse: 0.0903\n","epoch 770\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8732 - policy_loss: 2.2411 - value_loss: 0.6288 - policy_categorical_accuracy: 0.4117 - value_mse: 0.0931\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.888050079345703, 2.254051685333252, 0.6306142807006836, 0.41110000014305115, 0.0921805277466774]\n","epoch 771\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8956 - policy_loss: 2.2582 - value_loss: 0.6340 - policy_categorical_accuracy: 0.4141 - value_mse: 0.0937\n","epoch 772\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8842 - policy_loss: 2.2561 - value_loss: 0.6247 - policy_categorical_accuracy: 0.4134 - value_mse: 0.0895\n","epoch 773\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9063 - policy_loss: 2.2707 - value_loss: 0.6323 - policy_categorical_accuracy: 0.4098 - value_mse: 0.0926\n","epoch 774\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9265 - policy_loss: 2.2910 - value_loss: 0.6321 - policy_categorical_accuracy: 0.4058 - value_mse: 0.0912\n","epoch 775\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9208 - policy_loss: 2.2896 - value_loss: 0.6279 - policy_categorical_accuracy: 0.4032 - value_mse: 0.0909\n","epoch 776\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 79ms/step - loss: 2.8966 - policy_loss: 2.2589 - value_loss: 0.6343 - policy_categorical_accuracy: 0.4084 - value_mse: 0.0943\n","epoch 777\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 79ms/step - loss: 2.8743 - policy_loss: 2.2439 - value_loss: 0.6271 - policy_categorical_accuracy: 0.4118 - value_mse: 0.0916\n","epoch 778\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9643 - policy_loss: 2.3314 - value_loss: 0.6296 - policy_categorical_accuracy: 0.3982 - value_mse: 0.0910\n","epoch 779\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8893 - policy_loss: 2.2582 - value_loss: 0.6278 - policy_categorical_accuracy: 0.4096 - value_mse: 0.0892\n","epoch 780\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9165 - policy_loss: 2.2832 - value_loss: 0.6300 - policy_categorical_accuracy: 0.4094 - value_mse: 0.0905\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9011895656585693, 2.2439115047454834, 0.6539702415466309, 0.4174000024795532, 0.10181344300508499]\n","epoch 781\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9074 - policy_loss: 2.2775 - value_loss: 0.6266 - policy_categorical_accuracy: 0.4088 - value_mse: 0.0898\n","epoch 782\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9206 - policy_loss: 2.2838 - value_loss: 0.6335 - policy_categorical_accuracy: 0.4062 - value_mse: 0.0917\n","epoch 783\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9098 - policy_loss: 2.2729 - value_loss: 0.6337 - policy_categorical_accuracy: 0.4117 - value_mse: 0.0923\n","epoch 784\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8889 - policy_loss: 2.2530 - value_loss: 0.6326 - policy_categorical_accuracy: 0.4106 - value_mse: 0.0929\n","epoch 785\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9085 - policy_loss: 2.2774 - value_loss: 0.6278 - policy_categorical_accuracy: 0.4062 - value_mse: 0.0891\n","epoch 786\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9423 - policy_loss: 2.3068 - value_loss: 0.6322 - policy_categorical_accuracy: 0.4005 - value_mse: 0.0914\n","epoch 787\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 81ms/step - loss: 2.8929 - policy_loss: 2.2580 - value_loss: 0.6316 - policy_categorical_accuracy: 0.4090 - value_mse: 0.0923\n","epoch 788\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9129 - policy_loss: 2.2816 - value_loss: 0.6280 - policy_categorical_accuracy: 0.4030 - value_mse: 0.0916\n","epoch 789\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8858 - policy_loss: 2.2535 - value_loss: 0.6289 - policy_categorical_accuracy: 0.4088 - value_mse: 0.0924\n","epoch 790\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8800 - policy_loss: 2.2476 - value_loss: 0.6290 - policy_categorical_accuracy: 0.4140 - value_mse: 0.0896\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.915900707244873, 2.229172945022583, 0.6833491921424866, 0.4205000102519989, 0.11259841173887253]\n","epoch 791\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8942 - policy_loss: 2.2616 - value_loss: 0.6293 - policy_categorical_accuracy: 0.4098 - value_mse: 0.0892\n","epoch 792\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8798 - policy_loss: 2.2459 - value_loss: 0.6306 - policy_categorical_accuracy: 0.4127 - value_mse: 0.0923\n","epoch 793\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8997 - policy_loss: 2.2697 - value_loss: 0.6266 - policy_categorical_accuracy: 0.4069 - value_mse: 0.0902\n","epoch 794\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9306 - policy_loss: 2.2982 - value_loss: 0.6290 - policy_categorical_accuracy: 0.4016 - value_mse: 0.0913\n","epoch 795\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8928 - policy_loss: 2.2614 - value_loss: 0.6280 - policy_categorical_accuracy: 0.4066 - value_mse: 0.0897\n","epoch 796\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8872 - policy_loss: 2.2570 - value_loss: 0.6269 - policy_categorical_accuracy: 0.4047 - value_mse: 0.0918\n","epoch 797\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8686 - policy_loss: 2.2307 - value_loss: 0.6346 - policy_categorical_accuracy: 0.4162 - value_mse: 0.0929\n","epoch 798\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9020 - policy_loss: 2.2663 - value_loss: 0.6323 - policy_categorical_accuracy: 0.4055 - value_mse: 0.0911\n","epoch 799\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 81ms/step - loss: 2.9117 - policy_loss: 2.2793 - value_loss: 0.6290 - policy_categorical_accuracy: 0.4047 - value_mse: 0.0933\n","epoch 800\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8806 - policy_loss: 2.2487 - value_loss: 0.6286 - policy_categorical_accuracy: 0.4097 - value_mse: 0.0918\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.8773088455200195, 2.22947096824646, 0.6444854736328125, 0.4174000024795532, 0.09801463782787323]\n","epoch 801\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8853 - policy_loss: 2.2546 - value_loss: 0.6273 - policy_categorical_accuracy: 0.4101 - value_mse: 0.0889\n","epoch 802\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8854 - policy_loss: 2.2544 - value_loss: 0.6276 - policy_categorical_accuracy: 0.4037 - value_mse: 0.0898\n","epoch 803\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8868 - policy_loss: 2.2523 - value_loss: 0.6311 - policy_categorical_accuracy: 0.4142 - value_mse: 0.0905\n","epoch 804\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9024 - policy_loss: 2.2708 - value_loss: 0.6282 - policy_categorical_accuracy: 0.4125 - value_mse: 0.0895\n","epoch 805\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8811 - policy_loss: 2.2495 - value_loss: 0.6283 - policy_categorical_accuracy: 0.4124 - value_mse: 0.0918\n","epoch 806\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8759 - policy_loss: 2.2375 - value_loss: 0.6350 - policy_categorical_accuracy: 0.4149 - value_mse: 0.0934\n","epoch 807\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8967 - policy_loss: 2.2650 - value_loss: 0.6283 - policy_categorical_accuracy: 0.4183 - value_mse: 0.0890\n","epoch 808\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9016 - policy_loss: 2.2702 - value_loss: 0.6281 - policy_categorical_accuracy: 0.4062 - value_mse: 0.0907\n","epoch 809\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 79ms/step - loss: 2.9130 - policy_loss: 2.2804 - value_loss: 0.6292 - policy_categorical_accuracy: 0.4040 - value_mse: 0.0909\n","epoch 810\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8612 - policy_loss: 2.2260 - value_loss: 0.6318 - policy_categorical_accuracy: 0.4141 - value_mse: 0.0917\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9050025939941406, 2.236717462539673, 0.664878249168396, 0.4171000123023987, 0.10587263107299805]\n","epoch 811\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9072 - policy_loss: 2.2733 - value_loss: 0.6305 - policy_categorical_accuracy: 0.4006 - value_mse: 0.0911\n","epoch 812\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8946 - policy_loss: 2.2594 - value_loss: 0.6319 - policy_categorical_accuracy: 0.4089 - value_mse: 0.0928\n","epoch 813\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9022 - policy_loss: 2.2698 - value_loss: 0.6290 - policy_categorical_accuracy: 0.3980 - value_mse: 0.0916\n","epoch 814\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 78ms/step - loss: 2.8706 - policy_loss: 2.2373 - value_loss: 0.6299 - policy_categorical_accuracy: 0.4120 - value_mse: 0.0926\n","epoch 815\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8872 - policy_loss: 2.2558 - value_loss: 0.6280 - policy_categorical_accuracy: 0.4090 - value_mse: 0.0910\n","epoch 816\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8980 - policy_loss: 2.2678 - value_loss: 0.6268 - policy_categorical_accuracy: 0.4041 - value_mse: 0.0901\n","epoch 817\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8880 - policy_loss: 2.2541 - value_loss: 0.6306 - policy_categorical_accuracy: 0.4117 - value_mse: 0.0908\n","epoch 818\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8808 - policy_loss: 2.2462 - value_loss: 0.6312 - policy_categorical_accuracy: 0.4150 - value_mse: 0.0921\n","epoch 819\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8960 - policy_loss: 2.2644 - value_loss: 0.6282 - policy_categorical_accuracy: 0.4134 - value_mse: 0.0907\n","epoch 820\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 79ms/step - loss: 2.8746 - policy_loss: 2.2367 - value_loss: 0.6345 - policy_categorical_accuracy: 0.4206 - value_mse: 0.0942\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.861867904663086, 2.2337992191314697, 0.6246960163116455, 0.4196999967098236, 0.0894651710987091]\n","epoch 821\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8872 - policy_loss: 2.2573 - value_loss: 0.6265 - policy_categorical_accuracy: 0.4136 - value_mse: 0.0895\n","epoch 822\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9184 - policy_loss: 2.2837 - value_loss: 0.6312 - policy_categorical_accuracy: 0.4090 - value_mse: 0.0921\n","epoch 823\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8850 - policy_loss: 2.2486 - value_loss: 0.6329 - policy_categorical_accuracy: 0.4111 - value_mse: 0.0909\n","epoch 824\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8714 - policy_loss: 2.2403 - value_loss: 0.6277 - policy_categorical_accuracy: 0.4135 - value_mse: 0.0905\n","epoch 825\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8891 - policy_loss: 2.2532 - value_loss: 0.6325 - policy_categorical_accuracy: 0.4167 - value_mse: 0.0918\n","epoch 826\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8625 - policy_loss: 2.2285 - value_loss: 0.6306 - policy_categorical_accuracy: 0.4155 - value_mse: 0.0914\n","epoch 827\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8635 - policy_loss: 2.2341 - value_loss: 0.6260 - policy_categorical_accuracy: 0.4155 - value_mse: 0.0916\n","epoch 828\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9063 - policy_loss: 2.2734 - value_loss: 0.6295 - policy_categorical_accuracy: 0.4076 - value_mse: 0.0918\n","epoch 829\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9089 - policy_loss: 2.2731 - value_loss: 0.6324 - policy_categorical_accuracy: 0.4077 - value_mse: 0.0922\n","epoch 830\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9321 - policy_loss: 2.2991 - value_loss: 0.6297 - policy_categorical_accuracy: 0.4024 - value_mse: 0.0903\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.860783815383911, 2.227210760116577, 0.6302239298820496, 0.41780000925064087, 0.09176861494779587]\n","epoch 831\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 78ms/step - loss: 2.8917 - policy_loss: 2.2555 - value_loss: 0.6328 - policy_categorical_accuracy: 0.4099 - value_mse: 0.0920\n","epoch 832\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9078 - policy_loss: 2.2784 - value_loss: 0.6260 - policy_categorical_accuracy: 0.4064 - value_mse: 0.0902\n","epoch 833\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8726 - policy_loss: 2.2432 - value_loss: 0.6261 - policy_categorical_accuracy: 0.4150 - value_mse: 0.0920\n","epoch 834\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9126 - policy_loss: 2.2798 - value_loss: 0.6295 - policy_categorical_accuracy: 0.4076 - value_mse: 0.0902\n","epoch 835\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8862 - policy_loss: 2.2540 - value_loss: 0.6289 - policy_categorical_accuracy: 0.4153 - value_mse: 0.0916\n","epoch 836\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8629 - policy_loss: 2.2268 - value_loss: 0.6327 - policy_categorical_accuracy: 0.4181 - value_mse: 0.0920\n","epoch 837\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8828 - policy_loss: 2.2523 - value_loss: 0.6271 - policy_categorical_accuracy: 0.4074 - value_mse: 0.0925\n","epoch 838\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8610 - policy_loss: 2.2296 - value_loss: 0.6281 - policy_categorical_accuracy: 0.4148 - value_mse: 0.0914\n","epoch 839\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8990 - policy_loss: 2.2658 - value_loss: 0.6299 - policy_categorical_accuracy: 0.4083 - value_mse: 0.0900\n","epoch 840\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8938 - policy_loss: 2.2588 - value_loss: 0.6317 - policy_categorical_accuracy: 0.4116 - value_mse: 0.0905\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.8808374404907227, 2.2347028255462646, 0.6427812576293945, 0.4169999957084656, 0.09690740704536438]\n","epoch 841\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8837 - policy_loss: 2.2518 - value_loss: 0.6285 - policy_categorical_accuracy: 0.4112 - value_mse: 0.0907\n","epoch 842\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9265 - policy_loss: 2.2912 - value_loss: 0.6319 - policy_categorical_accuracy: 0.4056 - value_mse: 0.0920\n","epoch 843\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8905 - policy_loss: 2.2577 - value_loss: 0.6294 - policy_categorical_accuracy: 0.4121 - value_mse: 0.0906\n","epoch 844\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8673 - policy_loss: 2.2367 - value_loss: 0.6272 - policy_categorical_accuracy: 0.4156 - value_mse: 0.0910\n","epoch 845\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8759 - policy_loss: 2.2400 - value_loss: 0.6325 - policy_categorical_accuracy: 0.4150 - value_mse: 0.0928\n","epoch 846\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8717 - policy_loss: 2.2444 - value_loss: 0.6240 - policy_categorical_accuracy: 0.4120 - value_mse: 0.0905\n","epoch 847\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9060 - policy_loss: 2.2720 - value_loss: 0.6306 - policy_categorical_accuracy: 0.4064 - value_mse: 0.0906\n","epoch 848\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9094 - policy_loss: 2.2753 - value_loss: 0.6307 - policy_categorical_accuracy: 0.4026 - value_mse: 0.0914\n","epoch 849\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8656 - policy_loss: 2.2356 - value_loss: 0.6266 - policy_categorical_accuracy: 0.4122 - value_mse: 0.0915\n","epoch 850\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9061 - policy_loss: 2.2750 - value_loss: 0.6278 - policy_categorical_accuracy: 0.4127 - value_mse: 0.0918\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.865650177001953, 2.229156255722046, 0.6330358386039734, 0.41690000891685486, 0.09312699735164642]\n","epoch 851\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8701 - policy_loss: 2.2378 - value_loss: 0.6288 - policy_categorical_accuracy: 0.4160 - value_mse: 0.0907\n","epoch 852\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9002 - policy_loss: 2.2695 - value_loss: 0.6273 - policy_categorical_accuracy: 0.4048 - value_mse: 0.0891\n","epoch 853\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 82ms/step - loss: 2.8926 - policy_loss: 2.2595 - value_loss: 0.6297 - policy_categorical_accuracy: 0.4076 - value_mse: 0.0905\n","epoch 854\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9079 - policy_loss: 2.2775 - value_loss: 0.6269 - policy_categorical_accuracy: 0.3988 - value_mse: 0.0911\n","epoch 855\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9046 - policy_loss: 2.2687 - value_loss: 0.6324 - policy_categorical_accuracy: 0.4096 - value_mse: 0.0922\n","epoch 856\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8843 - policy_loss: 2.2540 - value_loss: 0.6269 - policy_categorical_accuracy: 0.4150 - value_mse: 0.0909\n","epoch 857\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9033 - policy_loss: 2.2711 - value_loss: 0.6288 - policy_categorical_accuracy: 0.4067 - value_mse: 0.0914\n","epoch 858\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8928 - policy_loss: 2.2575 - value_loss: 0.6319 - policy_categorical_accuracy: 0.4094 - value_mse: 0.0929\n","epoch 859\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8760 - policy_loss: 2.2421 - value_loss: 0.6305 - policy_categorical_accuracy: 0.4154 - value_mse: 0.0906\n","epoch 860\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8723 - policy_loss: 2.2404 - value_loss: 0.6285 - policy_categorical_accuracy: 0.4144 - value_mse: 0.0894\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9434337615966797, 2.2451999187469482, 0.6947957277297974, 0.41850000619888306, 0.11682058125734329]\n","epoch 861\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8886 - policy_loss: 2.2587 - value_loss: 0.6264 - policy_categorical_accuracy: 0.4074 - value_mse: 0.0903\n","epoch 862\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8920 - policy_loss: 2.2564 - value_loss: 0.6321 - policy_categorical_accuracy: 0.4092 - value_mse: 0.0927\n","epoch 863\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 78ms/step - loss: 2.9147 - policy_loss: 2.2800 - value_loss: 0.6313 - policy_categorical_accuracy: 0.4054 - value_mse: 0.0922\n","epoch 864\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8662 - policy_loss: 2.2324 - value_loss: 0.6303 - policy_categorical_accuracy: 0.4124 - value_mse: 0.0909\n","epoch 865\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8987 - policy_loss: 2.2652 - value_loss: 0.6301 - policy_categorical_accuracy: 0.4118 - value_mse: 0.0925\n","epoch 866\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9024 - policy_loss: 2.2717 - value_loss: 0.6273 - policy_categorical_accuracy: 0.4083 - value_mse: 0.0904\n","epoch 867\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9332 - policy_loss: 2.2972 - value_loss: 0.6326 - policy_categorical_accuracy: 0.4065 - value_mse: 0.0903\n","epoch 868\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8924 - policy_loss: 2.2600 - value_loss: 0.6290 - policy_categorical_accuracy: 0.4158 - value_mse: 0.0908\n","epoch 869\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8604 - policy_loss: 2.2278 - value_loss: 0.6292 - policy_categorical_accuracy: 0.4133 - value_mse: 0.0916\n","epoch 870\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8672 - policy_loss: 2.2374 - value_loss: 0.6264 - policy_categorical_accuracy: 0.4211 - value_mse: 0.0915\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.8749890327453613, 2.237802743911743, 0.6337458491325378, 0.41620001196861267, 0.0935235396027565]\n","epoch 871\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8677 - policy_loss: 2.2407 - value_loss: 0.6235 - policy_categorical_accuracy: 0.4129 - value_mse: 0.0890\n","epoch 872\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8953 - policy_loss: 2.2608 - value_loss: 0.6311 - policy_categorical_accuracy: 0.4096 - value_mse: 0.0930\n","epoch 873\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8845 - policy_loss: 2.2543 - value_loss: 0.6269 - policy_categorical_accuracy: 0.4115 - value_mse: 0.0891\n","epoch 874\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 83ms/step - loss: 2.8756 - policy_loss: 2.2387 - value_loss: 0.6335 - policy_categorical_accuracy: 0.4141 - value_mse: 0.0928\n","epoch 875\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8683 - policy_loss: 2.2413 - value_loss: 0.6236 - policy_categorical_accuracy: 0.4116 - value_mse: 0.0886\n","epoch 876\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8808 - policy_loss: 2.2486 - value_loss: 0.6288 - policy_categorical_accuracy: 0.4157 - value_mse: 0.0907\n","epoch 877\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8847 - policy_loss: 2.2581 - value_loss: 0.6232 - policy_categorical_accuracy: 0.4079 - value_mse: 0.0888\n","epoch 878\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8767 - policy_loss: 2.2456 - value_loss: 0.6277 - policy_categorical_accuracy: 0.4091 - value_mse: 0.0909\n","epoch 879\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8864 - policy_loss: 2.2573 - value_loss: 0.6256 - policy_categorical_accuracy: 0.4080 - value_mse: 0.0912\n","epoch 880\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8587 - policy_loss: 2.2351 - value_loss: 0.6201 - policy_categorical_accuracy: 0.4089 - value_mse: 0.0880\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.8558740615844727, 2.2193448543548584, 0.6330364942550659, 0.41589999198913574, 0.09309624880552292]\n","epoch 881\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8702 - policy_loss: 2.2407 - value_loss: 0.6261 - policy_categorical_accuracy: 0.4109 - value_mse: 0.0901\n","epoch 882\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8745 - policy_loss: 2.2452 - value_loss: 0.6257 - policy_categorical_accuracy: 0.4121 - value_mse: 0.0877\n","epoch 883\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8839 - policy_loss: 2.2525 - value_loss: 0.6279 - policy_categorical_accuracy: 0.4158 - value_mse: 0.0907\n","epoch 884\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8921 - policy_loss: 2.2614 - value_loss: 0.6272 - policy_categorical_accuracy: 0.4049 - value_mse: 0.0909\n","epoch 885\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 7s 82ms/step - loss: 2.8974 - policy_loss: 2.2726 - value_loss: 0.6212 - policy_categorical_accuracy: 0.4062 - value_mse: 0.0900\n","epoch 886\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8773 - policy_loss: 2.2418 - value_loss: 0.6320 - policy_categorical_accuracy: 0.4102 - value_mse: 0.0926\n","epoch 887\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9036 - policy_loss: 2.2751 - value_loss: 0.6250 - policy_categorical_accuracy: 0.4157 - value_mse: 0.0889\n","epoch 888\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8697 - policy_loss: 2.2398 - value_loss: 0.6264 - policy_categorical_accuracy: 0.4115 - value_mse: 0.0893\n","epoch 889\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8967 - policy_loss: 2.2638 - value_loss: 0.6294 - policy_categorical_accuracy: 0.4063 - value_mse: 0.0909\n","epoch 890\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8539 - policy_loss: 2.2220 - value_loss: 0.6284 - policy_categorical_accuracy: 0.4154 - value_mse: 0.0933\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9084463119506836, 2.234757661819458, 0.670190691947937, 0.4228000044822693, 0.10810361057519913]\n","epoch 891\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8598 - policy_loss: 2.2331 - value_loss: 0.6232 - policy_categorical_accuracy: 0.4128 - value_mse: 0.0886\n","epoch 892\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8793 - policy_loss: 2.2473 - value_loss: 0.6285 - policy_categorical_accuracy: 0.4104 - value_mse: 0.0902\n","epoch 893\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8701 - policy_loss: 2.2380 - value_loss: 0.6286 - policy_categorical_accuracy: 0.4172 - value_mse: 0.0922\n","epoch 894\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8702 - policy_loss: 2.2384 - value_loss: 0.6282 - policy_categorical_accuracy: 0.4130 - value_mse: 0.0899\n","epoch 895\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 78ms/step - loss: 2.8550 - policy_loss: 2.2247 - value_loss: 0.6267 - policy_categorical_accuracy: 0.4148 - value_mse: 0.0897\n","epoch 896\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 80ms/step - loss: 2.8561 - policy_loss: 2.2284 - value_loss: 0.6242 - policy_categorical_accuracy: 0.4109 - value_mse: 0.0883\n","epoch 897\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8496 - policy_loss: 2.2163 - value_loss: 0.6298 - policy_categorical_accuracy: 0.4178 - value_mse: 0.0918\n","epoch 898\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8815 - policy_loss: 2.2561 - value_loss: 0.6220 - policy_categorical_accuracy: 0.3984 - value_mse: 0.0896\n","epoch 899\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8730 - policy_loss: 2.2413 - value_loss: 0.6282 - policy_categorical_accuracy: 0.4145 - value_mse: 0.0904\n","epoch 900\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8678 - policy_loss: 2.2394 - value_loss: 0.6249 - policy_categorical_accuracy: 0.4117 - value_mse: 0.0906\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.8381731510162354, 2.207310676574707, 0.6273564100265503, 0.4205999970436096, 0.09107792377471924]\n","epoch 901\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8489 - policy_loss: 2.2163 - value_loss: 0.6291 - policy_categorical_accuracy: 0.4227 - value_mse: 0.0890\n","epoch 902\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8969 - policy_loss: 2.2672 - value_loss: 0.6262 - policy_categorical_accuracy: 0.4096 - value_mse: 0.0922\n","epoch 903\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9151 - policy_loss: 2.2832 - value_loss: 0.6284 - policy_categorical_accuracy: 0.4044 - value_mse: 0.0916\n","epoch 904\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8876 - policy_loss: 2.2568 - value_loss: 0.6274 - policy_categorical_accuracy: 0.4079 - value_mse: 0.0912\n","epoch 905\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8609 - policy_loss: 2.2332 - value_loss: 0.6242 - policy_categorical_accuracy: 0.4178 - value_mse: 0.0898\n","epoch 906\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9054 - policy_loss: 2.2735 - value_loss: 0.6285 - policy_categorical_accuracy: 0.4087 - value_mse: 0.0906\n","epoch 907\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 81ms/step - loss: 2.9032 - policy_loss: 2.2706 - value_loss: 0.6291 - policy_categorical_accuracy: 0.4120 - value_mse: 0.0901\n","epoch 908\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8760 - policy_loss: 2.2488 - value_loss: 0.6237 - policy_categorical_accuracy: 0.4085 - value_mse: 0.0878\n","epoch 909\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8682 - policy_loss: 2.2391 - value_loss: 0.6257 - policy_categorical_accuracy: 0.4130 - value_mse: 0.0903\n","epoch 910\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8887 - policy_loss: 2.2504 - value_loss: 0.6348 - policy_categorical_accuracy: 0.4127 - value_mse: 0.0926\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.869779586791992, 2.239682674407959, 0.6266034841537476, 0.4129999876022339, 0.09057861566543579]\n","epoch 911\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8714 - policy_loss: 2.2416 - value_loss: 0.6263 - policy_categorical_accuracy: 0.4108 - value_mse: 0.0906\n","epoch 912\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8749 - policy_loss: 2.2476 - value_loss: 0.6238 - policy_categorical_accuracy: 0.4088 - value_mse: 0.0889\n","epoch 913\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8800 - policy_loss: 2.2512 - value_loss: 0.6253 - policy_categorical_accuracy: 0.4092 - value_mse: 0.0904\n","epoch 914\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9162 - policy_loss: 2.2855 - value_loss: 0.6272 - policy_categorical_accuracy: 0.4082 - value_mse: 0.0895\n","epoch 915\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8609 - policy_loss: 2.2327 - value_loss: 0.6246 - policy_categorical_accuracy: 0.4075 - value_mse: 0.0894\n","epoch 916\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8631 - policy_loss: 2.2275 - value_loss: 0.6321 - policy_categorical_accuracy: 0.4194 - value_mse: 0.0905\n","epoch 917\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 81ms/step - loss: 2.8738 - policy_loss: 2.2406 - value_loss: 0.6296 - policy_categorical_accuracy: 0.4202 - value_mse: 0.0915\n","epoch 918\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8642 - policy_loss: 2.2308 - value_loss: 0.6299 - policy_categorical_accuracy: 0.4098 - value_mse: 0.0914\n","epoch 919\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9001 - policy_loss: 2.2734 - value_loss: 0.6232 - policy_categorical_accuracy: 0.4136 - value_mse: 0.0882\n","epoch 920\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8658 - policy_loss: 2.2363 - value_loss: 0.6259 - policy_categorical_accuracy: 0.4145 - value_mse: 0.0900\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.8737399578094482, 2.21274995803833, 0.657497227191925, 0.4203000068664551, 0.102829210460186]\n","epoch 921\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8409 - policy_loss: 2.2125 - value_loss: 0.6249 - policy_categorical_accuracy: 0.4276 - value_mse: 0.0891\n","epoch 922\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8771 - policy_loss: 2.2417 - value_loss: 0.6319 - policy_categorical_accuracy: 0.4161 - value_mse: 0.0926\n","epoch 923\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8735 - policy_loss: 2.2422 - value_loss: 0.6279 - policy_categorical_accuracy: 0.4186 - value_mse: 0.0913\n","epoch 924\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8796 - policy_loss: 2.2440 - value_loss: 0.6321 - policy_categorical_accuracy: 0.4107 - value_mse: 0.0922\n","epoch 925\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8720 - policy_loss: 2.2445 - value_loss: 0.6240 - policy_categorical_accuracy: 0.4118 - value_mse: 0.0900\n","epoch 926\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 78ms/step - loss: 2.8767 - policy_loss: 2.2436 - value_loss: 0.6296 - policy_categorical_accuracy: 0.4144 - value_mse: 0.0910\n","epoch 927\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8864 - policy_loss: 2.2559 - value_loss: 0.6270 - policy_categorical_accuracy: 0.4125 - value_mse: 0.0900\n","epoch 928\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8862 - policy_loss: 2.2588 - value_loss: 0.6239 - policy_categorical_accuracy: 0.4085 - value_mse: 0.0908\n","epoch 929\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9099 - policy_loss: 2.2746 - value_loss: 0.6318 - policy_categorical_accuracy: 0.4081 - value_mse: 0.0919\n","epoch 930\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8931 - policy_loss: 2.2579 - value_loss: 0.6317 - policy_categorical_accuracy: 0.4105 - value_mse: 0.0924\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.8550658226013184, 2.2224655151367188, 0.6290937662124634, 0.4174000024795532, 0.09124673157930374]\n","epoch 931\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8791 - policy_loss: 2.2416 - value_loss: 0.6339 - policy_categorical_accuracy: 0.4143 - value_mse: 0.0935\n","epoch 932\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8961 - policy_loss: 2.2637 - value_loss: 0.6289 - policy_categorical_accuracy: 0.4067 - value_mse: 0.0926\n","epoch 933\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8405 - policy_loss: 2.2116 - value_loss: 0.6255 - policy_categorical_accuracy: 0.4201 - value_mse: 0.0907\n","epoch 934\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8704 - policy_loss: 2.2380 - value_loss: 0.6289 - policy_categorical_accuracy: 0.4215 - value_mse: 0.0911\n","epoch 935\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8716 - policy_loss: 2.2438 - value_loss: 0.6243 - policy_categorical_accuracy: 0.4162 - value_mse: 0.0897\n","epoch 936\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9069 - policy_loss: 2.2753 - value_loss: 0.6281 - policy_categorical_accuracy: 0.4027 - value_mse: 0.0904\n","epoch 937\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 78ms/step - loss: 2.8492 - policy_loss: 2.2186 - value_loss: 0.6271 - policy_categorical_accuracy: 0.4205 - value_mse: 0.0907\n","epoch 938\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 79ms/step - loss: 2.8695 - policy_loss: 2.2380 - value_loss: 0.6280 - policy_categorical_accuracy: 0.4200 - value_mse: 0.0917\n","epoch 939\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8899 - policy_loss: 2.2611 - value_loss: 0.6253 - policy_categorical_accuracy: 0.4135 - value_mse: 0.0906\n","epoch 940\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8558 - policy_loss: 2.2277 - value_loss: 0.6245 - policy_categorical_accuracy: 0.4212 - value_mse: 0.0893\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.8969357013702393, 2.211843252182007, 0.6815715432167053, 0.4172999858856201, 0.11160219460725784]\n","epoch 941\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8656 - policy_loss: 2.2399 - value_loss: 0.6222 - policy_categorical_accuracy: 0.4132 - value_mse: 0.0893\n","epoch 942\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8643 - policy_loss: 2.2317 - value_loss: 0.6291 - policy_categorical_accuracy: 0.4088 - value_mse: 0.0914\n","epoch 943\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8942 - policy_loss: 2.2652 - value_loss: 0.6254 - policy_categorical_accuracy: 0.4090 - value_mse: 0.0905\n","epoch 944\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8609 - policy_loss: 2.2279 - value_loss: 0.6294 - policy_categorical_accuracy: 0.4161 - value_mse: 0.0906\n","epoch 945\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8219 - policy_loss: 2.1891 - value_loss: 0.6292 - policy_categorical_accuracy: 0.4213 - value_mse: 0.0928\n","epoch 946\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8874 - policy_loss: 2.2559 - value_loss: 0.6279 - policy_categorical_accuracy: 0.4146 - value_mse: 0.0897\n","epoch 947\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8525 - policy_loss: 2.2196 - value_loss: 0.6293 - policy_categorical_accuracy: 0.4165 - value_mse: 0.0910\n","epoch 948\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8642 - policy_loss: 2.2309 - value_loss: 0.6297 - policy_categorical_accuracy: 0.4111 - value_mse: 0.0923\n","epoch 949\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8877 - policy_loss: 2.2532 - value_loss: 0.6310 - policy_categorical_accuracy: 0.4097 - value_mse: 0.0917\n","epoch 950\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8947 - policy_loss: 2.2626 - value_loss: 0.6286 - policy_categorical_accuracy: 0.4081 - value_mse: 0.0911\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.863629102706909, 2.2235915660858154, 0.6365242004394531, 0.4162999987602234, 0.09487681835889816]\n","epoch 951\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8748 - policy_loss: 2.2436 - value_loss: 0.6277 - policy_categorical_accuracy: 0.4122 - value_mse: 0.0915\n","epoch 952\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8985 - policy_loss: 2.2668 - value_loss: 0.6282 - policy_categorical_accuracy: 0.4065 - value_mse: 0.0911\n","epoch 953\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9000 - policy_loss: 2.2688 - value_loss: 0.6277 - policy_categorical_accuracy: 0.4055 - value_mse: 0.0897\n","epoch 954\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8508 - policy_loss: 2.2206 - value_loss: 0.6267 - policy_categorical_accuracy: 0.4208 - value_mse: 0.0910\n","epoch 955\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8641 - policy_loss: 2.2346 - value_loss: 0.6260 - policy_categorical_accuracy: 0.4163 - value_mse: 0.0905\n","epoch 956\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8744 - policy_loss: 2.2443 - value_loss: 0.6266 - policy_categorical_accuracy: 0.4134 - value_mse: 0.0900\n","epoch 957\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8647 - policy_loss: 2.2298 - value_loss: 0.6313 - policy_categorical_accuracy: 0.4141 - value_mse: 0.0910\n","epoch 958\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 80ms/step - loss: 2.8617 - policy_loss: 2.2345 - value_loss: 0.6236 - policy_categorical_accuracy: 0.4130 - value_mse: 0.0897\n","epoch 959\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8985 - policy_loss: 2.2686 - value_loss: 0.6264 - policy_categorical_accuracy: 0.4099 - value_mse: 0.0910\n","epoch 960\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8893 - policy_loss: 2.2570 - value_loss: 0.6288 - policy_categorical_accuracy: 0.4051 - value_mse: 0.0902\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.8910763263702393, 2.257664442062378, 0.6298817992210388, 0.41429999470710754, 0.09142399579286575]\n","epoch 961\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8764 - policy_loss: 2.2448 - value_loss: 0.6281 - policy_categorical_accuracy: 0.4157 - value_mse: 0.0906\n","epoch 962\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8999 - policy_loss: 2.2674 - value_loss: 0.6289 - policy_categorical_accuracy: 0.4133 - value_mse: 0.0921\n","epoch 963\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8476 - policy_loss: 2.2202 - value_loss: 0.6238 - policy_categorical_accuracy: 0.4144 - value_mse: 0.0906\n","epoch 964\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 75ms/step - loss: 2.8772 - policy_loss: 2.2415 - value_loss: 0.6322 - policy_categorical_accuracy: 0.4162 - value_mse: 0.0918\n","epoch 965\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.9034 - policy_loss: 2.2760 - value_loss: 0.6239 - policy_categorical_accuracy: 0.4047 - value_mse: 0.0889\n","epoch 966\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8703 - policy_loss: 2.2392 - value_loss: 0.6275 - policy_categorical_accuracy: 0.4113 - value_mse: 0.0885\n","epoch 967\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.9104 - policy_loss: 2.2807 - value_loss: 0.6262 - policy_categorical_accuracy: 0.4049 - value_mse: 0.0899\n","epoch 968\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8776 - policy_loss: 2.2456 - value_loss: 0.6284 - policy_categorical_accuracy: 0.4138 - value_mse: 0.0893\n","epoch 969\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 81ms/step - loss: 2.8675 - policy_loss: 2.2426 - value_loss: 0.6214 - policy_categorical_accuracy: 0.4124 - value_mse: 0.0906\n","epoch 970\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8948 - policy_loss: 2.2635 - value_loss: 0.6277 - policy_categorical_accuracy: 0.4062 - value_mse: 0.0906\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.8629496097564697, 2.2214057445526123, 0.6379876732826233, 0.4162999987602234, 0.09496023505926132]\n","epoch 971\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8961 - policy_loss: 2.2657 - value_loss: 0.6268 - policy_categorical_accuracy: 0.4086 - value_mse: 0.0901\n","epoch 972\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8787 - policy_loss: 2.2461 - value_loss: 0.6291 - policy_categorical_accuracy: 0.4154 - value_mse: 0.0898\n","epoch 973\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8629 - policy_loss: 2.2339 - value_loss: 0.6255 - policy_categorical_accuracy: 0.4159 - value_mse: 0.0905\n","epoch 974\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8791 - policy_loss: 2.2496 - value_loss: 0.6259 - policy_categorical_accuracy: 0.4107 - value_mse: 0.0916\n","epoch 975\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8960 - policy_loss: 2.2631 - value_loss: 0.6293 - policy_categorical_accuracy: 0.4073 - value_mse: 0.0912\n","epoch 976\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8761 - policy_loss: 2.2463 - value_loss: 0.6262 - policy_categorical_accuracy: 0.4173 - value_mse: 0.0900\n","epoch 977\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8968 - policy_loss: 2.2605 - value_loss: 0.6328 - policy_categorical_accuracy: 0.4144 - value_mse: 0.0922\n","epoch 978\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8877 - policy_loss: 2.2561 - value_loss: 0.6281 - policy_categorical_accuracy: 0.4100 - value_mse: 0.0918\n","epoch 979\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8700 - policy_loss: 2.2426 - value_loss: 0.6239 - policy_categorical_accuracy: 0.4176 - value_mse: 0.0890\n","epoch 980\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8662 - policy_loss: 2.2357 - value_loss: 0.6270 - policy_categorical_accuracy: 0.4192 - value_mse: 0.0918\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.8368358612060547, 2.2044639587402344, 0.6288096904754639, 0.4262000024318695, 0.09129787981510162]\n","epoch 981\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8580 - policy_loss: 2.2307 - value_loss: 0.6237 - policy_categorical_accuracy: 0.4165 - value_mse: 0.0898\n","epoch 982\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8949 - policy_loss: 2.2682 - value_loss: 0.6232 - policy_categorical_accuracy: 0.4054 - value_mse: 0.0885\n","epoch 983\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8690 - policy_loss: 2.2359 - value_loss: 0.6296 - policy_categorical_accuracy: 0.4141 - value_mse: 0.0908\n","epoch 984\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8543 - policy_loss: 2.2245 - value_loss: 0.6263 - policy_categorical_accuracy: 0.4131 - value_mse: 0.0904\n","epoch 985\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8613 - policy_loss: 2.2315 - value_loss: 0.6263 - policy_categorical_accuracy: 0.4186 - value_mse: 0.0902\n","epoch 986\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8747 - policy_loss: 2.2423 - value_loss: 0.6289 - policy_categorical_accuracy: 0.4111 - value_mse: 0.0913\n","epoch 987\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8716 - policy_loss: 2.2366 - value_loss: 0.6315 - policy_categorical_accuracy: 0.4163 - value_mse: 0.0919\n","epoch 988\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8549 - policy_loss: 2.2248 - value_loss: 0.6266 - policy_categorical_accuracy: 0.4146 - value_mse: 0.0902\n","epoch 989\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8329 - policy_loss: 2.2022 - value_loss: 0.6271 - policy_categorical_accuracy: 0.4176 - value_mse: 0.0913\n","epoch 990\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8536 - policy_loss: 2.2255 - value_loss: 0.6246 - policy_categorical_accuracy: 0.4195 - value_mse: 0.0897\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.860288381576538, 2.2100112438201904, 0.6467107534408569, 0.4223000109195709, 0.09844060987234116]\n","epoch 991\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 78ms/step - loss: 2.8428 - policy_loss: 2.2112 - value_loss: 0.6280 - policy_categorical_accuracy: 0.4243 - value_mse: 0.0905\n","epoch 992\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8803 - policy_loss: 2.2480 - value_loss: 0.6287 - policy_categorical_accuracy: 0.4130 - value_mse: 0.0907\n","epoch 993\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8638 - policy_loss: 2.2303 - value_loss: 0.6300 - policy_categorical_accuracy: 0.4238 - value_mse: 0.0909\n","epoch 994\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8625 - policy_loss: 2.2341 - value_loss: 0.6248 - policy_categorical_accuracy: 0.4077 - value_mse: 0.0888\n","epoch 995\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8824 - policy_loss: 2.2524 - value_loss: 0.6264 - policy_categorical_accuracy: 0.4111 - value_mse: 0.0902\n","epoch 996\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8500 - policy_loss: 2.2192 - value_loss: 0.6273 - policy_categorical_accuracy: 0.4154 - value_mse: 0.0915\n","epoch 997\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 77ms/step - loss: 2.8770 - policy_loss: 2.2498 - value_loss: 0.6236 - policy_categorical_accuracy: 0.4099 - value_mse: 0.0895\n","epoch 998\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8625 - policy_loss: 2.2334 - value_loss: 0.6255 - policy_categorical_accuracy: 0.4105 - value_mse: 0.0903\n","epoch 999\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8770 - policy_loss: 2.2438 - value_loss: 0.6296 - policy_categorical_accuracy: 0.4090 - value_mse: 0.0896\n","epoch 1000\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 6s 76ms/step - loss: 2.8712 - policy_loss: 2.2429 - value_loss: 0.6246 - policy_categorical_accuracy: 0.4167 - value_mse: 0.0894\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.8650693893432617, 2.2065963745117188, 0.654870331287384, 0.4219000041484833, 0.10125678777694702]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SNxDy5hTfHs_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6a55ca18-8b35-4004-c19b-b3209903d48c","executionInfo":{"status":"ok","timestamp":1672390270596,"user_tz":-60,"elapsed":6796670,"user":{"displayName":"Adrien","userId":"14922326483433512417"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-12-30 06:57:52.968318: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-12-30 06:57:53.884535: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-12-30 06:57:53.884694: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-12-30 06:57:53.884715: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","getValidation\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","tcmalloc: large alloc 2400002048 bytes == 0x57028000 @  0x7eff3eeb4887 0x7efeec0af0d9 0x7efeec0b485f 0x7efeec0c906f 0x58e314 0x514581 0x5a5fb6 0x607433 0x601066 0x60112c 0x6015f6 0x64faa2 0x64fc4e 0x7eff3eaafc87 0x5b64ca\n","nbPositionsSGF = 29425326\n","nbPositionsSGF = 29425326\n","loading validation.data\n","2022-12-30 06:58:21.501560: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-30 06:58:21.646387: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-30 06:58:21.647044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-30 06:58:21.647925: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-12-30 06:58:21.648184: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-30 06:58:21.648759: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-30 06:58:21.649365: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-30 06:58:22.305617: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-30 06:58:22.306320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-30 06:58:22.306878: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-30 06:58:22.307406: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-12-30 06:58:22.307490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13779 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," board (InputLayer)             [(None, 19, 19, 31)  0           []                               \n","                                ]                                                                 \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 19, 19, 24)   768         ['board[0][0]']                  \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 19, 19, 24)  96          ['conv2d[0][0]']                 \n"," alization)                                                                                       \n","                                                                                                  \n"," tf.math.sigmoid (TFOpLambda)   (None, 19, 19, 24)   0           ['batch_normalization[0][0]']    \n","                                                                                                  \n"," multiply (Multiply)            (None, 19, 19, 24)   0           ['batch_normalization[0][0]',    \n","                                                                  'tf.math.sigmoid[0][0]']        \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 19, 19, 48)   1152        ['multiply[0][0]']               \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 19, 19, 48)  192         ['conv2d_1[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.math.sigmoid_1 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," multiply_1 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_1[0][0]',  \n","                                                                  'tf.math.sigmoid_1[0][0]']      \n","                                                                                                  \n"," depthwise_conv2d (DepthwiseCon  (None, 19, 19, 48)  432         ['multiply_1[0][0]']             \n"," v2D)                                                                                             \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 19, 19, 48)  192         ['depthwise_conv2d[0][0]']       \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.math.sigmoid_2 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_2[0][0]']  \n","                                                                                                  \n"," multiply_2 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_2[0][0]',  \n","                                                                  'tf.math.sigmoid_2[0][0]']      \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 19, 19, 24)   1152        ['multiply_2[0][0]']             \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 19, 19, 24)  96          ['conv2d_2[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add (Add)                      (None, 19, 19, 24)   0           ['batch_normalization_3[0][0]',  \n","                                                                  'multiply[0][0]']               \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 19, 19, 48)   1152        ['add[0][0]']                    \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 19, 19, 48)  192         ['conv2d_3[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.math.sigmoid_3 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_4[0][0]']  \n","                                                                                                  \n"," multiply_3 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_4[0][0]',  \n","                                                                  'tf.math.sigmoid_3[0][0]']      \n","                                                                                                  \n"," depthwise_conv2d_1 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_3[0][0]']             \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 19, 19, 48)  192         ['depthwise_conv2d_1[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.math.sigmoid_4 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," multiply_4 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_5[0][0]',  \n","                                                                  'tf.math.sigmoid_4[0][0]']      \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 19, 19, 24)   1152        ['multiply_4[0][0]']             \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 19, 19, 24)  96          ['conv2d_4[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add_1 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_6[0][0]',  \n","                                                                  'add[0][0]']                    \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 19, 19, 48)   1152        ['add_1[0][0]']                  \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 19, 19, 48)  192         ['conv2d_5[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.math.sigmoid_5 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_7[0][0]']  \n","                                                                                                  \n"," multiply_5 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_7[0][0]',  \n","                                                                  'tf.math.sigmoid_5[0][0]']      \n","                                                                                                  \n"," depthwise_conv2d_2 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_5[0][0]']             \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 19, 19, 48)  192         ['depthwise_conv2d_2[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.math.sigmoid_6 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_8[0][0]']  \n","                                                                                                  \n"," multiply_6 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_8[0][0]',  \n","                                                                  'tf.math.sigmoid_6[0][0]']      \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 19, 19, 24)   1152        ['multiply_6[0][0]']             \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 19, 19, 24)  96          ['conv2d_6[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add_2 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_9[0][0]',  \n","                                                                  'add_1[0][0]']                  \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 19, 19, 48)   1152        ['add_2[0][0]']                  \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 19, 19, 48)  192         ['conv2d_7[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_7 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_10[0][0]'] \n","                                                                                                  \n"," multiply_7 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_10[0][0]', \n","                                                                  'tf.math.sigmoid_7[0][0]']      \n","                                                                                                  \n"," depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_7[0][0]']             \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_11 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_3[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_8 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_11[0][0]'] \n","                                                                                                  \n"," multiply_8 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_11[0][0]', \n","                                                                  'tf.math.sigmoid_8[0][0]']      \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 19, 19, 24)   1152        ['multiply_8[0][0]']             \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 19, 19, 24)  96          ['conv2d_8[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_3 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_12[0][0]', \n","                                                                  'add_2[0][0]']                  \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 19, 19, 48)   1152        ['add_3[0][0]']                  \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 19, 19, 48)  192         ['conv2d_9[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_9 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_13[0][0]'] \n","                                                                                                  \n"," multiply_9 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_13[0][0]', \n","                                                                  'tf.math.sigmoid_9[0][0]']      \n","                                                                                                  \n"," depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_9[0][0]']             \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_4[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_10 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_14[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_10 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_14[0][0]', \n","                                                                  'tf.math.sigmoid_10[0][0]']     \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 19, 19, 24)   1152        ['multiply_10[0][0]']            \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 19, 19, 24)  96          ['conv2d_10[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_4 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_15[0][0]', \n","                                                                  'add_3[0][0]']                  \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 19, 19, 48)   1152        ['add_4[0][0]']                  \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 19, 19, 48)  192         ['conv2d_11[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_11 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_16[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_11 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_16[0][0]', \n","                                                                  'tf.math.sigmoid_11[0][0]']     \n","                                                                                                  \n"," depthwise_conv2d_5 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_11[0][0]']            \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_5[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_12 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_17[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_12 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_17[0][0]', \n","                                                                  'tf.math.sigmoid_12[0][0]']     \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 19, 19, 24)   1152        ['multiply_12[0][0]']            \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 19, 19, 24)  96          ['conv2d_12[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_5 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_18[0][0]', \n","                                                                  'add_4[0][0]']                  \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 19, 19, 48)   1152        ['add_5[0][0]']                  \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 19, 19, 48)  192         ['conv2d_13[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_13 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_19[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_13 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_19[0][0]', \n","                                                                  'tf.math.sigmoid_13[0][0]']     \n","                                                                                                  \n"," depthwise_conv2d_6 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_13[0][0]']            \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_6[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_14 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_20[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_14 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_20[0][0]', \n","                                                                  'tf.math.sigmoid_14[0][0]']     \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 19, 19, 24)   1152        ['multiply_14[0][0]']            \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 19, 19, 24)  96          ['conv2d_14[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_6 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_21[0][0]', \n","                                                                  'add_5[0][0]']                  \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 19, 19, 48)   1152        ['add_6[0][0]']                  \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 19, 19, 48)  192         ['conv2d_15[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_15 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_22[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_15 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_22[0][0]', \n","                                                                  'tf.math.sigmoid_15[0][0]']     \n","                                                                                                  \n"," depthwise_conv2d_7 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_15[0][0]']            \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_7[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_16 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_23[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_16 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_23[0][0]', \n","                                                                  'tf.math.sigmoid_16[0][0]']     \n","                                                                                                  \n"," conv2d_16 (Conv2D)             (None, 19, 19, 24)   1152        ['multiply_16[0][0]']            \n","                                                                                                  \n"," batch_normalization_24 (BatchN  (None, 19, 19, 24)  96          ['conv2d_16[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_7 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_24[0][0]', \n","                                                                  'add_6[0][0]']                  \n","                                                                                                  \n"," conv2d_17 (Conv2D)             (None, 19, 19, 48)   1152        ['add_7[0][0]']                  \n","                                                                                                  \n"," batch_normalization_25 (BatchN  (None, 19, 19, 48)  192         ['conv2d_17[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_17 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_25[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_17 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_25[0][0]', \n","                                                                  'tf.math.sigmoid_17[0][0]']     \n","                                                                                                  \n"," depthwise_conv2d_8 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_17[0][0]']            \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_26 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_8[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_18 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_26[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_18 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_26[0][0]', \n","                                                                  'tf.math.sigmoid_18[0][0]']     \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 19, 19, 24)   1152        ['multiply_18[0][0]']            \n","                                                                                                  \n"," batch_normalization_27 (BatchN  (None, 19, 19, 24)  96          ['conv2d_18[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_8 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_27[0][0]', \n","                                                                  'add_7[0][0]']                  \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 19, 19, 48)   1152        ['add_8[0][0]']                  \n","                                                                                                  \n"," batch_normalization_28 (BatchN  (None, 19, 19, 48)  192         ['conv2d_19[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_19 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_28[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_19 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_28[0][0]', \n","                                                                  'tf.math.sigmoid_19[0][0]']     \n","                                                                                                  \n"," depthwise_conv2d_9 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_19[0][0]']            \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_29 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_9[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_20 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_29[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_20 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_29[0][0]', \n","                                                                  'tf.math.sigmoid_20[0][0]']     \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 19, 19, 24)   1152        ['multiply_20[0][0]']            \n","                                                                                                  \n"," batch_normalization_30 (BatchN  (None, 19, 19, 24)  96          ['conv2d_20[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_9 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_30[0][0]', \n","                                                                  'add_8[0][0]']                  \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 19, 19, 48)   1152        ['add_9[0][0]']                  \n","                                                                                                  \n"," batch_normalization_31 (BatchN  (None, 19, 19, 48)  192         ['conv2d_21[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_21 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_31[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_21 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_31[0][0]', \n","                                                                  'tf.math.sigmoid_21[0][0]']     \n","                                                                                                  \n"," depthwise_conv2d_10 (Depthwise  (None, 19, 19, 48)  432         ['multiply_21[0][0]']            \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_32 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_10[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_22 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_32[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_22 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_32[0][0]', \n","                                                                  'tf.math.sigmoid_22[0][0]']     \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 19, 19, 24)   1152        ['multiply_22[0][0]']            \n","                                                                                                  \n"," batch_normalization_33 (BatchN  (None, 19, 19, 24)  96          ['conv2d_22[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_10 (Add)                   (None, 19, 19, 24)   0           ['batch_normalization_33[0][0]', \n","                                                                  'add_9[0][0]']                  \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 19, 19, 48)   1152        ['add_10[0][0]']                 \n","                                                                                                  \n"," batch_normalization_34 (BatchN  (None, 19, 19, 48)  192         ['conv2d_23[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_23 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_34[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_23 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_34[0][0]', \n","                                                                  'tf.math.sigmoid_23[0][0]']     \n","                                                                                                  \n"," depthwise_conv2d_11 (Depthwise  (None, 19, 19, 48)  432         ['multiply_23[0][0]']            \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_35 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_11[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_24 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_35[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_24 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_35[0][0]', \n","                                                                  'tf.math.sigmoid_24[0][0]']     \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 19, 19, 24)   1152        ['multiply_24[0][0]']            \n","                                                                                                  \n"," batch_normalization_36 (BatchN  (None, 19, 19, 24)  96          ['conv2d_24[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_11 (Add)                   (None, 19, 19, 24)   0           ['batch_normalization_36[0][0]', \n","                                                                  'add_10[0][0]']                 \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 19, 19, 1)    24          ['add_11[0][0]']                 \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 19, 19, 1)    24          ['add_11[0][0]']                 \n","                                                                                                  \n"," flatten_1 (Flatten)            (None, 361)          0           ['conv2d_26[0][0]']              \n","                                                                                                  \n"," flatten (Flatten)              (None, 361)          0           ['conv2d_25[0][0]']              \n","                                                                                                  \n"," dense (Dense)                  (None, 50)           18100       ['flatten_1[0][0]']              \n","                                                                                                  \n"," policy (Activation)            (None, 361)          0           ['flatten[0][0]']                \n","                                                                                                  \n"," value (Dense)                  (None, 1)            51          ['dense[0][0]']                  \n","                                                                                                  \n","==================================================================================================\n","Total params: 57,655\n","Trainable params: 54,727\n","Non-trainable params: 2,928\n","__________________________________________________________________________________________________\n","epoch 1\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2022-12-30 06:58:24.702761: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","2022-12-30 06:58:35.065926: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n","2022-12-30 06:58:40.183505: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x10ea54d00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-12-30 06:58:40.183567: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2022-12-30 06:58:40.249991: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2022-12-30 06:58:40.629608: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","79/79 [==============================] - 29s 56ms/step - loss: 7.6159 - policy_loss: 6.6274 - value_loss: 0.8988 - policy_categorical_accuracy: 0.0197 - value_mse: 0.1664\n","epoch 2\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2022-12-30 06:59:15.583351: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","79/79 [==============================] - 4s 55ms/step - loss: 5.4734 - policy_loss: 4.6835 - value_loss: 0.7004 - policy_categorical_accuracy: 0.0909 - value_mse: 0.1228\n","epoch 3\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2022-12-30 06:59:21.822266: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","79/79 [==============================] - 4s 54ms/step - loss: 4.9228 - policy_loss: 4.1371 - value_loss: 0.6962 - policy_categorical_accuracy: 0.1494 - value_mse: 0.1220\n","epoch 4\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2022-12-30 06:59:28.033059: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","79/79 [==============================] - 4s 54ms/step - loss: 4.6321 - policy_loss: 3.8490 - value_loss: 0.6939 - policy_categorical_accuracy: 0.1906 - value_mse: 0.1211\n","epoch 5\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2022-12-30 06:59:34.174205: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","79/79 [==============================] - 4s 54ms/step - loss: 4.4925 - policy_loss: 3.7101 - value_loss: 0.6934 - policy_categorical_accuracy: 0.2059 - value_mse: 0.1196\n","epoch 6\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 4.3549 - policy_loss: 3.5732 - value_loss: 0.6929 - policy_categorical_accuracy: 0.2303 - value_mse: 0.1179\n","epoch 7\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 4.2866 - policy_loss: 3.5057 - value_loss: 0.6923 - policy_categorical_accuracy: 0.2397 - value_mse: 0.1198\n","epoch 8\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 54ms/step - loss: 4.1632 - policy_loss: 3.3831 - value_loss: 0.6917 - policy_categorical_accuracy: 0.2565 - value_mse: 0.1191\n","epoch 9\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 54ms/step - loss: 4.1144 - policy_loss: 3.3346 - value_loss: 0.6917 - policy_categorical_accuracy: 0.2613 - value_mse: 0.1183\n","epoch 10\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 54ms/step - loss: 4.0562 - policy_loss: 3.2768 - value_loss: 0.6915 - policy_categorical_accuracy: 0.2672 - value_mse: 0.1183\n","epoch 11\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 61ms/step - loss: 3.9881 - policy_loss: 3.2086 - value_loss: 0.6918 - policy_categorical_accuracy: 0.2889 - value_mse: 0.1205\n","epoch 12\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 60ms/step - loss: 3.9417 - policy_loss: 3.1631 - value_loss: 0.6912 - policy_categorical_accuracy: 0.2880 - value_mse: 0.1193\n","epoch 13\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.8801 - policy_loss: 3.1014 - value_loss: 0.6915 - policy_categorical_accuracy: 0.2876 - value_mse: 0.1182\n","epoch 14\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.8826 - policy_loss: 3.1043 - value_loss: 0.6913 - policy_categorical_accuracy: 0.2914 - value_mse: 0.1167\n","epoch 15\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.8792 - policy_loss: 3.1016 - value_loss: 0.6908 - policy_categorical_accuracy: 0.2939 - value_mse: 0.1191\n","epoch 16\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.8285 - policy_loss: 3.0516 - value_loss: 0.6905 - policy_categorical_accuracy: 0.3027 - value_mse: 0.1170\n","epoch 17\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.8302 - policy_loss: 3.0538 - value_loss: 0.6902 - policy_categorical_accuracy: 0.2991 - value_mse: 0.1169\n","epoch 18\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.7879 - policy_loss: 3.0112 - value_loss: 0.6907 - policy_categorical_accuracy: 0.3068 - value_mse: 0.1198\n","epoch 19\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 54ms/step - loss: 3.7707 - policy_loss: 2.9938 - value_loss: 0.6911 - policy_categorical_accuracy: 0.3117 - value_mse: 0.1164\n","epoch 20\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.7356 - policy_loss: 2.9598 - value_loss: 0.6903 - policy_categorical_accuracy: 0.3146 - value_mse: 0.1192\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.6989917755126953, 2.9230189323425293, 0.6906328201293945, 0.32019999623298645, 0.11879055202007294]\n","epoch 21\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.7158 - policy_loss: 2.9405 - value_loss: 0.6901 - policy_categorical_accuracy: 0.3129 - value_mse: 0.1176\n","epoch 22\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.7101 - policy_loss: 2.9348 - value_loss: 0.6904 - policy_categorical_accuracy: 0.3112 - value_mse: 0.1189\n","epoch 23\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.7160 - policy_loss: 2.9409 - value_loss: 0.6903 - policy_categorical_accuracy: 0.3104 - value_mse: 0.1186\n","epoch 24\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.6966 - policy_loss: 2.9227 - value_loss: 0.6895 - policy_categorical_accuracy: 0.3201 - value_mse: 0.1184\n","epoch 25\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.6774 - policy_loss: 2.9026 - value_loss: 0.6906 - policy_categorical_accuracy: 0.3244 - value_mse: 0.1177\n","epoch 26\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.6892 - policy_loss: 2.9155 - value_loss: 0.6898 - policy_categorical_accuracy: 0.3179 - value_mse: 0.1166\n","epoch 27\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.6251 - policy_loss: 2.8517 - value_loss: 0.6897 - policy_categorical_accuracy: 0.3303 - value_mse: 0.1192\n","epoch 28\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.6231 - policy_loss: 2.8500 - value_loss: 0.6897 - policy_categorical_accuracy: 0.3317 - value_mse: 0.1175\n","epoch 29\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.6164 - policy_loss: 2.8434 - value_loss: 0.6899 - policy_categorical_accuracy: 0.3289 - value_mse: 0.1173\n","epoch 30\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.5530 - policy_loss: 2.7816 - value_loss: 0.6886 - policy_categorical_accuracy: 0.3342 - value_mse: 0.1174\n","epoch 31\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.6114 - policy_loss: 2.8407 - value_loss: 0.6881 - policy_categorical_accuracy: 0.3194 - value_mse: 0.1159\n","epoch 32\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.5987 - policy_loss: 2.8269 - value_loss: 0.6895 - policy_categorical_accuracy: 0.3343 - value_mse: 0.1166\n","epoch 33\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.5959 - policy_loss: 2.8250 - value_loss: 0.6888 - policy_categorical_accuracy: 0.3343 - value_mse: 0.1163\n","epoch 34\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.5820 - policy_loss: 2.8114 - value_loss: 0.6889 - policy_categorical_accuracy: 0.3316 - value_mse: 0.1178\n","epoch 35\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.5577 - policy_loss: 2.7870 - value_loss: 0.6892 - policy_categorical_accuracy: 0.3374 - value_mse: 0.1163\n","epoch 36\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.5637 - policy_loss: 2.7947 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3325 - value_mse: 0.1177\n","epoch 37\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.5486 - policy_loss: 2.7794 - value_loss: 0.6881 - policy_categorical_accuracy: 0.3388 - value_mse: 0.1177\n","epoch 38\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.5769 - policy_loss: 2.8073 - value_loss: 0.6888 - policy_categorical_accuracy: 0.3303 - value_mse: 0.1183\n","epoch 39\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.5678 - policy_loss: 2.7982 - value_loss: 0.6891 - policy_categorical_accuracy: 0.3331 - value_mse: 0.1174\n","epoch 40\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.5358 - policy_loss: 2.7660 - value_loss: 0.6894 - policy_categorical_accuracy: 0.3413 - value_mse: 0.1153\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.5024874210357666, 2.733638286590576, 0.688661515712738, 0.3467999994754791, 0.11779201775789261]\n","epoch 41\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.5309 - policy_loss: 2.7621 - value_loss: 0.6888 - policy_categorical_accuracy: 0.3422 - value_mse: 0.1168\n","epoch 42\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.5192 - policy_loss: 2.7505 - value_loss: 0.6888 - policy_categorical_accuracy: 0.3373 - value_mse: 0.1188\n","epoch 43\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.4715 - policy_loss: 2.7033 - value_loss: 0.6886 - policy_categorical_accuracy: 0.3516 - value_mse: 0.1169\n","epoch 44\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.4701 - policy_loss: 2.7026 - value_loss: 0.6881 - policy_categorical_accuracy: 0.3471 - value_mse: 0.1167\n","epoch 45\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.4885 - policy_loss: 2.7216 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3466 - value_mse: 0.1164\n","epoch 46\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.4989 - policy_loss: 2.7321 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3446 - value_mse: 0.1167\n","epoch 47\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 61ms/step - loss: 3.4526 - policy_loss: 2.6861 - value_loss: 0.6878 - policy_categorical_accuracy: 0.3524 - value_mse: 0.1184\n","epoch 48\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 3.4825 - policy_loss: 2.7154 - value_loss: 0.6887 - policy_categorical_accuracy: 0.3444 - value_mse: 0.1187\n","epoch 49\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.4718 - policy_loss: 2.7054 - value_loss: 0.6883 - policy_categorical_accuracy: 0.3394 - value_mse: 0.1183\n","epoch 50\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.4492 - policy_loss: 2.6823 - value_loss: 0.6890 - policy_categorical_accuracy: 0.3555 - value_mse: 0.1185\n","epoch 51\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.4921 - policy_loss: 2.7262 - value_loss: 0.6883 - policy_categorical_accuracy: 0.3396 - value_mse: 0.1190\n","epoch 52\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 54ms/step - loss: 3.4797 - policy_loss: 2.7131 - value_loss: 0.6891 - policy_categorical_accuracy: 0.3409 - value_mse: 0.1156\n","epoch 53\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.4918 - policy_loss: 2.7260 - value_loss: 0.6887 - policy_categorical_accuracy: 0.3348 - value_mse: 0.1171\n","epoch 54\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.4561 - policy_loss: 2.6911 - value_loss: 0.6880 - policy_categorical_accuracy: 0.3447 - value_mse: 0.1165\n","epoch 55\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.4718 - policy_loss: 2.7078 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3514 - value_mse: 0.1167\n","epoch 56\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.4538 - policy_loss: 2.6893 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3542 - value_mse: 0.1176\n","epoch 57\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.4404 - policy_loss: 2.6757 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3515 - value_mse: 0.1191\n","epoch 58\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.4560 - policy_loss: 2.6920 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3518 - value_mse: 0.1174\n","epoch 59\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.4311 - policy_loss: 2.6662 - value_loss: 0.6890 - policy_categorical_accuracy: 0.3563 - value_mse: 0.1180\n","epoch 60\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.4355 - policy_loss: 2.6727 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3535 - value_mse: 0.1169\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.421363353729248, 2.657935857772827, 0.687922477722168, 0.3571999967098236, 0.11744249612092972]\n","epoch 61\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.4360 - policy_loss: 2.6728 - value_loss: 0.6878 - policy_categorical_accuracy: 0.3430 - value_mse: 0.1174\n","epoch 62\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.4368 - policy_loss: 2.6729 - value_loss: 0.6888 - policy_categorical_accuracy: 0.3521 - value_mse: 0.1178\n","epoch 63\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3986 - policy_loss: 2.6365 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3590 - value_mse: 0.1152\n","epoch 64\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.4243 - policy_loss: 2.6613 - value_loss: 0.6881 - policy_categorical_accuracy: 0.3520 - value_mse: 0.1175\n","epoch 65\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.4307 - policy_loss: 2.6676 - value_loss: 0.6885 - policy_categorical_accuracy: 0.3493 - value_mse: 0.1182\n","epoch 66\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.4044 - policy_loss: 2.6437 - value_loss: 0.6863 - policy_categorical_accuracy: 0.3555 - value_mse: 0.1157\n","epoch 67\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.4228 - policy_loss: 2.6619 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3587 - value_mse: 0.1150\n","epoch 68\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.4052 - policy_loss: 2.6430 - value_loss: 0.6881 - policy_categorical_accuracy: 0.3568 - value_mse: 0.1170\n","epoch 69\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.4239 - policy_loss: 2.6623 - value_loss: 0.6878 - policy_categorical_accuracy: 0.3540 - value_mse: 0.1174\n","epoch 70\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.4022 - policy_loss: 2.6415 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3563 - value_mse: 0.1169\n","epoch 71\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.4241 - policy_loss: 2.6631 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3525 - value_mse: 0.1171\n","epoch 72\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3981 - policy_loss: 2.6358 - value_loss: 0.6890 - policy_categorical_accuracy: 0.3573 - value_mse: 0.1176\n","epoch 73\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.4004 - policy_loss: 2.6397 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3576 - value_mse: 0.1151\n","epoch 74\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3678 - policy_loss: 2.6079 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3624 - value_mse: 0.1145\n","epoch 75\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3816 - policy_loss: 2.6213 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3597 - value_mse: 0.1161\n","epoch 76\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3892 - policy_loss: 2.6284 - value_loss: 0.6882 - policy_categorical_accuracy: 0.3661 - value_mse: 0.1155\n","epoch 77\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3992 - policy_loss: 2.6390 - value_loss: 0.6878 - policy_categorical_accuracy: 0.3528 - value_mse: 0.1168\n","epoch 78\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3561 - policy_loss: 2.5951 - value_loss: 0.6888 - policy_categorical_accuracy: 0.3603 - value_mse: 0.1174\n","epoch 79\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.4061 - policy_loss: 2.6473 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3539 - value_mse: 0.1159\n","epoch 80\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3771 - policy_loss: 2.6176 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3596 - value_mse: 0.1173\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.373809814453125, 2.6153862476348877, 0.6866565942764282, 0.35929998755455017, 0.1168164312839508]\n","epoch 81\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3776 - policy_loss: 2.6185 - value_loss: 0.6875 - policy_categorical_accuracy: 0.3567 - value_mse: 0.1158\n","epoch 82\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 58ms/step - loss: 3.4046 - policy_loss: 2.6456 - value_loss: 0.6874 - policy_categorical_accuracy: 0.3565 - value_mse: 0.1156\n","epoch 83\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 3.3815 - policy_loss: 2.6225 - value_loss: 0.6875 - policy_categorical_accuracy: 0.3524 - value_mse: 0.1170\n","epoch 84\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3768 - policy_loss: 2.6171 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3566 - value_mse: 0.1160\n","epoch 85\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3526 - policy_loss: 2.5933 - value_loss: 0.6882 - policy_categorical_accuracy: 0.3605 - value_mse: 0.1162\n","epoch 86\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3505 - policy_loss: 2.5930 - value_loss: 0.6866 - policy_categorical_accuracy: 0.3628 - value_mse: 0.1167\n","epoch 87\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3357 - policy_loss: 2.5782 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3614 - value_mse: 0.1171\n","epoch 88\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3358 - policy_loss: 2.5780 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3599 - value_mse: 0.1179\n","epoch 89\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3888 - policy_loss: 2.6305 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3532 - value_mse: 0.1173\n","epoch 90\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3440 - policy_loss: 2.5872 - value_loss: 0.6863 - policy_categorical_accuracy: 0.3658 - value_mse: 0.1179\n","epoch 91\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3779 - policy_loss: 2.6199 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3554 - value_mse: 0.1175\n","epoch 92\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3723 - policy_loss: 2.6141 - value_loss: 0.6880 - policy_categorical_accuracy: 0.3572 - value_mse: 0.1165\n","epoch 93\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3270 - policy_loss: 2.5689 - value_loss: 0.6880 - policy_categorical_accuracy: 0.3730 - value_mse: 0.1170\n","epoch 94\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3536 - policy_loss: 2.5975 - value_loss: 0.6861 - policy_categorical_accuracy: 0.3554 - value_mse: 0.1171\n","epoch 95\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3499 - policy_loss: 2.5921 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3557 - value_mse: 0.1170\n","epoch 96\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3559 - policy_loss: 2.5993 - value_loss: 0.6869 - policy_categorical_accuracy: 0.3610 - value_mse: 0.1164\n","epoch 97\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3249 - policy_loss: 2.5672 - value_loss: 0.6881 - policy_categorical_accuracy: 0.3598 - value_mse: 0.1174\n","epoch 98\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3522 - policy_loss: 2.5953 - value_loss: 0.6875 - policy_categorical_accuracy: 0.3589 - value_mse: 0.1179\n","epoch 99\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3439 - policy_loss: 2.5874 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3652 - value_mse: 0.1171\n","epoch 100\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3341 - policy_loss: 2.5770 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3668 - value_mse: 0.1173\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.3210487365722656, 2.563343048095703, 0.6885683536529541, 0.3686000108718872, 0.11776634305715561]\n","epoch 101\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3137 - policy_loss: 2.5577 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3650 - value_mse: 0.1165\n","epoch 102\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3341 - policy_loss: 2.5772 - value_loss: 0.6880 - policy_categorical_accuracy: 0.3627 - value_mse: 0.1158\n","epoch 103\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2973 - policy_loss: 2.5401 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3731 - value_mse: 0.1173\n","epoch 104\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3121 - policy_loss: 2.5553 - value_loss: 0.6881 - policy_categorical_accuracy: 0.3634 - value_mse: 0.1168\n","epoch 105\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3317 - policy_loss: 2.5760 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3613 - value_mse: 0.1163\n","epoch 106\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3244 - policy_loss: 2.5688 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3691 - value_mse: 0.1161\n","epoch 107\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3235 - policy_loss: 2.5688 - value_loss: 0.6862 - policy_categorical_accuracy: 0.3632 - value_mse: 0.1180\n","epoch 108\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3152 - policy_loss: 2.5588 - value_loss: 0.6880 - policy_categorical_accuracy: 0.3640 - value_mse: 0.1177\n","epoch 109\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3528 - policy_loss: 2.5968 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3590 - value_mse: 0.1180\n","epoch 110\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2972 - policy_loss: 2.5414 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3696 - value_mse: 0.1168\n","epoch 111\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3219 - policy_loss: 2.5670 - value_loss: 0.6869 - policy_categorical_accuracy: 0.3634 - value_mse: 0.1138\n","epoch 112\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2997 - policy_loss: 2.5431 - value_loss: 0.6887 - policy_categorical_accuracy: 0.3699 - value_mse: 0.1181\n","epoch 113\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3032 - policy_loss: 2.5470 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3649 - value_mse: 0.1181\n","epoch 114\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2982 - policy_loss: 2.5421 - value_loss: 0.6883 - policy_categorical_accuracy: 0.3643 - value_mse: 0.1163\n","epoch 115\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3078 - policy_loss: 2.5529 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3653 - value_mse: 0.1148\n","epoch 116\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2678 - policy_loss: 2.5129 - value_loss: 0.6874 - policy_categorical_accuracy: 0.3759 - value_mse: 0.1179\n","epoch 117\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.3106 - policy_loss: 2.5552 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3709 - value_mse: 0.1182\n","epoch 118\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3223 - policy_loss: 2.5672 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3651 - value_mse: 0.1158\n","epoch 119\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 61ms/step - loss: 3.3044 - policy_loss: 2.5500 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3674 - value_mse: 0.1145\n","epoch 120\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 58ms/step - loss: 3.2802 - policy_loss: 2.5265 - value_loss: 0.6865 - policy_categorical_accuracy: 0.3684 - value_mse: 0.1155\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.267833709716797, 2.513822555541992, 0.6869134902954102, 0.37610000371932983, 0.11694496870040894]\n","epoch 121\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2958 - policy_loss: 2.5411 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3675 - value_mse: 0.1164\n","epoch 122\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2752 - policy_loss: 2.5217 - value_loss: 0.6866 - policy_categorical_accuracy: 0.3710 - value_mse: 0.1154\n","epoch 123\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2853 - policy_loss: 2.5306 - value_loss: 0.6878 - policy_categorical_accuracy: 0.3710 - value_mse: 0.1170\n","epoch 124\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.3048 - policy_loss: 2.5514 - value_loss: 0.6866 - policy_categorical_accuracy: 0.3613 - value_mse: 0.1159\n","epoch 125\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2545 - policy_loss: 2.5007 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3800 - value_mse: 0.1180\n","epoch 126\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2855 - policy_loss: 2.5316 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3721 - value_mse: 0.1176\n","epoch 127\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2422 - policy_loss: 2.4873 - value_loss: 0.6883 - policy_categorical_accuracy: 0.3726 - value_mse: 0.1161\n","epoch 128\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2572 - policy_loss: 2.5046 - value_loss: 0.6862 - policy_categorical_accuracy: 0.3754 - value_mse: 0.1162\n","epoch 129\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2746 - policy_loss: 2.5205 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3750 - value_mse: 0.1168\n","epoch 130\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2556 - policy_loss: 2.5040 - value_loss: 0.6853 - policy_categorical_accuracy: 0.3757 - value_mse: 0.1170\n","epoch 131\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2337 - policy_loss: 2.4802 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3799 - value_mse: 0.1179\n","epoch 132\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2782 - policy_loss: 2.5248 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3756 - value_mse: 0.1172\n","epoch 133\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2754 - policy_loss: 2.5223 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3731 - value_mse: 0.1161\n","epoch 134\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2523 - policy_loss: 2.4997 - value_loss: 0.6866 - policy_categorical_accuracy: 0.3743 - value_mse: 0.1149\n","epoch 135\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2631 - policy_loss: 2.5099 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3712 - value_mse: 0.1160\n","epoch 136\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2607 - policy_loss: 2.5082 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3772 - value_mse: 0.1157\n","epoch 137\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2369 - policy_loss: 2.4832 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3819 - value_mse: 0.1149\n","epoch 138\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2497 - policy_loss: 2.4985 - value_loss: 0.6856 - policy_categorical_accuracy: 0.3727 - value_mse: 0.1153\n","epoch 139\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2418 - policy_loss: 2.4900 - value_loss: 0.6862 - policy_categorical_accuracy: 0.3771 - value_mse: 0.1161\n","epoch 140\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2312 - policy_loss: 2.4788 - value_loss: 0.6869 - policy_categorical_accuracy: 0.3838 - value_mse: 0.1174\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.2594778537750244, 2.5069899559020996, 0.6869551539421082, 0.37549999356269836, 0.11696391552686691]\n","epoch 141\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2686 - policy_loss: 2.5156 - value_loss: 0.6875 - policy_categorical_accuracy: 0.3767 - value_mse: 0.1181\n","epoch 142\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2567 - policy_loss: 2.5032 - value_loss: 0.6880 - policy_categorical_accuracy: 0.3753 - value_mse: 0.1184\n","epoch 143\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2515 - policy_loss: 2.4989 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3700 - value_mse: 0.1167\n","epoch 144\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2514 - policy_loss: 2.4971 - value_loss: 0.6890 - policy_categorical_accuracy: 0.3766 - value_mse: 0.1183\n","epoch 145\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2376 - policy_loss: 2.4860 - value_loss: 0.6864 - policy_categorical_accuracy: 0.3736 - value_mse: 0.1157\n","epoch 146\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2455 - policy_loss: 2.4926 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3766 - value_mse: 0.1181\n","epoch 147\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2437 - policy_loss: 2.4913 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3773 - value_mse: 0.1180\n","epoch 148\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2010 - policy_loss: 2.4489 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3833 - value_mse: 0.1157\n","epoch 149\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2630 - policy_loss: 2.5113 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3694 - value_mse: 0.1167\n","epoch 150\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2848 - policy_loss: 2.5336 - value_loss: 0.6863 - policy_categorical_accuracy: 0.3687 - value_mse: 0.1165\n","epoch 151\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2322 - policy_loss: 2.4800 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3871 - value_mse: 0.1159\n","epoch 152\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2460 - policy_loss: 2.4940 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3765 - value_mse: 0.1166\n","epoch 153\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2191 - policy_loss: 2.4670 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3772 - value_mse: 0.1184\n","epoch 154\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 61ms/step - loss: 3.2303 - policy_loss: 2.4778 - value_loss: 0.6878 - policy_categorical_accuracy: 0.3768 - value_mse: 0.1167\n","epoch 155\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 60ms/step - loss: 3.2338 - policy_loss: 2.4832 - value_loss: 0.6860 - policy_categorical_accuracy: 0.3749 - value_mse: 0.1163\n","epoch 156\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2247 - policy_loss: 2.4729 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3826 - value_mse: 0.1171\n","epoch 157\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2166 - policy_loss: 2.4642 - value_loss: 0.6878 - policy_categorical_accuracy: 0.3833 - value_mse: 0.1164\n","epoch 158\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2266 - policy_loss: 2.4750 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3823 - value_mse: 0.1181\n","epoch 159\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2174 - policy_loss: 2.4649 - value_loss: 0.6881 - policy_categorical_accuracy: 0.3829 - value_mse: 0.1179\n","epoch 160\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2158 - policy_loss: 2.4637 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3846 - value_mse: 0.1159\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.206815242767334, 2.4550812244415283, 0.687400758266449, 0.38350000977516174, 0.11718138307332993]\n","epoch 161\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2233 - policy_loss: 2.4714 - value_loss: 0.6875 - policy_categorical_accuracy: 0.3824 - value_mse: 0.1167\n","epoch 162\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2262 - policy_loss: 2.4747 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3828 - value_mse: 0.1172\n","epoch 163\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1936 - policy_loss: 2.4422 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3894 - value_mse: 0.1185\n","epoch 164\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2457 - policy_loss: 2.4934 - value_loss: 0.6882 - policy_categorical_accuracy: 0.3691 - value_mse: 0.1151\n","epoch 165\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1945 - policy_loss: 2.4427 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3807 - value_mse: 0.1175\n","epoch 166\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1708 - policy_loss: 2.4203 - value_loss: 0.6865 - policy_categorical_accuracy: 0.3919 - value_mse: 0.1164\n","epoch 167\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2176 - policy_loss: 2.4666 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3819 - value_mse: 0.1164\n","epoch 168\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2393 - policy_loss: 2.4882 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3810 - value_mse: 0.1168\n","epoch 169\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1996 - policy_loss: 2.4473 - value_loss: 0.6885 - policy_categorical_accuracy: 0.3883 - value_mse: 0.1168\n","epoch 170\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2216 - policy_loss: 2.4699 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3788 - value_mse: 0.1148\n","epoch 171\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2145 - policy_loss: 2.4644 - value_loss: 0.6863 - policy_categorical_accuracy: 0.3817 - value_mse: 0.1158\n","epoch 172\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1875 - policy_loss: 2.4358 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3839 - value_mse: 0.1178\n","epoch 173\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2231 - policy_loss: 2.4734 - value_loss: 0.6860 - policy_categorical_accuracy: 0.3754 - value_mse: 0.1152\n","epoch 174\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1366 - policy_loss: 2.3867 - value_loss: 0.6863 - policy_categorical_accuracy: 0.3937 - value_mse: 0.1171\n","epoch 175\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2070 - policy_loss: 2.4559 - value_loss: 0.6875 - policy_categorical_accuracy: 0.3856 - value_mse: 0.1184\n","epoch 176\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1990 - policy_loss: 2.4486 - value_loss: 0.6868 - policy_categorical_accuracy: 0.3878 - value_mse: 0.1156\n","epoch 177\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2077 - policy_loss: 2.4582 - value_loss: 0.6860 - policy_categorical_accuracy: 0.3775 - value_mse: 0.1153\n","epoch 178\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2364 - policy_loss: 2.4851 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3762 - value_mse: 0.1161\n","epoch 179\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2335 - policy_loss: 2.4833 - value_loss: 0.6868 - policy_categorical_accuracy: 0.3809 - value_mse: 0.1168\n","epoch 180\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2008 - policy_loss: 2.4500 - value_loss: 0.6874 - policy_categorical_accuracy: 0.3761 - value_mse: 0.1179\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.185953140258789, 2.435666084289551, 0.6869959235191345, 0.38600000739097595, 0.11698517948389053]\n","epoch 181\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1966 - policy_loss: 2.4449 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3807 - value_mse: 0.1169\n","epoch 182\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2226 - policy_loss: 2.4722 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3756 - value_mse: 0.1180\n","epoch 183\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1762 - policy_loss: 2.4251 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3898 - value_mse: 0.1172\n","epoch 184\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1948 - policy_loss: 2.4457 - value_loss: 0.6860 - policy_categorical_accuracy: 0.3834 - value_mse: 0.1160\n","epoch 185\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2086 - policy_loss: 2.4583 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3772 - value_mse: 0.1171\n","epoch 186\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1797 - policy_loss: 2.4311 - value_loss: 0.6856 - policy_categorical_accuracy: 0.3889 - value_mse: 0.1158\n","epoch 187\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2012 - policy_loss: 2.4509 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3729 - value_mse: 0.1173\n","epoch 188\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1582 - policy_loss: 2.4086 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3928 - value_mse: 0.1157\n","epoch 189\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 57ms/step - loss: 3.1917 - policy_loss: 2.4413 - value_loss: 0.6874 - policy_categorical_accuracy: 0.3847 - value_mse: 0.1186\n","epoch 190\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 60ms/step - loss: 3.1648 - policy_loss: 2.4159 - value_loss: 0.6861 - policy_categorical_accuracy: 0.3896 - value_mse: 0.1180\n","epoch 191\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 58ms/step - loss: 3.1965 - policy_loss: 2.4473 - value_loss: 0.6863 - policy_categorical_accuracy: 0.3793 - value_mse: 0.1166\n","epoch 192\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1800 - policy_loss: 2.4290 - value_loss: 0.6881 - policy_categorical_accuracy: 0.3865 - value_mse: 0.1157\n","epoch 193\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1752 - policy_loss: 2.4238 - value_loss: 0.6886 - policy_categorical_accuracy: 0.3873 - value_mse: 0.1173\n","epoch 194\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.2134 - policy_loss: 2.4643 - value_loss: 0.6863 - policy_categorical_accuracy: 0.3770 - value_mse: 0.1168\n","epoch 195\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1812 - policy_loss: 2.4317 - value_loss: 0.6868 - policy_categorical_accuracy: 0.3837 - value_mse: 0.1177\n","epoch 196\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1848 - policy_loss: 2.4341 - value_loss: 0.6880 - policy_categorical_accuracy: 0.3826 - value_mse: 0.1160\n","epoch 197\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1542 - policy_loss: 2.4040 - value_loss: 0.6875 - policy_categorical_accuracy: 0.3856 - value_mse: 0.1157\n","epoch 198\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1865 - policy_loss: 2.4370 - value_loss: 0.6868 - policy_categorical_accuracy: 0.3807 - value_mse: 0.1151\n","epoch 199\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1927 - policy_loss: 2.4434 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3827 - value_mse: 0.1184\n","epoch 200\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.2130 - policy_loss: 2.4629 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3767 - value_mse: 0.1152\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.1664671897888184, 2.414125680923462, 0.6897855997085571, 0.3894999921321869, 0.11835860460996628]\n","epoch 201\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1718 - policy_loss: 2.4216 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3868 - value_mse: 0.1154\n","epoch 202\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1652 - policy_loss: 2.4160 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3909 - value_mse: 0.1168\n","epoch 203\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1735 - policy_loss: 2.4242 - value_loss: 0.6869 - policy_categorical_accuracy: 0.3878 - value_mse: 0.1177\n","epoch 204\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1809 - policy_loss: 2.4308 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3861 - value_mse: 0.1179\n","epoch 205\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1856 - policy_loss: 2.4358 - value_loss: 0.6874 - policy_categorical_accuracy: 0.3814 - value_mse: 0.1147\n","epoch 206\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1771 - policy_loss: 2.4277 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3786 - value_mse: 0.1142\n","epoch 207\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1640 - policy_loss: 2.4143 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3859 - value_mse: 0.1183\n","epoch 208\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1970 - policy_loss: 2.4482 - value_loss: 0.6866 - policy_categorical_accuracy: 0.3848 - value_mse: 0.1146\n","epoch 209\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1557 - policy_loss: 2.4051 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3889 - value_mse: 0.1192\n","epoch 210\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1883 - policy_loss: 2.4386 - value_loss: 0.6874 - policy_categorical_accuracy: 0.3836 - value_mse: 0.1174\n","epoch 211\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1323 - policy_loss: 2.3810 - value_loss: 0.6890 - policy_categorical_accuracy: 0.3903 - value_mse: 0.1182\n","epoch 212\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1678 - policy_loss: 2.4186 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3855 - value_mse: 0.1162\n","epoch 213\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1591 - policy_loss: 2.4090 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3907 - value_mse: 0.1198\n","epoch 214\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1584 - policy_loss: 2.4103 - value_loss: 0.6859 - policy_categorical_accuracy: 0.3883 - value_mse: 0.1151\n","epoch 215\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1768 - policy_loss: 2.4274 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3871 - value_mse: 0.1156\n","epoch 216\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1464 - policy_loss: 2.3959 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3898 - value_mse: 0.1173\n","epoch 217\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1439 - policy_loss: 2.3954 - value_loss: 0.6865 - policy_categorical_accuracy: 0.3904 - value_mse: 0.1159\n","epoch 218\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1728 - policy_loss: 2.4231 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3817 - value_mse: 0.1167\n","epoch 219\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1634 - policy_loss: 2.4131 - value_loss: 0.6883 - policy_categorical_accuracy: 0.3880 - value_mse: 0.1164\n","epoch 220\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1290 - policy_loss: 2.3811 - value_loss: 0.6859 - policy_categorical_accuracy: 0.3895 - value_mse: 0.1170\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.1752753257751465, 2.4264907836914062, 0.6868584752082825, 0.38929998874664307, 0.11690026521682739]\n","epoch 221\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1748 - policy_loss: 2.4251 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3877 - value_mse: 0.1166\n","epoch 222\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1503 - policy_loss: 2.4022 - value_loss: 0.6862 - policy_categorical_accuracy: 0.3930 - value_mse: 0.1148\n","epoch 223\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1959 - policy_loss: 2.4458 - value_loss: 0.6883 - policy_categorical_accuracy: 0.3790 - value_mse: 0.1178\n","epoch 224\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1215 - policy_loss: 2.3742 - value_loss: 0.6855 - policy_categorical_accuracy: 0.3895 - value_mse: 0.1166\n","epoch 225\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1292 - policy_loss: 2.3808 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3967 - value_mse: 0.1158\n","epoch 226\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 58ms/step - loss: 3.1242 - policy_loss: 2.3742 - value_loss: 0.6882 - policy_categorical_accuracy: 0.3956 - value_mse: 0.1181\n","epoch 227\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 61ms/step - loss: 3.1714 - policy_loss: 2.4221 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3824 - value_mse: 0.1177\n","epoch 228\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 58ms/step - loss: 3.1783 - policy_loss: 2.4295 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3819 - value_mse: 0.1163\n","epoch 229\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1615 - policy_loss: 2.4128 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3867 - value_mse: 0.1161\n","epoch 230\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1311 - policy_loss: 2.3830 - value_loss: 0.6864 - policy_categorical_accuracy: 0.3921 - value_mse: 0.1152\n","epoch 231\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1525 - policy_loss: 2.4034 - value_loss: 0.6875 - policy_categorical_accuracy: 0.3929 - value_mse: 0.1148\n","epoch 232\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1686 - policy_loss: 2.4198 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3848 - value_mse: 0.1164\n","epoch 233\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 57ms/step - loss: 3.1982 - policy_loss: 2.4487 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3855 - value_mse: 0.1165\n","epoch 234\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 57ms/step - loss: 3.1564 - policy_loss: 2.4080 - value_loss: 0.6868 - policy_categorical_accuracy: 0.3879 - value_mse: 0.1150\n","epoch 235\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1020 - policy_loss: 2.3527 - value_loss: 0.6878 - policy_categorical_accuracy: 0.3936 - value_mse: 0.1148\n","epoch 236\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1456 - policy_loss: 2.3973 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3910 - value_mse: 0.1163\n","epoch 237\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1694 - policy_loss: 2.4205 - value_loss: 0.6874 - policy_categorical_accuracy: 0.3904 - value_mse: 0.1164\n","epoch 238\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1395 - policy_loss: 2.3895 - value_loss: 0.6885 - policy_categorical_accuracy: 0.3923 - value_mse: 0.1166\n","epoch 239\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1510 - policy_loss: 2.4021 - value_loss: 0.6875 - policy_categorical_accuracy: 0.3915 - value_mse: 0.1169\n","epoch 240\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1470 - policy_loss: 2.3990 - value_loss: 0.6865 - policy_categorical_accuracy: 0.3866 - value_mse: 0.1166\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.125981330871582, 2.377729892730713, 0.6868316531181335, 0.39820000529289246, 0.1169017106294632]\n","epoch 241\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1370 - policy_loss: 2.3900 - value_loss: 0.6856 - policy_categorical_accuracy: 0.3892 - value_mse: 0.1147\n","epoch 242\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 57ms/step - loss: 3.1538 - policy_loss: 2.4046 - value_loss: 0.6878 - policy_categorical_accuracy: 0.3814 - value_mse: 0.1171\n","epoch 243\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1485 - policy_loss: 2.4007 - value_loss: 0.6863 - policy_categorical_accuracy: 0.3895 - value_mse: 0.1165\n","epoch 244\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1531 - policy_loss: 2.4045 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3876 - value_mse: 0.1167\n","epoch 245\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1619 - policy_loss: 2.4138 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3844 - value_mse: 0.1162\n","epoch 246\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1614 - policy_loss: 2.4128 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3890 - value_mse: 0.1151\n","epoch 247\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1573 - policy_loss: 2.4087 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3881 - value_mse: 0.1167\n","epoch 248\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0953 - policy_loss: 2.3458 - value_loss: 0.6882 - policy_categorical_accuracy: 0.3988 - value_mse: 0.1167\n","epoch 249\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1204 - policy_loss: 2.3719 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3932 - value_mse: 0.1162\n","epoch 250\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1258 - policy_loss: 2.3791 - value_loss: 0.6854 - policy_categorical_accuracy: 0.3893 - value_mse: 0.1167\n","epoch 251\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1299 - policy_loss: 2.3821 - value_loss: 0.6865 - policy_categorical_accuracy: 0.3926 - value_mse: 0.1151\n","epoch 252\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1251 - policy_loss: 2.3768 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3941 - value_mse: 0.1158\n","epoch 253\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1200 - policy_loss: 2.3730 - value_loss: 0.6858 - policy_categorical_accuracy: 0.3957 - value_mse: 0.1179\n","epoch 254\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1420 - policy_loss: 2.3932 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3820 - value_mse: 0.1172\n","epoch 255\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1393 - policy_loss: 2.3912 - value_loss: 0.6869 - policy_categorical_accuracy: 0.3835 - value_mse: 0.1177\n","epoch 256\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1187 - policy_loss: 2.3700 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3880 - value_mse: 0.1160\n","epoch 257\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1285 - policy_loss: 2.3807 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3926 - value_mse: 0.1175\n","epoch 258\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1326 - policy_loss: 2.3841 - value_loss: 0.6874 - policy_categorical_accuracy: 0.3848 - value_mse: 0.1149\n","epoch 259\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1480 - policy_loss: 2.4005 - value_loss: 0.6864 - policy_categorical_accuracy: 0.3942 - value_mse: 0.1150\n","epoch 260\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1770 - policy_loss: 2.4290 - value_loss: 0.6869 - policy_categorical_accuracy: 0.3802 - value_mse: 0.1171\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.124967575073242, 2.374774694442749, 0.6891151070594788, 0.3952000141143799, 0.11801279336214066]\n","epoch 261\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 57ms/step - loss: 3.1180 - policy_loss: 2.3692 - value_loss: 0.6878 - policy_categorical_accuracy: 0.3946 - value_mse: 0.1182\n","epoch 262\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 60ms/step - loss: 3.1073 - policy_loss: 2.3600 - value_loss: 0.6863 - policy_categorical_accuracy: 0.3889 - value_mse: 0.1154\n","epoch 263\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 60ms/step - loss: 3.1338 - policy_loss: 2.3847 - value_loss: 0.6881 - policy_categorical_accuracy: 0.3898 - value_mse: 0.1171\n","epoch 264\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 57ms/step - loss: 3.1083 - policy_loss: 2.3600 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3949 - value_mse: 0.1156\n","epoch 265\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1250 - policy_loss: 2.3753 - value_loss: 0.6888 - policy_categorical_accuracy: 0.3912 - value_mse: 0.1176\n","epoch 266\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1088 - policy_loss: 2.3613 - value_loss: 0.6865 - policy_categorical_accuracy: 0.3920 - value_mse: 0.1156\n","epoch 267\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0824 - policy_loss: 2.3348 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4056 - value_mse: 0.1171\n","epoch 268\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0959 - policy_loss: 2.3482 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4057 - value_mse: 0.1152\n","epoch 269\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1212 - policy_loss: 2.3727 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3918 - value_mse: 0.1153\n","epoch 270\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1230 - policy_loss: 2.3737 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3953 - value_mse: 0.1154\n","epoch 271\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1096 - policy_loss: 2.3617 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3938 - value_mse: 0.1165\n","epoch 272\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0900 - policy_loss: 2.3426 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4016 - value_mse: 0.1156\n","epoch 273\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1372 - policy_loss: 2.3894 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3849 - value_mse: 0.1164\n","epoch 274\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1157 - policy_loss: 2.3685 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4011 - value_mse: 0.1166\n","epoch 275\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1250 - policy_loss: 2.3767 - value_loss: 0.6875 - policy_categorical_accuracy: 0.3927 - value_mse: 0.1175\n","epoch 276\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1042 - policy_loss: 2.3554 - value_loss: 0.6880 - policy_categorical_accuracy: 0.3942 - value_mse: 0.1174\n","epoch 277\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1210 - policy_loss: 2.3730 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3917 - value_mse: 0.1159\n","epoch 278\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1338 - policy_loss: 2.3860 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3914 - value_mse: 0.1148\n","epoch 279\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 57ms/step - loss: 3.1220 - policy_loss: 2.3754 - value_loss: 0.6859 - policy_categorical_accuracy: 0.3940 - value_mse: 0.1151\n","epoch 280\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0865 - policy_loss: 2.3387 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3961 - value_mse: 0.1168\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.1218361854553223, 2.373669385910034, 0.687493622303009, 0.40400001406669617, 0.11722895503044128]\n","epoch 281\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0791 - policy_loss: 2.3309 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3976 - value_mse: 0.1171\n","epoch 282\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1236 - policy_loss: 2.3754 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4008 - value_mse: 0.1168\n","epoch 283\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1263 - policy_loss: 2.3790 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3898 - value_mse: 0.1155\n","epoch 284\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1304 - policy_loss: 2.3825 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3916 - value_mse: 0.1153\n","epoch 285\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1369 - policy_loss: 2.3892 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3871 - value_mse: 0.1175\n","epoch 286\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0686 - policy_loss: 2.3214 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4022 - value_mse: 0.1156\n","epoch 287\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0904 - policy_loss: 2.3420 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3971 - value_mse: 0.1161\n","epoch 288\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0991 - policy_loss: 2.3522 - value_loss: 0.6863 - policy_categorical_accuracy: 0.3958 - value_mse: 0.1157\n","epoch 289\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1013 - policy_loss: 2.3542 - value_loss: 0.6866 - policy_categorical_accuracy: 0.3974 - value_mse: 0.1140\n","epoch 290\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1181 - policy_loss: 2.3703 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3928 - value_mse: 0.1171\n","epoch 291\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1169 - policy_loss: 2.3688 - value_loss: 0.6875 - policy_categorical_accuracy: 0.3981 - value_mse: 0.1163\n","epoch 292\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1359 - policy_loss: 2.3870 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3908 - value_mse: 0.1173\n","epoch 293\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1017 - policy_loss: 2.3559 - value_loss: 0.6853 - policy_categorical_accuracy: 0.3920 - value_mse: 0.1167\n","epoch 294\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1236 - policy_loss: 2.3748 - value_loss: 0.6882 - policy_categorical_accuracy: 0.3953 - value_mse: 0.1148\n","epoch 295\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0829 - policy_loss: 2.3348 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4003 - value_mse: 0.1163\n","epoch 296\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1237 - policy_loss: 2.3767 - value_loss: 0.6864 - policy_categorical_accuracy: 0.3943 - value_mse: 0.1162\n","epoch 297\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1130 - policy_loss: 2.3661 - value_loss: 0.6863 - policy_categorical_accuracy: 0.3969 - value_mse: 0.1156\n","epoch 298\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1003 - policy_loss: 2.3530 - value_loss: 0.6868 - policy_categorical_accuracy: 0.3913 - value_mse: 0.1182\n","epoch 299\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 57ms/step - loss: 3.0918 - policy_loss: 2.3436 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3969 - value_mse: 0.1167\n","epoch 300\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 60ms/step - loss: 3.1204 - policy_loss: 2.3738 - value_loss: 0.6861 - policy_categorical_accuracy: 0.3889 - value_mse: 0.1164\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.1192469596862793, 2.371053695678711, 0.6876688003540039, 0.40119999647140503, 0.11731914430856705]\n","epoch 301\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1096 - policy_loss: 2.3626 - value_loss: 0.6865 - policy_categorical_accuracy: 0.3911 - value_mse: 0.1162\n","epoch 302\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0900 - policy_loss: 2.3424 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4038 - value_mse: 0.1169\n","epoch 303\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1124 - policy_loss: 2.3667 - value_loss: 0.6852 - policy_categorical_accuracy: 0.3971 - value_mse: 0.1154\n","epoch 304\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1002 - policy_loss: 2.3528 - value_loss: 0.6869 - policy_categorical_accuracy: 0.3938 - value_mse: 0.1163\n","epoch 305\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1078 - policy_loss: 2.3611 - value_loss: 0.6863 - policy_categorical_accuracy: 0.3891 - value_mse: 0.1157\n","epoch 306\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0756 - policy_loss: 2.3284 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4004 - value_mse: 0.1152\n","epoch 307\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1015 - policy_loss: 2.3556 - value_loss: 0.6854 - policy_categorical_accuracy: 0.3933 - value_mse: 0.1179\n","epoch 308\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1204 - policy_loss: 2.3723 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3914 - value_mse: 0.1170\n","epoch 309\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1253 - policy_loss: 2.3772 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3868 - value_mse: 0.1181\n","epoch 310\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0796 - policy_loss: 2.3321 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3976 - value_mse: 0.1156\n","epoch 311\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0847 - policy_loss: 2.3378 - value_loss: 0.6865 - policy_categorical_accuracy: 0.3946 - value_mse: 0.1151\n","epoch 312\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0770 - policy_loss: 2.3301 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4036 - value_mse: 0.1165\n","epoch 313\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0948 - policy_loss: 2.3487 - value_loss: 0.6858 - policy_categorical_accuracy: 0.3900 - value_mse: 0.1174\n","epoch 314\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1205 - policy_loss: 2.3739 - value_loss: 0.6862 - policy_categorical_accuracy: 0.3949 - value_mse: 0.1165\n","epoch 315\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0859 - policy_loss: 2.3388 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4014 - value_mse: 0.1170\n","epoch 316\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1156 - policy_loss: 2.3682 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3884 - value_mse: 0.1146\n","epoch 317\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0874 - policy_loss: 2.3410 - value_loss: 0.6860 - policy_categorical_accuracy: 0.3992 - value_mse: 0.1161\n","epoch 318\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1190 - policy_loss: 2.3709 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3933 - value_mse: 0.1174\n","epoch 319\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.1144 - policy_loss: 2.3663 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3973 - value_mse: 0.1172\n","epoch 320\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0779 - policy_loss: 2.3301 - value_loss: 0.6874 - policy_categorical_accuracy: 0.3989 - value_mse: 0.1157\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.0896148681640625, 2.3421103954315186, 0.6871410012245178, 0.4018000066280365, 0.11705609411001205]\n","epoch 321\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0726 - policy_loss: 2.3248 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4014 - value_mse: 0.1154\n","epoch 322\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0924 - policy_loss: 2.3443 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3945 - value_mse: 0.1154\n","epoch 323\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1130 - policy_loss: 2.3668 - value_loss: 0.6858 - policy_categorical_accuracy: 0.3928 - value_mse: 0.1146\n","epoch 324\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0725 - policy_loss: 2.3248 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3973 - value_mse: 0.1171\n","epoch 325\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0885 - policy_loss: 2.3426 - value_loss: 0.6855 - policy_categorical_accuracy: 0.3936 - value_mse: 0.1146\n","epoch 326\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1008 - policy_loss: 2.3535 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3919 - value_mse: 0.1159\n","epoch 327\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0865 - policy_loss: 2.3387 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4027 - value_mse: 0.1177\n","epoch 328\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0837 - policy_loss: 2.3355 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4009 - value_mse: 0.1163\n","epoch 329\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1223 - policy_loss: 2.3732 - value_loss: 0.6888 - policy_categorical_accuracy: 0.3882 - value_mse: 0.1168\n","epoch 330\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1154 - policy_loss: 2.3671 - value_loss: 0.6880 - policy_categorical_accuracy: 0.3875 - value_mse: 0.1147\n","epoch 331\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1062 - policy_loss: 2.3591 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3906 - value_mse: 0.1155\n","epoch 332\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0803 - policy_loss: 2.3338 - value_loss: 0.6862 - policy_categorical_accuracy: 0.3973 - value_mse: 0.1152\n","epoch 333\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0839 - policy_loss: 2.3365 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3980 - value_mse: 0.1170\n","epoch 334\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1062 - policy_loss: 2.3584 - value_loss: 0.6874 - policy_categorical_accuracy: 0.3934 - value_mse: 0.1159\n","epoch 335\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 57ms/step - loss: 3.0845 - policy_loss: 2.3377 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4003 - value_mse: 0.1170\n","epoch 336\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 3.0822 - policy_loss: 2.3341 - value_loss: 0.6879 - policy_categorical_accuracy: 0.4004 - value_mse: 0.1198\n","epoch 337\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 57ms/step - loss: 3.0765 - policy_loss: 2.3282 - value_loss: 0.6880 - policy_categorical_accuracy: 0.3949 - value_mse: 0.1192\n","epoch 338\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0761 - policy_loss: 2.3293 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4059 - value_mse: 0.1175\n","epoch 339\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0909 - policy_loss: 2.3427 - value_loss: 0.6879 - policy_categorical_accuracy: 0.4019 - value_mse: 0.1156\n","epoch 340\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0944 - policy_loss: 2.3468 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4014 - value_mse: 0.1157\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.071254014968872, 2.323531150817871, 0.6874151229858398, 0.39910000562667847, 0.1171889528632164]\n","epoch 341\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0545 - policy_loss: 2.3068 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4073 - value_mse: 0.1159\n","epoch 342\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1073 - policy_loss: 2.3591 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3973 - value_mse: 0.1181\n","epoch 343\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0779 - policy_loss: 2.3307 - value_loss: 0.6869 - policy_categorical_accuracy: 0.3967 - value_mse: 0.1146\n","epoch 344\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0975 - policy_loss: 2.3503 - value_loss: 0.6869 - policy_categorical_accuracy: 0.3977 - value_mse: 0.1155\n","epoch 345\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0714 - policy_loss: 2.3236 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4035 - value_mse: 0.1159\n","epoch 346\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0677 - policy_loss: 2.3211 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4025 - value_mse: 0.1161\n","epoch 347\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0695 - policy_loss: 2.3229 - value_loss: 0.6864 - policy_categorical_accuracy: 0.3993 - value_mse: 0.1163\n","epoch 348\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0587 - policy_loss: 2.3128 - value_loss: 0.6857 - policy_categorical_accuracy: 0.4000 - value_mse: 0.1161\n","epoch 349\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0662 - policy_loss: 2.3203 - value_loss: 0.6856 - policy_categorical_accuracy: 0.4078 - value_mse: 0.1164\n","epoch 350\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0871 - policy_loss: 2.3405 - value_loss: 0.6863 - policy_categorical_accuracy: 0.3931 - value_mse: 0.1163\n","epoch 351\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0727 - policy_loss: 2.3271 - value_loss: 0.6852 - policy_categorical_accuracy: 0.3996 - value_mse: 0.1151\n","epoch 352\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0468 - policy_loss: 2.2988 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4067 - value_mse: 0.1176\n","epoch 353\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0707 - policy_loss: 2.3246 - value_loss: 0.6858 - policy_categorical_accuracy: 0.4059 - value_mse: 0.1144\n","epoch 354\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.1174 - policy_loss: 2.3704 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3860 - value_mse: 0.1156\n","epoch 355\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0724 - policy_loss: 2.3260 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4052 - value_mse: 0.1158\n","epoch 356\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0718 - policy_loss: 2.3253 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4004 - value_mse: 0.1160\n","epoch 357\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0934 - policy_loss: 2.3452 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3926 - value_mse: 0.1179\n","epoch 358\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0696 - policy_loss: 2.3225 - value_loss: 0.6868 - policy_categorical_accuracy: 0.3988 - value_mse: 0.1180\n","epoch 359\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0617 - policy_loss: 2.3145 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3972 - value_mse: 0.1174\n","epoch 360\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0871 - policy_loss: 2.3406 - value_loss: 0.6862 - policy_categorical_accuracy: 0.3918 - value_mse: 0.1163\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.047577142715454, 2.2996416091918945, 0.6876541376113892, 0.4027999937534332, 0.1172969713807106]\n","epoch 361\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0689 - policy_loss: 2.3230 - value_loss: 0.6857 - policy_categorical_accuracy: 0.3995 - value_mse: 0.1153\n","epoch 362\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0822 - policy_loss: 2.3350 - value_loss: 0.6869 - policy_categorical_accuracy: 0.3983 - value_mse: 0.1173\n","epoch 363\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0843 - policy_loss: 2.3370 - value_loss: 0.6869 - policy_categorical_accuracy: 0.3981 - value_mse: 0.1161\n","epoch 364\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0614 - policy_loss: 2.3146 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4000 - value_mse: 0.1160\n","epoch 365\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0944 - policy_loss: 2.3475 - value_loss: 0.6866 - policy_categorical_accuracy: 0.3934 - value_mse: 0.1183\n","epoch 366\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0936 - policy_loss: 2.3439 - value_loss: 0.6894 - policy_categorical_accuracy: 0.4003 - value_mse: 0.1184\n","epoch 367\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0937 - policy_loss: 2.3459 - value_loss: 0.6874 - policy_categorical_accuracy: 0.3900 - value_mse: 0.1154\n","epoch 368\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0666 - policy_loss: 2.3179 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3980 - value_mse: 0.1171\n","epoch 369\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0730 - policy_loss: 2.3255 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4016 - value_mse: 0.1179\n","epoch 370\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0749 - policy_loss: 2.3277 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4058 - value_mse: 0.1185\n","epoch 371\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 57ms/step - loss: 3.0763 - policy_loss: 2.3291 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4044 - value_mse: 0.1168\n","epoch 372\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 60ms/step - loss: 3.0737 - policy_loss: 2.3265 - value_loss: 0.6869 - policy_categorical_accuracy: 0.3975 - value_mse: 0.1167\n","epoch 373\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 3.0909 - policy_loss: 2.3433 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4059 - value_mse: 0.1161\n","epoch 374\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0433 - policy_loss: 2.2959 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4061 - value_mse: 0.1183\n","epoch 375\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0381 - policy_loss: 2.2908 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4081 - value_mse: 0.1168\n","epoch 376\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0652 - policy_loss: 2.3198 - value_loss: 0.6851 - policy_categorical_accuracy: 0.3992 - value_mse: 0.1154\n","epoch 377\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0812 - policy_loss: 2.3349 - value_loss: 0.6859 - policy_categorical_accuracy: 0.3988 - value_mse: 0.1146\n","epoch 378\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0727 - policy_loss: 2.3248 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4024 - value_mse: 0.1180\n","epoch 379\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0868 - policy_loss: 2.3400 - value_loss: 0.6864 - policy_categorical_accuracy: 0.3929 - value_mse: 0.1159\n","epoch 380\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0492 - policy_loss: 2.3020 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4053 - value_mse: 0.1172\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.0715649127960205, 2.3241896629333496, 0.6870594024658203, 0.40119999647140503, 0.11700831353664398]\n","epoch 381\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0637 - policy_loss: 2.3169 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4062 - value_mse: 0.1169\n","epoch 382\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0755 - policy_loss: 2.3268 - value_loss: 0.6885 - policy_categorical_accuracy: 0.3976 - value_mse: 0.1186\n","epoch 383\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0711 - policy_loss: 2.3241 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4000 - value_mse: 0.1179\n","epoch 384\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0486 - policy_loss: 2.3014 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4019 - value_mse: 0.1167\n","epoch 385\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0712 - policy_loss: 2.3226 - value_loss: 0.6883 - policy_categorical_accuracy: 0.3948 - value_mse: 0.1166\n","epoch 386\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0714 - policy_loss: 2.3237 - value_loss: 0.6875 - policy_categorical_accuracy: 0.3970 - value_mse: 0.1174\n","epoch 387\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0773 - policy_loss: 2.3290 - value_loss: 0.6880 - policy_categorical_accuracy: 0.3983 - value_mse: 0.1155\n","epoch 388\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0346 - policy_loss: 2.2869 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4085 - value_mse: 0.1149\n","epoch 389\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0803 - policy_loss: 2.3333 - value_loss: 0.6868 - policy_categorical_accuracy: 0.3934 - value_mse: 0.1148\n","epoch 390\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0712 - policy_loss: 2.3236 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3969 - value_mse: 0.1144\n","epoch 391\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0644 - policy_loss: 2.3174 - value_loss: 0.6867 - policy_categorical_accuracy: 0.3997 - value_mse: 0.1177\n","epoch 392\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0794 - policy_loss: 2.3325 - value_loss: 0.6866 - policy_categorical_accuracy: 0.3978 - value_mse: 0.1176\n","epoch 393\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0564 - policy_loss: 2.3078 - value_loss: 0.6882 - policy_categorical_accuracy: 0.4102 - value_mse: 0.1180\n","epoch 394\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0729 - policy_loss: 2.3255 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4134 - value_mse: 0.1166\n","epoch 395\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0713 - policy_loss: 2.3249 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4011 - value_mse: 0.1160\n","epoch 396\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0303 - policy_loss: 2.2842 - value_loss: 0.6857 - policy_categorical_accuracy: 0.4112 - value_mse: 0.1152\n","epoch 397\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0613 - policy_loss: 2.3142 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4127 - value_mse: 0.1166\n","epoch 398\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0478 - policy_loss: 2.3001 - value_loss: 0.6874 - policy_categorical_accuracy: 0.3929 - value_mse: 0.1154\n","epoch 399\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0517 - policy_loss: 2.3046 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4038 - value_mse: 0.1173\n","epoch 400\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0471 - policy_loss: 2.2997 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4078 - value_mse: 0.1162\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.0650477409362793, 2.3171305656433105, 0.6875452399253845, 0.4097999930381775, 0.11725838482379913]\n","epoch 401\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0390 - policy_loss: 2.2924 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4092 - value_mse: 0.1145\n","epoch 402\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0635 - policy_loss: 2.3162 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4002 - value_mse: 0.1130\n","epoch 403\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0552 - policy_loss: 2.3073 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4049 - value_mse: 0.1150\n","epoch 404\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0693 - policy_loss: 2.3224 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4018 - value_mse: 0.1157\n","epoch 405\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0658 - policy_loss: 2.3192 - value_loss: 0.6862 - policy_categorical_accuracy: 0.3916 - value_mse: 0.1152\n","epoch 406\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 58ms/step - loss: 3.0535 - policy_loss: 2.3072 - value_loss: 0.6859 - policy_categorical_accuracy: 0.4078 - value_mse: 0.1158\n","epoch 407\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 60ms/step - loss: 3.0562 - policy_loss: 2.3088 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4023 - value_mse: 0.1158\n","epoch 408\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 58ms/step - loss: 3.0692 - policy_loss: 2.3226 - value_loss: 0.6861 - policy_categorical_accuracy: 0.3925 - value_mse: 0.1165\n","epoch 409\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0817 - policy_loss: 2.3326 - value_loss: 0.6886 - policy_categorical_accuracy: 0.3973 - value_mse: 0.1165\n","epoch 410\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0392 - policy_loss: 2.2929 - value_loss: 0.6859 - policy_categorical_accuracy: 0.4052 - value_mse: 0.1161\n","epoch 411\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0421 - policy_loss: 2.2948 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4087 - value_mse: 0.1162\n","epoch 412\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0770 - policy_loss: 2.3306 - value_loss: 0.6860 - policy_categorical_accuracy: 0.4026 - value_mse: 0.1160\n","epoch 413\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0663 - policy_loss: 2.3190 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4021 - value_mse: 0.1177\n","epoch 414\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0641 - policy_loss: 2.3165 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3972 - value_mse: 0.1156\n","epoch 415\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0330 - policy_loss: 2.2850 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4093 - value_mse: 0.1176\n","epoch 416\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0689 - policy_loss: 2.3208 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4028 - value_mse: 0.1166\n","epoch 417\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0239 - policy_loss: 2.2771 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4060 - value_mse: 0.1175\n","epoch 418\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0168 - policy_loss: 2.2689 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4117 - value_mse: 0.1164\n","epoch 419\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0586 - policy_loss: 2.3110 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4011 - value_mse: 0.1137\n","epoch 420\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0729 - policy_loss: 2.3251 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4025 - value_mse: 0.1164\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.0386385917663574, 2.2908618450164795, 0.687293529510498, 0.41190001368522644, 0.11713455617427826]\n","epoch 421\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0473 - policy_loss: 2.2993 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4089 - value_mse: 0.1173\n","epoch 422\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0508 - policy_loss: 2.3040 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4002 - value_mse: 0.1160\n","epoch 423\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0696 - policy_loss: 2.3224 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4026 - value_mse: 0.1167\n","epoch 424\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0557 - policy_loss: 2.3088 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4001 - value_mse: 0.1180\n","epoch 425\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0960 - policy_loss: 2.3486 - value_loss: 0.6869 - policy_categorical_accuracy: 0.3969 - value_mse: 0.1165\n","epoch 426\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0839 - policy_loss: 2.3368 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4022 - value_mse: 0.1156\n","epoch 427\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0663 - policy_loss: 2.3187 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4037 - value_mse: 0.1162\n","epoch 428\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0476 - policy_loss: 2.3001 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4067 - value_mse: 0.1162\n","epoch 429\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0519 - policy_loss: 2.3042 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4074 - value_mse: 0.1150\n","epoch 430\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0402 - policy_loss: 2.2917 - value_loss: 0.6880 - policy_categorical_accuracy: 0.3999 - value_mse: 0.1179\n","epoch 431\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0231 - policy_loss: 2.2759 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4089 - value_mse: 0.1151\n","epoch 432\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0391 - policy_loss: 2.2918 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4057 - value_mse: 0.1166\n","epoch 433\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0324 - policy_loss: 2.2847 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4047 - value_mse: 0.1165\n","epoch 434\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0356 - policy_loss: 2.2882 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4085 - value_mse: 0.1166\n","epoch 435\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0367 - policy_loss: 2.2886 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4047 - value_mse: 0.1164\n","epoch 436\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0340 - policy_loss: 2.2856 - value_loss: 0.6880 - policy_categorical_accuracy: 0.4042 - value_mse: 0.1176\n","epoch 437\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0375 - policy_loss: 2.2906 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4076 - value_mse: 0.1154\n","epoch 438\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0622 - policy_loss: 2.3155 - value_loss: 0.6862 - policy_categorical_accuracy: 0.3903 - value_mse: 0.1165\n","epoch 439\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0482 - policy_loss: 2.3003 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4022 - value_mse: 0.1139\n","epoch 440\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0492 - policy_loss: 2.3023 - value_loss: 0.6865 - policy_categorical_accuracy: 0.3989 - value_mse: 0.1160\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.026608467102051, 2.277252197265625, 0.6889104843139648, 0.41429999470710754, 0.11793701350688934]\n","epoch 441\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 3.0101 - policy_loss: 2.2624 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4105 - value_mse: 0.1184\n","epoch 442\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 57ms/step - loss: 3.0349 - policy_loss: 2.2874 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4054 - value_mse: 0.1165\n","epoch 443\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0538 - policy_loss: 2.3067 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4014 - value_mse: 0.1146\n","epoch 444\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0365 - policy_loss: 2.2903 - value_loss: 0.6857 - policy_categorical_accuracy: 0.4076 - value_mse: 0.1156\n","epoch 445\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0225 - policy_loss: 2.2762 - value_loss: 0.6859 - policy_categorical_accuracy: 0.4111 - value_mse: 0.1162\n","epoch 446\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0364 - policy_loss: 2.2896 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4049 - value_mse: 0.1143\n","epoch 447\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0646 - policy_loss: 2.3159 - value_loss: 0.6881 - policy_categorical_accuracy: 0.3956 - value_mse: 0.1177\n","epoch 448\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0120 - policy_loss: 2.2653 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4127 - value_mse: 0.1160\n","epoch 449\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0358 - policy_loss: 2.2891 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4094 - value_mse: 0.1159\n","epoch 450\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0573 - policy_loss: 2.3098 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4055 - value_mse: 0.1160\n","epoch 451\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0411 - policy_loss: 2.2935 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4031 - value_mse: 0.1171\n","epoch 452\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0346 - policy_loss: 2.2867 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4017 - value_mse: 0.1162\n","epoch 453\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0359 - policy_loss: 2.2878 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4065 - value_mse: 0.1146\n","epoch 454\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0310 - policy_loss: 2.2842 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4079 - value_mse: 0.1147\n","epoch 455\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0545 - policy_loss: 2.3074 - value_loss: 0.6866 - policy_categorical_accuracy: 0.3932 - value_mse: 0.1155\n","epoch 456\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0147 - policy_loss: 2.2682 - value_loss: 0.6858 - policy_categorical_accuracy: 0.4097 - value_mse: 0.1155\n","epoch 457\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0629 - policy_loss: 2.3169 - value_loss: 0.6853 - policy_categorical_accuracy: 0.4021 - value_mse: 0.1149\n","epoch 458\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0546 - policy_loss: 2.3084 - value_loss: 0.6856 - policy_categorical_accuracy: 0.4023 - value_mse: 0.1159\n","epoch 459\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0461 - policy_loss: 2.2986 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4049 - value_mse: 0.1157\n","epoch 460\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0182 - policy_loss: 2.2705 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4124 - value_mse: 0.1151\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.009394645690918, 2.2619407176971436, 0.6868211627006531, 0.4146000146865845, 0.11689817160367966]\n","epoch 461\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0341 - policy_loss: 2.2866 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4085 - value_mse: 0.1159\n","epoch 462\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0771 - policy_loss: 2.3301 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4024 - value_mse: 0.1163\n","epoch 463\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0352 - policy_loss: 2.2865 - value_loss: 0.6880 - policy_categorical_accuracy: 0.4013 - value_mse: 0.1164\n","epoch 464\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0345 - policy_loss: 2.2862 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4093 - value_mse: 0.1165\n","epoch 465\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0452 - policy_loss: 2.2971 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4097 - value_mse: 0.1159\n","epoch 466\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0371 - policy_loss: 2.2887 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4112 - value_mse: 0.1179\n","epoch 467\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0476 - policy_loss: 2.2992 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4092 - value_mse: 0.1172\n","epoch 468\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0500 - policy_loss: 2.3022 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4061 - value_mse: 0.1162\n","epoch 469\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9878 - policy_loss: 2.2408 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4157 - value_mse: 0.1162\n","epoch 470\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0542 - policy_loss: 2.3061 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4008 - value_mse: 0.1167\n","epoch 471\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0442 - policy_loss: 2.2961 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4029 - value_mse: 0.1160\n","epoch 472\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0271 - policy_loss: 2.2806 - value_loss: 0.6858 - policy_categorical_accuracy: 0.4075 - value_mse: 0.1170\n","epoch 473\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0648 - policy_loss: 2.3176 - value_loss: 0.6865 - policy_categorical_accuracy: 0.3995 - value_mse: 0.1158\n","epoch 474\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0570 - policy_loss: 2.3098 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4045 - value_mse: 0.1159\n","epoch 475\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0376 - policy_loss: 2.2895 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4032 - value_mse: 0.1178\n","epoch 476\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 62ms/step - loss: 3.0283 - policy_loss: 2.2806 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4060 - value_mse: 0.1179\n","epoch 477\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 3.0068 - policy_loss: 2.2583 - value_loss: 0.6879 - policy_categorical_accuracy: 0.4084 - value_mse: 0.1164\n","epoch 478\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0473 - policy_loss: 2.2991 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4018 - value_mse: 0.1165\n","epoch 479\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0228 - policy_loss: 2.2756 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4040 - value_mse: 0.1163\n","epoch 480\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0180 - policy_loss: 2.2705 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4119 - value_mse: 0.1155\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.005427837371826, 2.2578232288360596, 0.6868730187416077, 0.41530001163482666, 0.11692463606595993]\n","epoch 481\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0171 - policy_loss: 2.2680 - value_loss: 0.6883 - policy_categorical_accuracy: 0.4138 - value_mse: 0.1188\n","epoch 482\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0308 - policy_loss: 2.2828 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4134 - value_mse: 0.1158\n","epoch 483\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0367 - policy_loss: 2.2882 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4061 - value_mse: 0.1170\n","epoch 484\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0608 - policy_loss: 2.3134 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4040 - value_mse: 0.1149\n","epoch 485\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0366 - policy_loss: 2.2882 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4043 - value_mse: 0.1167\n","epoch 486\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0333 - policy_loss: 2.2862 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4097 - value_mse: 0.1168\n","epoch 487\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0115 - policy_loss: 2.2634 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4131 - value_mse: 0.1166\n","epoch 488\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0155 - policy_loss: 2.2669 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4065 - value_mse: 0.1173\n","epoch 489\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0695 - policy_loss: 2.3217 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4106 - value_mse: 0.1173\n","epoch 490\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9922 - policy_loss: 2.2449 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4201 - value_mse: 0.1150\n","epoch 491\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9899 - policy_loss: 2.2422 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4149 - value_mse: 0.1170\n","epoch 492\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0467 - policy_loss: 2.2989 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3955 - value_mse: 0.1168\n","epoch 493\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0355 - policy_loss: 2.2872 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4079 - value_mse: 0.1155\n","epoch 494\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0166 - policy_loss: 2.2699 - value_loss: 0.6858 - policy_categorical_accuracy: 0.4068 - value_mse: 0.1167\n","epoch 495\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0236 - policy_loss: 2.2760 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4117 - value_mse: 0.1150\n","epoch 496\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0314 - policy_loss: 2.2836 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4107 - value_mse: 0.1159\n","epoch 497\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0392 - policy_loss: 2.2916 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4081 - value_mse: 0.1166\n","epoch 498\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0074 - policy_loss: 2.2597 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4113 - value_mse: 0.1170\n","epoch 499\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0348 - policy_loss: 2.2859 - value_loss: 0.6881 - policy_categorical_accuracy: 0.4079 - value_mse: 0.1167\n","epoch 500\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0076 - policy_loss: 2.2610 - value_loss: 0.6857 - policy_categorical_accuracy: 0.4088 - value_mse: 0.1160\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.020869731903076, 2.2729313373565674, 0.6870514154434204, 0.4101000130176544, 0.11700943857431412]\n","epoch 501\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0076 - policy_loss: 2.2611 - value_loss: 0.6856 - policy_categorical_accuracy: 0.4094 - value_mse: 0.1144\n","epoch 502\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0371 - policy_loss: 2.2893 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4054 - value_mse: 0.1159\n","epoch 503\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0058 - policy_loss: 2.2588 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4069 - value_mse: 0.1133\n","epoch 504\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0151 - policy_loss: 2.2673 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4068 - value_mse: 0.1164\n","epoch 505\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0257 - policy_loss: 2.2778 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4089 - value_mse: 0.1167\n","epoch 506\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0383 - policy_loss: 2.2911 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4019 - value_mse: 0.1157\n","epoch 507\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9981 - policy_loss: 2.2503 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4141 - value_mse: 0.1166\n","epoch 508\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0364 - policy_loss: 2.2874 - value_loss: 0.6879 - policy_categorical_accuracy: 0.4104 - value_mse: 0.1165\n","epoch 509\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 3.0250 - policy_loss: 2.2775 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4022 - value_mse: 0.1172\n","epoch 510\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 2.9993 - policy_loss: 2.2513 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4068 - value_mse: 0.1163\n","epoch 511\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0417 - policy_loss: 2.2942 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4072 - value_mse: 0.1167\n","epoch 512\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0174 - policy_loss: 2.2713 - value_loss: 0.6851 - policy_categorical_accuracy: 0.4062 - value_mse: 0.1164\n","epoch 513\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0093 - policy_loss: 2.2600 - value_loss: 0.6883 - policy_categorical_accuracy: 0.4112 - value_mse: 0.1168\n","epoch 514\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0157 - policy_loss: 2.2674 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4114 - value_mse: 0.1161\n","epoch 515\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0767 - policy_loss: 2.3281 - value_loss: 0.6875 - policy_categorical_accuracy: 0.3940 - value_mse: 0.1172\n","epoch 516\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0338 - policy_loss: 2.2852 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4067 - value_mse: 0.1165\n","epoch 517\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0144 - policy_loss: 2.2663 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4123 - value_mse: 0.1171\n","epoch 518\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0494 - policy_loss: 2.3015 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4045 - value_mse: 0.1171\n","epoch 519\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9895 - policy_loss: 2.2413 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4123 - value_mse: 0.1176\n","epoch 520\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0169 - policy_loss: 2.2678 - value_loss: 0.6881 - policy_categorical_accuracy: 0.4076 - value_mse: 0.1161\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.0396173000335693, 2.2911953926086426, 0.6873732209205627, 0.41200000047683716, 0.11717218905687332]\n","epoch 521\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0214 - policy_loss: 2.2739 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4084 - value_mse: 0.1166\n","epoch 522\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0424 - policy_loss: 2.2943 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3968 - value_mse: 0.1179\n","epoch 523\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0005 - policy_loss: 2.2537 - value_loss: 0.6857 - policy_categorical_accuracy: 0.4112 - value_mse: 0.1156\n","epoch 524\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0175 - policy_loss: 2.2709 - value_loss: 0.6856 - policy_categorical_accuracy: 0.4068 - value_mse: 0.1155\n","epoch 525\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0008 - policy_loss: 2.2536 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4124 - value_mse: 0.1162\n","epoch 526\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0169 - policy_loss: 2.2689 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4102 - value_mse: 0.1185\n","epoch 527\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0118 - policy_loss: 2.2641 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4125 - value_mse: 0.1149\n","epoch 528\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0077 - policy_loss: 2.2588 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4027 - value_mse: 0.1176\n","epoch 529\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9991 - policy_loss: 2.2511 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4135 - value_mse: 0.1165\n","epoch 530\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0210 - policy_loss: 2.2732 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4064 - value_mse: 0.1171\n","epoch 531\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0180 - policy_loss: 2.2699 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4078 - value_mse: 0.1179\n","epoch 532\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0376 - policy_loss: 2.2893 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4106 - value_mse: 0.1148\n","epoch 533\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0100 - policy_loss: 2.2621 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4069 - value_mse: 0.1171\n","epoch 534\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0291 - policy_loss: 2.2796 - value_loss: 0.6883 - policy_categorical_accuracy: 0.4024 - value_mse: 0.1153\n","epoch 535\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0047 - policy_loss: 2.2566 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4183 - value_mse: 0.1149\n","epoch 536\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0254 - policy_loss: 2.2776 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4060 - value_mse: 0.1164\n","epoch 537\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0161 - policy_loss: 2.2673 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4045 - value_mse: 0.1182\n","epoch 538\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0206 - policy_loss: 2.2735 - value_loss: 0.6859 - policy_categorical_accuracy: 0.4053 - value_mse: 0.1168\n","epoch 539\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0091 - policy_loss: 2.2612 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4086 - value_mse: 0.1146\n","epoch 540\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0368 - policy_loss: 2.2882 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4033 - value_mse: 0.1169\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.0116381645202637, 2.262848138809204, 0.6875571012496948, 0.4165000021457672, 0.11726155877113342]\n","epoch 541\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0025 - policy_loss: 2.2543 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4157 - value_mse: 0.1162\n","epoch 542\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0488 - policy_loss: 2.2994 - value_loss: 0.6882 - policy_categorical_accuracy: 0.4069 - value_mse: 0.1160\n","epoch 543\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0319 - policy_loss: 2.2832 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4067 - value_mse: 0.1169\n","epoch 544\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 61ms/step - loss: 3.0133 - policy_loss: 2.2652 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4121 - value_mse: 0.1191\n","epoch 545\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 3.0105 - policy_loss: 2.2629 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4073 - value_mse: 0.1156\n","epoch 546\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9959 - policy_loss: 2.2479 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4117 - value_mse: 0.1162\n","epoch 547\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9904 - policy_loss: 2.2430 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4176 - value_mse: 0.1165\n","epoch 548\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0311 - policy_loss: 2.2829 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4051 - value_mse: 0.1168\n","epoch 549\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0380 - policy_loss: 2.2897 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4102 - value_mse: 0.1171\n","epoch 550\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0374 - policy_loss: 2.2879 - value_loss: 0.6881 - policy_categorical_accuracy: 0.4052 - value_mse: 0.1178\n","epoch 551\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0143 - policy_loss: 2.2669 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4105 - value_mse: 0.1152\n","epoch 552\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0062 - policy_loss: 2.2575 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4112 - value_mse: 0.1170\n","epoch 553\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0353 - policy_loss: 2.2870 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4033 - value_mse: 0.1175\n","epoch 554\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0109 - policy_loss: 2.2618 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4118 - value_mse: 0.1173\n","epoch 555\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0052 - policy_loss: 2.2567 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4134 - value_mse: 0.1173\n","epoch 556\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0242 - policy_loss: 2.2767 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4067 - value_mse: 0.1148\n","epoch 557\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9950 - policy_loss: 2.2464 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4103 - value_mse: 0.1182\n","epoch 558\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0267 - policy_loss: 2.2784 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4072 - value_mse: 0.1169\n","epoch 559\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0122 - policy_loss: 2.2616 - value_loss: 0.6892 - policy_categorical_accuracy: 0.4095 - value_mse: 0.1186\n","epoch 560\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0212 - policy_loss: 2.2729 - value_loss: 0.6869 - policy_categorical_accuracy: 0.3996 - value_mse: 0.1152\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.988037586212158, 2.2381463050842285, 0.6884923577308655, 0.41589999198913574, 0.1177305281162262]\n","epoch 561\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0388 - policy_loss: 2.2897 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4090 - value_mse: 0.1151\n","epoch 562\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0225 - policy_loss: 2.2743 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4078 - value_mse: 0.1152\n","epoch 563\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9976 - policy_loss: 2.2500 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4090 - value_mse: 0.1162\n","epoch 564\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0169 - policy_loss: 2.2678 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4031 - value_mse: 0.1171\n","epoch 565\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0421 - policy_loss: 2.2936 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4078 - value_mse: 0.1159\n","epoch 566\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0023 - policy_loss: 2.2546 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4130 - value_mse: 0.1158\n","epoch 567\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9922 - policy_loss: 2.2428 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4198 - value_mse: 0.1158\n","epoch 568\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0237 - policy_loss: 2.2756 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4104 - value_mse: 0.1173\n","epoch 569\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9899 - policy_loss: 2.2422 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4165 - value_mse: 0.1152\n","epoch 570\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9998 - policy_loss: 2.2512 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4166 - value_mse: 0.1185\n","epoch 571\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0245 - policy_loss: 2.2761 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4142 - value_mse: 0.1167\n","epoch 572\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0009 - policy_loss: 2.2526 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4127 - value_mse: 0.1165\n","epoch 573\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0269 - policy_loss: 2.2772 - value_loss: 0.6881 - policy_categorical_accuracy: 0.4069 - value_mse: 0.1160\n","epoch 574\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9976 - policy_loss: 2.2501 - value_loss: 0.6859 - policy_categorical_accuracy: 0.4112 - value_mse: 0.1182\n","epoch 575\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0030 - policy_loss: 2.2547 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4098 - value_mse: 0.1152\n","epoch 576\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0028 - policy_loss: 2.2533 - value_loss: 0.6879 - policy_categorical_accuracy: 0.4175 - value_mse: 0.1174\n","epoch 577\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0205 - policy_loss: 2.2730 - value_loss: 0.6859 - policy_categorical_accuracy: 0.4146 - value_mse: 0.1168\n","epoch 578\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0446 - policy_loss: 2.2980 - value_loss: 0.6850 - policy_categorical_accuracy: 0.4039 - value_mse: 0.1137\n","epoch 579\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 60ms/step - loss: 2.9990 - policy_loss: 2.2491 - value_loss: 0.6882 - policy_categorical_accuracy: 0.4163 - value_mse: 0.1173\n","epoch 580\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 3.0211 - policy_loss: 2.2723 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4052 - value_mse: 0.1154\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.0231921672821045, 2.2736270427703857, 0.6879911422729492, 0.414000004529953, 0.11746743321418762]\n","epoch 581\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0443 - policy_loss: 2.2966 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4043 - value_mse: 0.1165\n","epoch 582\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0072 - policy_loss: 2.2585 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4106 - value_mse: 0.1157\n","epoch 583\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9692 - policy_loss: 2.2202 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4203 - value_mse: 0.1185\n","epoch 584\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0458 - policy_loss: 2.2974 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4045 - value_mse: 0.1146\n","epoch 585\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9945 - policy_loss: 2.2476 - value_loss: 0.6853 - policy_categorical_accuracy: 0.4096 - value_mse: 0.1151\n","epoch 586\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0321 - policy_loss: 2.2842 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4047 - value_mse: 0.1149\n","epoch 587\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9959 - policy_loss: 2.2479 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4143 - value_mse: 0.1174\n","epoch 588\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0322 - policy_loss: 2.2829 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4075 - value_mse: 0.1157\n","epoch 589\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0339 - policy_loss: 2.2856 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4092 - value_mse: 0.1150\n","epoch 590\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9817 - policy_loss: 2.2325 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4204 - value_mse: 0.1176\n","epoch 591\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9913 - policy_loss: 2.2440 - value_loss: 0.6857 - policy_categorical_accuracy: 0.4160 - value_mse: 0.1180\n","epoch 592\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0296 - policy_loss: 2.2807 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4059 - value_mse: 0.1166\n","epoch 593\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0014 - policy_loss: 2.2524 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4172 - value_mse: 0.1172\n","epoch 594\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0047 - policy_loss: 2.2544 - value_loss: 0.6886 - policy_categorical_accuracy: 0.4085 - value_mse: 0.1182\n","epoch 595\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0231 - policy_loss: 2.2745 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4045 - value_mse: 0.1157\n","epoch 596\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9974 - policy_loss: 2.2498 - value_loss: 0.6859 - policy_categorical_accuracy: 0.4114 - value_mse: 0.1156\n","epoch 597\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9902 - policy_loss: 2.2418 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4154 - value_mse: 0.1177\n","epoch 598\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0091 - policy_loss: 2.2607 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4057 - value_mse: 0.1164\n","epoch 599\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0093 - policy_loss: 2.2618 - value_loss: 0.6857 - policy_categorical_accuracy: 0.4125 - value_mse: 0.1146\n","epoch 600\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0030 - policy_loss: 2.2544 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4088 - value_mse: 0.1167\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.029564380645752, 2.280287504196167, 0.6875146627426147, 0.41029998660087585, 0.11724186688661575]\n","epoch 601\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9956 - policy_loss: 2.2469 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4147 - value_mse: 0.1151\n","epoch 602\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0343 - policy_loss: 2.2856 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4068 - value_mse: 0.1171\n","epoch 603\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0286 - policy_loss: 2.2804 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4052 - value_mse: 0.1161\n","epoch 604\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0001 - policy_loss: 2.2507 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4159 - value_mse: 0.1170\n","epoch 605\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9881 - policy_loss: 2.2394 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4155 - value_mse: 0.1178\n","epoch 606\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0180 - policy_loss: 2.2702 - value_loss: 0.6860 - policy_categorical_accuracy: 0.4006 - value_mse: 0.1158\n","epoch 607\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0548 - policy_loss: 2.3052 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4030 - value_mse: 0.1176\n","epoch 608\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0082 - policy_loss: 2.2610 - value_loss: 0.6854 - policy_categorical_accuracy: 0.4115 - value_mse: 0.1176\n","epoch 609\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9995 - policy_loss: 2.2510 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4102 - value_mse: 0.1171\n","epoch 610\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0036 - policy_loss: 2.2555 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4132 - value_mse: 0.1147\n","epoch 611\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9921 - policy_loss: 2.2426 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4185 - value_mse: 0.1174\n","epoch 612\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9954 - policy_loss: 2.2467 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4140 - value_mse: 0.1158\n","epoch 613\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 61ms/step - loss: 3.0120 - policy_loss: 2.2620 - value_loss: 0.6882 - policy_categorical_accuracy: 0.4075 - value_mse: 0.1173\n","epoch 614\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 2.9939 - policy_loss: 2.2445 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4121 - value_mse: 0.1165\n","epoch 615\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0114 - policy_loss: 2.2622 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4109 - value_mse: 0.1142\n","epoch 616\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9983 - policy_loss: 2.2496 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4139 - value_mse: 0.1159\n","epoch 617\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9841 - policy_loss: 2.2358 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4128 - value_mse: 0.1156\n","epoch 618\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0066 - policy_loss: 2.2569 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4047 - value_mse: 0.1191\n","epoch 619\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0311 - policy_loss: 2.2820 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4109 - value_mse: 0.1153\n","epoch 620\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9852 - policy_loss: 2.2366 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4135 - value_mse: 0.1155\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9917426109313965, 2.242201328277588, 0.6876054406166077, 0.414900004863739, 0.11728895455598831]\n","epoch 621\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0069 - policy_loss: 2.2573 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4116 - value_mse: 0.1179\n","epoch 622\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9966 - policy_loss: 2.2494 - value_loss: 0.6852 - policy_categorical_accuracy: 0.4067 - value_mse: 0.1172\n","epoch 623\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0069 - policy_loss: 2.2576 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4058 - value_mse: 0.1179\n","epoch 624\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9640 - policy_loss: 2.2147 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4228 - value_mse: 0.1163\n","epoch 625\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0176 - policy_loss: 2.2682 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4063 - value_mse: 0.1148\n","epoch 626\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9972 - policy_loss: 2.2484 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4075 - value_mse: 0.1177\n","epoch 627\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0078 - policy_loss: 2.2598 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4153 - value_mse: 0.1160\n","epoch 628\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0128 - policy_loss: 2.2645 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4090 - value_mse: 0.1160\n","epoch 629\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0057 - policy_loss: 2.2568 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4078 - value_mse: 0.1167\n","epoch 630\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9836 - policy_loss: 2.2356 - value_loss: 0.6860 - policy_categorical_accuracy: 0.4131 - value_mse: 0.1144\n","epoch 631\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0143 - policy_loss: 2.2646 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4069 - value_mse: 0.1193\n","epoch 632\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0095 - policy_loss: 2.2598 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4056 - value_mse: 0.1169\n","epoch 633\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0033 - policy_loss: 2.2539 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4122 - value_mse: 0.1156\n","epoch 634\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0034 - policy_loss: 2.2543 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4156 - value_mse: 0.1164\n","epoch 635\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0011 - policy_loss: 2.2524 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4107 - value_mse: 0.1155\n","epoch 636\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9955 - policy_loss: 2.2468 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4171 - value_mse: 0.1170\n","epoch 637\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0406 - policy_loss: 2.2916 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4085 - value_mse: 0.1155\n","epoch 638\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9852 - policy_loss: 2.2361 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4164 - value_mse: 0.1169\n","epoch 639\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0094 - policy_loss: 2.2602 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4176 - value_mse: 0.1174\n","epoch 640\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9797 - policy_loss: 2.2296 - value_loss: 0.6880 - policy_categorical_accuracy: 0.4215 - value_mse: 0.1189\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.007741689682007, 2.2583963871002197, 0.6872317790985107, 0.4106000065803528, 0.11710294336080551]\n","epoch 641\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0108 - policy_loss: 2.2621 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4013 - value_mse: 0.1157\n","epoch 642\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0152 - policy_loss: 2.2665 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4085 - value_mse: 0.1163\n","epoch 643\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0075 - policy_loss: 2.2587 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4071 - value_mse: 0.1172\n","epoch 644\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9939 - policy_loss: 2.2457 - value_loss: 0.6860 - policy_categorical_accuracy: 0.4168 - value_mse: 0.1158\n","epoch 645\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9821 - policy_loss: 2.2327 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4170 - value_mse: 0.1186\n","epoch 646\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9842 - policy_loss: 2.2357 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4088 - value_mse: 0.1160\n","epoch 647\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 2.9747 - policy_loss: 2.2245 - value_loss: 0.6880 - policy_categorical_accuracy: 0.4150 - value_mse: 0.1175\n","epoch 648\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 3.0168 - policy_loss: 2.2680 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4086 - value_mse: 0.1162\n","epoch 649\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 58ms/step - loss: 3.0066 - policy_loss: 2.2582 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4109 - value_mse: 0.1156\n","epoch 650\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0177 - policy_loss: 2.2679 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4114 - value_mse: 0.1160\n","epoch 651\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0230 - policy_loss: 2.2755 - value_loss: 0.6853 - policy_categorical_accuracy: 0.4012 - value_mse: 0.1160\n","epoch 652\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9761 - policy_loss: 2.2276 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4194 - value_mse: 0.1149\n","epoch 653\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9927 - policy_loss: 2.2442 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4146 - value_mse: 0.1161\n","epoch 654\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0346 - policy_loss: 2.2856 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4051 - value_mse: 0.1159\n","epoch 655\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0177 - policy_loss: 2.2700 - value_loss: 0.6854 - policy_categorical_accuracy: 0.4068 - value_mse: 0.1143\n","epoch 656\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0142 - policy_loss: 2.2651 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4051 - value_mse: 0.1165\n","epoch 657\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0125 - policy_loss: 2.2622 - value_loss: 0.6880 - policy_categorical_accuracy: 0.4154 - value_mse: 0.1167\n","epoch 658\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9890 - policy_loss: 2.2399 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4158 - value_mse: 0.1183\n","epoch 659\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0165 - policy_loss: 2.2673 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4108 - value_mse: 0.1159\n","epoch 660\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9947 - policy_loss: 2.2456 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4132 - value_mse: 0.1164\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9905874729156494, 2.241142511367798, 0.6871317625045776, 0.41839998960494995, 0.11705482006072998]\n","epoch 661\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9766 - policy_loss: 2.2273 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4179 - value_mse: 0.1173\n","epoch 662\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0029 - policy_loss: 2.2531 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4187 - value_mse: 0.1167\n","epoch 663\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9893 - policy_loss: 2.2404 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4109 - value_mse: 0.1181\n","epoch 664\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0024 - policy_loss: 2.2530 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4130 - value_mse: 0.1195\n","epoch 665\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9529 - policy_loss: 2.2030 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4250 - value_mse: 0.1175\n","epoch 666\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0070 - policy_loss: 2.2577 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4101 - value_mse: 0.1167\n","epoch 667\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9806 - policy_loss: 2.2305 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4156 - value_mse: 0.1167\n","epoch 668\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9535 - policy_loss: 2.2051 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4240 - value_mse: 0.1158\n","epoch 669\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9924 - policy_loss: 2.2440 - value_loss: 0.6860 - policy_categorical_accuracy: 0.4178 - value_mse: 0.1165\n","epoch 670\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9745 - policy_loss: 2.2258 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4222 - value_mse: 0.1172\n","epoch 671\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0138 - policy_loss: 2.2642 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4095 - value_mse: 0.1188\n","epoch 672\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0038 - policy_loss: 2.2543 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4152 - value_mse: 0.1166\n","epoch 673\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9763 - policy_loss: 2.2274 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4168 - value_mse: 0.1145\n","epoch 674\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0024 - policy_loss: 2.2536 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4071 - value_mse: 0.1162\n","epoch 675\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9725 - policy_loss: 2.2229 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4173 - value_mse: 0.1161\n","epoch 676\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9935 - policy_loss: 2.2435 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4144 - value_mse: 0.1176\n","epoch 677\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9972 - policy_loss: 2.2476 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4144 - value_mse: 0.1175\n","epoch 678\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9922 - policy_loss: 2.2428 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4092 - value_mse: 0.1160\n","epoch 679\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9810 - policy_loss: 2.2315 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4130 - value_mse: 0.1165\n","epoch 680\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0283 - policy_loss: 2.2795 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4003 - value_mse: 0.1151\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.966264009475708, 2.2170584201812744, 0.6868290305137634, 0.42500001192092896, 0.11689884960651398]\n","epoch 681\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9880 - policy_loss: 2.2376 - value_loss: 0.6879 - policy_categorical_accuracy: 0.4148 - value_mse: 0.1168\n","epoch 682\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 60ms/step - loss: 2.9995 - policy_loss: 2.2493 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4076 - value_mse: 0.1174\n","epoch 683\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 3.0155 - policy_loss: 2.2659 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4030 - value_mse: 0.1139\n","epoch 684\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9890 - policy_loss: 2.2383 - value_loss: 0.6884 - policy_categorical_accuracy: 0.4154 - value_mse: 0.1164\n","epoch 685\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9848 - policy_loss: 2.2349 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4170 - value_mse: 0.1177\n","epoch 686\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9617 - policy_loss: 2.2113 - value_loss: 0.6880 - policy_categorical_accuracy: 0.4228 - value_mse: 0.1164\n","epoch 687\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9897 - policy_loss: 2.2401 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4101 - value_mse: 0.1171\n","epoch 688\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0350 - policy_loss: 2.2855 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4058 - value_mse: 0.1160\n","epoch 689\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9821 - policy_loss: 2.2322 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4094 - value_mse: 0.1171\n","epoch 690\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9682 - policy_loss: 2.2189 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4086 - value_mse: 0.1158\n","epoch 691\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9629 - policy_loss: 2.2140 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4263 - value_mse: 0.1170\n","epoch 692\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0157 - policy_loss: 2.2659 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4070 - value_mse: 0.1182\n","epoch 693\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0075 - policy_loss: 2.2574 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4099 - value_mse: 0.1166\n","epoch 694\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9944 - policy_loss: 2.2452 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4133 - value_mse: 0.1152\n","epoch 695\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0022 - policy_loss: 2.2517 - value_loss: 0.6879 - policy_categorical_accuracy: 0.4087 - value_mse: 0.1169\n","epoch 696\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9811 - policy_loss: 2.2310 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4174 - value_mse: 0.1159\n","epoch 697\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9897 - policy_loss: 2.2411 - value_loss: 0.6860 - policy_categorical_accuracy: 0.4122 - value_mse: 0.1167\n","epoch 698\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9633 - policy_loss: 2.2126 - value_loss: 0.6881 - policy_categorical_accuracy: 0.4117 - value_mse: 0.1158\n","epoch 699\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9748 - policy_loss: 2.2239 - value_loss: 0.6882 - policy_categorical_accuracy: 0.4129 - value_mse: 0.1148\n","epoch 700\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9769 - policy_loss: 2.2262 - value_loss: 0.6881 - policy_categorical_accuracy: 0.4221 - value_mse: 0.1182\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9885823726654053, 2.2377843856811523, 0.6881517171859741, 0.4169999957084656, 0.1175515353679657]\n","epoch 701\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0125 - policy_loss: 2.2623 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4072 - value_mse: 0.1174\n","epoch 702\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9659 - policy_loss: 2.2170 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4179 - value_mse: 0.1147\n","epoch 703\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9477 - policy_loss: 2.1985 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4165 - value_mse: 0.1155\n","epoch 704\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9872 - policy_loss: 2.2389 - value_loss: 0.6856 - policy_categorical_accuracy: 0.4214 - value_mse: 0.1158\n","epoch 705\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9836 - policy_loss: 2.2336 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4147 - value_mse: 0.1173\n","epoch 706\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9667 - policy_loss: 2.2163 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4196 - value_mse: 0.1151\n","epoch 707\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9960 - policy_loss: 2.2473 - value_loss: 0.6860 - policy_categorical_accuracy: 0.4194 - value_mse: 0.1158\n","epoch 708\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9968 - policy_loss: 2.2472 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4132 - value_mse: 0.1164\n","epoch 709\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9689 - policy_loss: 2.2185 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4181 - value_mse: 0.1177\n","epoch 710\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9630 - policy_loss: 2.2136 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4177 - value_mse: 0.1178\n","epoch 711\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9989 - policy_loss: 2.2490 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4134 - value_mse: 0.1166\n","epoch 712\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9646 - policy_loss: 2.2156 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4205 - value_mse: 0.1184\n","epoch 713\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0315 - policy_loss: 2.2818 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4060 - value_mse: 0.1195\n","epoch 714\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9808 - policy_loss: 2.2313 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4182 - value_mse: 0.1148\n","epoch 715\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9992 - policy_loss: 2.2501 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4114 - value_mse: 0.1153\n","epoch 716\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0050 - policy_loss: 2.2549 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4134 - value_mse: 0.1162\n","epoch 717\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 58ms/step - loss: 2.9966 - policy_loss: 2.2478 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4077 - value_mse: 0.1162\n","epoch 718\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 60ms/step - loss: 2.9786 - policy_loss: 2.2295 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4211 - value_mse: 0.1157\n","epoch 719\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 57ms/step - loss: 3.0137 - policy_loss: 2.2635 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4087 - value_mse: 0.1160\n","epoch 720\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9816 - policy_loss: 2.2311 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4176 - value_mse: 0.1167\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.008594036102295, 2.2592313289642334, 0.6866251826286316, 0.41819998621940613, 0.11679863184690475]\n","epoch 721\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9935 - policy_loss: 2.2433 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4164 - value_mse: 0.1167\n","epoch 722\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9423 - policy_loss: 2.1924 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4246 - value_mse: 0.1168\n","epoch 723\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9945 - policy_loss: 2.2451 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4072 - value_mse: 0.1173\n","epoch 724\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0107 - policy_loss: 2.2607 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4095 - value_mse: 0.1172\n","epoch 725\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9775 - policy_loss: 2.2287 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4182 - value_mse: 0.1168\n","epoch 726\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0116 - policy_loss: 2.2627 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4092 - value_mse: 0.1175\n","epoch 727\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9684 - policy_loss: 2.2177 - value_loss: 0.6880 - policy_categorical_accuracy: 0.4223 - value_mse: 0.1163\n","epoch 728\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9882 - policy_loss: 2.2382 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4176 - value_mse: 0.1157\n","epoch 729\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9814 - policy_loss: 2.2305 - value_loss: 0.6880 - policy_categorical_accuracy: 0.4166 - value_mse: 0.1172\n","epoch 730\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9602 - policy_loss: 2.2114 - value_loss: 0.6860 - policy_categorical_accuracy: 0.4229 - value_mse: 0.1146\n","epoch 731\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9961 - policy_loss: 2.2460 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4123 - value_mse: 0.1169\n","epoch 732\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9928 - policy_loss: 2.2428 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4147 - value_mse: 0.1161\n","epoch 733\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9931 - policy_loss: 2.2428 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4110 - value_mse: 0.1148\n","epoch 734\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9608 - policy_loss: 2.2106 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4160 - value_mse: 0.1180\n","epoch 735\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9954 - policy_loss: 2.2455 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4090 - value_mse: 0.1176\n","epoch 736\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9926 - policy_loss: 2.2424 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4143 - value_mse: 0.1161\n","epoch 737\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9794 - policy_loss: 2.2295 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4204 - value_mse: 0.1174\n","epoch 738\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9618 - policy_loss: 2.2132 - value_loss: 0.6858 - policy_categorical_accuracy: 0.4112 - value_mse: 0.1169\n","epoch 739\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9788 - policy_loss: 2.2291 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4144 - value_mse: 0.1173\n","epoch 740\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9791 - policy_loss: 2.2295 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4181 - value_mse: 0.1148\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9581050872802734, 2.207716226577759, 0.6875528693199158, 0.42329999804496765, 0.1172623559832573]\n","epoch 741\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9924 - policy_loss: 2.2421 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4100 - value_mse: 0.1184\n","epoch 742\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9571 - policy_loss: 2.2064 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4154 - value_mse: 0.1168\n","epoch 743\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9893 - policy_loss: 2.2394 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4142 - value_mse: 0.1153\n","epoch 744\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9799 - policy_loss: 2.2308 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4150 - value_mse: 0.1146\n","epoch 745\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9812 - policy_loss: 2.2304 - value_loss: 0.6879 - policy_categorical_accuracy: 0.4168 - value_mse: 0.1184\n","epoch 746\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9955 - policy_loss: 2.2450 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4106 - value_mse: 0.1172\n","epoch 747\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9873 - policy_loss: 2.2374 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4127 - value_mse: 0.1161\n","epoch 748\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9915 - policy_loss: 2.2424 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4080 - value_mse: 0.1156\n","epoch 749\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0111 - policy_loss: 2.2616 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4008 - value_mse: 0.1172\n","epoch 750\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0146 - policy_loss: 2.2647 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4053 - value_mse: 0.1167\n","epoch 751\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0299 - policy_loss: 2.2784 - value_loss: 0.6885 - policy_categorical_accuracy: 0.4040 - value_mse: 0.1160\n","epoch 752\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 60ms/step - loss: 3.0005 - policy_loss: 2.2509 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4091 - value_mse: 0.1143\n","epoch 753\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 60ms/step - loss: 2.9650 - policy_loss: 2.2142 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4208 - value_mse: 0.1161\n","epoch 754\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9656 - policy_loss: 2.2149 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4168 - value_mse: 0.1182\n","epoch 755\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9589 - policy_loss: 2.2088 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4228 - value_mse: 0.1158\n","epoch 756\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9074 - policy_loss: 2.1579 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4285 - value_mse: 0.1156\n","epoch 757\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9679 - policy_loss: 2.2166 - value_loss: 0.6882 - policy_categorical_accuracy: 0.4191 - value_mse: 0.1181\n","epoch 758\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9906 - policy_loss: 2.2403 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4118 - value_mse: 0.1160\n","epoch 759\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0313 - policy_loss: 2.2822 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4040 - value_mse: 0.1158\n","epoch 760\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9674 - policy_loss: 2.2181 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4227 - value_mse: 0.1168\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9553682804107666, 2.205773115158081, 0.6865677833557129, 0.4253999888896942, 0.11677228659391403]\n","epoch 761\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9534 - policy_loss: 2.2025 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4135 - value_mse: 0.1165\n","epoch 762\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9499 - policy_loss: 2.2002 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4184 - value_mse: 0.1170\n","epoch 763\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0018 - policy_loss: 2.2518 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4126 - value_mse: 0.1157\n","epoch 764\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9599 - policy_loss: 2.2089 - value_loss: 0.6880 - policy_categorical_accuracy: 0.4225 - value_mse: 0.1164\n","epoch 765\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9803 - policy_loss: 2.2298 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4162 - value_mse: 0.1160\n","epoch 766\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9705 - policy_loss: 2.2215 - value_loss: 0.6859 - policy_categorical_accuracy: 0.4157 - value_mse: 0.1153\n","epoch 767\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0027 - policy_loss: 2.2531 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4114 - value_mse: 0.1169\n","epoch 768\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0152 - policy_loss: 2.2652 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4097 - value_mse: 0.1158\n","epoch 769\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9631 - policy_loss: 2.2137 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4151 - value_mse: 0.1154\n","epoch 770\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9769 - policy_loss: 2.2281 - value_loss: 0.6857 - policy_categorical_accuracy: 0.4123 - value_mse: 0.1179\n","epoch 771\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9841 - policy_loss: 2.2349 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4133 - value_mse: 0.1166\n","epoch 772\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9627 - policy_loss: 2.2106 - value_loss: 0.6890 - policy_categorical_accuracy: 0.4181 - value_mse: 0.1178\n","epoch 773\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9853 - policy_loss: 2.2354 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4159 - value_mse: 0.1166\n","epoch 774\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0044 - policy_loss: 2.2551 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4125 - value_mse: 0.1151\n","epoch 775\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0023 - policy_loss: 2.2520 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4126 - value_mse: 0.1172\n","epoch 776\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9783 - policy_loss: 2.2280 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4144 - value_mse: 0.1175\n","epoch 777\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9630 - policy_loss: 2.2137 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4185 - value_mse: 0.1175\n","epoch 778\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0303 - policy_loss: 2.2809 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4095 - value_mse: 0.1160\n","epoch 779\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9663 - policy_loss: 2.2168 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4159 - value_mse: 0.1147\n","epoch 780\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9972 - policy_loss: 2.2480 - value_loss: 0.6860 - policy_categorical_accuracy: 0.4137 - value_mse: 0.1149\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9599382877349854, 2.2099082469940186, 0.6868352293968201, 0.42179998755455017, 0.1169053316116333]\n","epoch 781\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9927 - policy_loss: 2.2428 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4059 - value_mse: 0.1159\n","epoch 782\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9912 - policy_loss: 2.2403 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4152 - value_mse: 0.1158\n","epoch 783\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9729 - policy_loss: 2.2236 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4173 - value_mse: 0.1151\n","epoch 784\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9701 - policy_loss: 2.2185 - value_loss: 0.6884 - policy_categorical_accuracy: 0.4174 - value_mse: 0.1173\n","epoch 785\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9854 - policy_loss: 2.2360 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4172 - value_mse: 0.1148\n","epoch 786\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0116 - policy_loss: 2.2608 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4093 - value_mse: 0.1160\n","epoch 787\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 2.9582 - policy_loss: 2.2072 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4216 - value_mse: 0.1171\n","epoch 788\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 3.0011 - policy_loss: 2.2515 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4132 - value_mse: 0.1169\n","epoch 789\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 57ms/step - loss: 2.9738 - policy_loss: 2.2224 - value_loss: 0.6881 - policy_categorical_accuracy: 0.4108 - value_mse: 0.1183\n","epoch 790\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9580 - policy_loss: 2.2060 - value_loss: 0.6887 - policy_categorical_accuracy: 0.4186 - value_mse: 0.1156\n","epoch 791\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9707 - policy_loss: 2.2211 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4119 - value_mse: 0.1142\n","epoch 792\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9648 - policy_loss: 2.2139 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4183 - value_mse: 0.1172\n","epoch 793\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9852 - policy_loss: 2.2355 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4110 - value_mse: 0.1159\n","epoch 794\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0076 - policy_loss: 2.2565 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4085 - value_mse: 0.1169\n","epoch 795\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9730 - policy_loss: 2.2235 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4166 - value_mse: 0.1151\n","epoch 796\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9831 - policy_loss: 2.2340 - value_loss: 0.6858 - policy_categorical_accuracy: 0.4133 - value_mse: 0.1173\n","epoch 797\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9340 - policy_loss: 2.1826 - value_loss: 0.6880 - policy_categorical_accuracy: 0.4261 - value_mse: 0.1164\n","epoch 798\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9774 - policy_loss: 2.2275 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4117 - value_mse: 0.1151\n","epoch 799\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9898 - policy_loss: 2.2401 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4120 - value_mse: 0.1186\n","epoch 800\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9634 - policy_loss: 2.2125 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4158 - value_mse: 0.1178\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.973247528076172, 2.222940683364868, 0.6869182586669922, 0.42329999804496765, 0.11694550514221191]\n","epoch 801\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9738 - policy_loss: 2.2237 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4207 - value_mse: 0.1151\n","epoch 802\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9786 - policy_loss: 2.2277 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4104 - value_mse: 0.1162\n","epoch 803\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9725 - policy_loss: 2.2232 - value_loss: 0.6859 - policy_categorical_accuracy: 0.4159 - value_mse: 0.1147\n","epoch 804\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9830 - policy_loss: 2.2334 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4164 - value_mse: 0.1147\n","epoch 805\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9567 - policy_loss: 2.2080 - value_loss: 0.6853 - policy_categorical_accuracy: 0.4190 - value_mse: 0.1167\n","epoch 806\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9480 - policy_loss: 2.1979 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4193 - value_mse: 0.1161\n","epoch 807\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9823 - policy_loss: 2.2332 - value_loss: 0.6857 - policy_categorical_accuracy: 0.4212 - value_mse: 0.1145\n","epoch 808\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9774 - policy_loss: 2.2262 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4182 - value_mse: 0.1171\n","epoch 809\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9884 - policy_loss: 2.2394 - value_loss: 0.6856 - policy_categorical_accuracy: 0.4163 - value_mse: 0.1156\n","epoch 810\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9461 - policy_loss: 2.1955 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4169 - value_mse: 0.1161\n","epoch 811\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9863 - policy_loss: 2.2367 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4104 - value_mse: 0.1154\n","epoch 812\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9610 - policy_loss: 2.2111 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4169 - value_mse: 0.1167\n","epoch 813\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9833 - policy_loss: 2.2337 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4083 - value_mse: 0.1166\n","epoch 814\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9463 - policy_loss: 2.1973 - value_loss: 0.6856 - policy_categorical_accuracy: 0.4250 - value_mse: 0.1172\n","epoch 815\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9729 - policy_loss: 2.2224 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4145 - value_mse: 0.1169\n","epoch 816\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9860 - policy_loss: 2.2354 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4120 - value_mse: 0.1163\n","epoch 817\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9725 - policy_loss: 2.2221 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4175 - value_mse: 0.1155\n","epoch 818\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9644 - policy_loss: 2.2135 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4213 - value_mse: 0.1168\n","epoch 819\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9676 - policy_loss: 2.2190 - value_loss: 0.6851 - policy_categorical_accuracy: 0.4160 - value_mse: 0.1156\n","epoch 820\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9364 - policy_loss: 2.1856 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4266 - value_mse: 0.1176\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9544153213500977, 2.2036991119384766, 0.6872063279151917, 0.4255000054836273, 0.11709189414978027]\n","epoch 821\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9785 - policy_loss: 2.2289 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4243 - value_mse: 0.1156\n","epoch 822\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 58ms/step - loss: 3.0021 - policy_loss: 2.2518 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4100 - value_mse: 0.1165\n","epoch 823\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 2.9567 - policy_loss: 2.2057 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4210 - value_mse: 0.1152\n","epoch 824\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 57ms/step - loss: 2.9506 - policy_loss: 2.2005 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4226 - value_mse: 0.1160\n","epoch 825\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9780 - policy_loss: 2.2283 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4191 - value_mse: 0.1152\n","epoch 826\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9442 - policy_loss: 2.1932 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4270 - value_mse: 0.1162\n","epoch 827\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9571 - policy_loss: 2.2066 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4143 - value_mse: 0.1184\n","epoch 828\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9709 - policy_loss: 2.2219 - value_loss: 0.6855 - policy_categorical_accuracy: 0.4175 - value_mse: 0.1160\n","epoch 829\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9861 - policy_loss: 2.2348 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4154 - value_mse: 0.1164\n","epoch 830\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9935 - policy_loss: 2.2438 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4128 - value_mse: 0.1149\n","epoch 831\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9808 - policy_loss: 2.2306 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4124 - value_mse: 0.1155\n","epoch 832\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9921 - policy_loss: 2.2423 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4167 - value_mse: 0.1164\n","epoch 833\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9595 - policy_loss: 2.2084 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4228 - value_mse: 0.1191\n","epoch 834\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0064 - policy_loss: 2.2565 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4124 - value_mse: 0.1150\n","epoch 835\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9623 - policy_loss: 2.2124 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4174 - value_mse: 0.1166\n","epoch 836\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9430 - policy_loss: 2.1918 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4255 - value_mse: 0.1162\n","epoch 837\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9693 - policy_loss: 2.2171 - value_loss: 0.6885 - policy_categorical_accuracy: 0.4119 - value_mse: 0.1196\n","epoch 838\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9333 - policy_loss: 2.1831 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4185 - value_mse: 0.1173\n","epoch 839\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9659 - policy_loss: 2.2148 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4153 - value_mse: 0.1151\n","epoch 840\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9869 - policy_loss: 2.2359 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4160 - value_mse: 0.1150\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.996152639389038, 2.245598793029785, 0.6869009137153625, 0.4131999909877777, 0.11693653464317322]\n","epoch 841\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9671 - policy_loss: 2.2171 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4208 - value_mse: 0.1161\n","epoch 842\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9987 - policy_loss: 2.2480 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4097 - value_mse: 0.1162\n","epoch 843\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9685 - policy_loss: 2.2170 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4179 - value_mse: 0.1163\n","epoch 844\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9555 - policy_loss: 2.2044 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4228 - value_mse: 0.1172\n","epoch 845\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9599 - policy_loss: 2.2105 - value_loss: 0.6857 - policy_categorical_accuracy: 0.4184 - value_mse: 0.1160\n","epoch 846\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9615 - policy_loss: 2.2108 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4134 - value_mse: 0.1179\n","epoch 847\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9932 - policy_loss: 2.2416 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4158 - value_mse: 0.1157\n","epoch 848\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9958 - policy_loss: 2.2455 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4080 - value_mse: 0.1160\n","epoch 849\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9435 - policy_loss: 2.1933 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4174 - value_mse: 0.1178\n","epoch 850\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9807 - policy_loss: 2.2298 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4176 - value_mse: 0.1175\n","epoch 851\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9559 - policy_loss: 2.2059 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4202 - value_mse: 0.1159\n","epoch 852\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9906 - policy_loss: 2.2389 - value_loss: 0.6879 - policy_categorical_accuracy: 0.4149 - value_mse: 0.1155\n","epoch 853\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9617 - policy_loss: 2.2095 - value_loss: 0.6884 - policy_categorical_accuracy: 0.4239 - value_mse: 0.1164\n","epoch 854\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0058 - policy_loss: 2.2552 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4059 - value_mse: 0.1172\n","epoch 855\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9975 - policy_loss: 2.2454 - value_loss: 0.6883 - policy_categorical_accuracy: 0.4143 - value_mse: 0.1167\n","epoch 856\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9598 - policy_loss: 2.2089 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4234 - value_mse: 0.1171\n","epoch 857\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9891 - policy_loss: 2.2381 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4167 - value_mse: 0.1167\n","epoch 858\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9799 - policy_loss: 2.2286 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4164 - value_mse: 0.1175\n","epoch 859\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 60ms/step - loss: 2.9539 - policy_loss: 2.2046 - value_loss: 0.6854 - policy_categorical_accuracy: 0.4245 - value_mse: 0.1147\n","epoch 860\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 2.9640 - policy_loss: 2.2123 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4239 - value_mse: 0.1153\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.953568696975708, 2.202674627304077, 0.6870154738426208, 0.42730000615119934, 0.11699403077363968]\n","epoch 861\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9863 - policy_loss: 2.2360 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4141 - value_mse: 0.1163\n","epoch 862\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9701 - policy_loss: 2.2187 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4144 - value_mse: 0.1172\n","epoch 863\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9874 - policy_loss: 2.2370 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4164 - value_mse: 0.1167\n","epoch 864\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9470 - policy_loss: 2.1962 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4205 - value_mse: 0.1157\n","epoch 865\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9889 - policy_loss: 2.2389 - value_loss: 0.6860 - policy_categorical_accuracy: 0.4153 - value_mse: 0.1171\n","epoch 866\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9923 - policy_loss: 2.2425 - value_loss: 0.6859 - policy_categorical_accuracy: 0.4139 - value_mse: 0.1161\n","epoch 867\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.0021 - policy_loss: 2.2500 - value_loss: 0.6881 - policy_categorical_accuracy: 0.4147 - value_mse: 0.1148\n","epoch 868\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9755 - policy_loss: 2.2244 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4235 - value_mse: 0.1164\n","epoch 869\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9598 - policy_loss: 2.2082 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4130 - value_mse: 0.1173\n","epoch 870\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9629 - policy_loss: 2.2124 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4187 - value_mse: 0.1176\n","epoch 871\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9564 - policy_loss: 2.2072 - value_loss: 0.6852 - policy_categorical_accuracy: 0.4183 - value_mse: 0.1155\n","epoch 872\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9827 - policy_loss: 2.2321 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4231 - value_mse: 0.1173\n","epoch 873\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9514 - policy_loss: 2.2012 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4187 - value_mse: 0.1148\n","epoch 874\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9601 - policy_loss: 2.2076 - value_loss: 0.6884 - policy_categorical_accuracy: 0.4134 - value_mse: 0.1172\n","epoch 875\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9489 - policy_loss: 2.1996 - value_loss: 0.6853 - policy_categorical_accuracy: 0.4204 - value_mse: 0.1155\n","epoch 876\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9663 - policy_loss: 2.2159 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4139 - value_mse: 0.1159\n","epoch 877\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9847 - policy_loss: 2.2334 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4135 - value_mse: 0.1169\n","epoch 878\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9544 - policy_loss: 2.2032 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4204 - value_mse: 0.1168\n","epoch 879\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9625 - policy_loss: 2.2108 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4183 - value_mse: 0.1184\n","epoch 880\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9607 - policy_loss: 2.2093 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4165 - value_mse: 0.1169\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9708311557769775, 2.217902421951294, 0.6888774633407593, 0.4221000075340271, 0.11792049556970596]\n","epoch 881\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9648 - policy_loss: 2.2140 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4188 - value_mse: 0.1164\n","epoch 882\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9583 - policy_loss: 2.2076 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4144 - value_mse: 0.1145\n","epoch 883\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9714 - policy_loss: 2.2207 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4152 - value_mse: 0.1161\n","epoch 884\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9791 - policy_loss: 2.2278 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4123 - value_mse: 0.1173\n","epoch 885\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9769 - policy_loss: 2.2253 - value_loss: 0.6875 - policy_categorical_accuracy: 0.4181 - value_mse: 0.1186\n","epoch 886\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9588 - policy_loss: 2.2079 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4165 - value_mse: 0.1169\n","epoch 887\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9930 - policy_loss: 2.2421 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4204 - value_mse: 0.1155\n","epoch 888\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9732 - policy_loss: 2.2220 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4184 - value_mse: 0.1159\n","epoch 889\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9768 - policy_loss: 2.2263 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4102 - value_mse: 0.1161\n","epoch 890\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9417 - policy_loss: 2.1902 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4182 - value_mse: 0.1190\n","epoch 891\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9596 - policy_loss: 2.2084 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4161 - value_mse: 0.1163\n","epoch 892\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9566 - policy_loss: 2.2060 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4213 - value_mse: 0.1155\n","epoch 893\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9515 - policy_loss: 2.2007 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4219 - value_mse: 0.1176\n","epoch 894\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 60ms/step - loss: 2.9579 - policy_loss: 2.2072 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4222 - value_mse: 0.1154\n","epoch 895\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 2.9408 - policy_loss: 2.1906 - value_loss: 0.6860 - policy_categorical_accuracy: 0.4199 - value_mse: 0.1160\n","epoch 896\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9415 - policy_loss: 2.1904 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4229 - value_mse: 0.1158\n","epoch 897\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9364 - policy_loss: 2.1844 - value_loss: 0.6879 - policy_categorical_accuracy: 0.4212 - value_mse: 0.1172\n","epoch 898\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9866 - policy_loss: 2.2360 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4053 - value_mse: 0.1175\n","epoch 899\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9641 - policy_loss: 2.2134 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4198 - value_mse: 0.1158\n","epoch 900\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9500 - policy_loss: 2.1988 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4177 - value_mse: 0.1178\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.963850975036621, 2.2116498947143555, 0.6880137920379639, 0.42480000853538513, 0.11749263852834702]\n","epoch 901\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9334 - policy_loss: 2.1817 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4266 - value_mse: 0.1143\n","epoch 902\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9714 - policy_loss: 2.2224 - value_loss: 0.6848 - policy_categorical_accuracy: 0.4155 - value_mse: 0.1178\n","epoch 903\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9906 - policy_loss: 2.2386 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4152 - value_mse: 0.1177\n","epoch 904\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9713 - policy_loss: 2.2201 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4165 - value_mse: 0.1171\n","epoch 905\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9331 - policy_loss: 2.1823 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4241 - value_mse: 0.1168\n","epoch 906\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0044 - policy_loss: 2.2533 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4093 - value_mse: 0.1161\n","epoch 907\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9908 - policy_loss: 2.2402 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4196 - value_mse: 0.1155\n","epoch 908\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9641 - policy_loss: 2.2130 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4203 - value_mse: 0.1156\n","epoch 909\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9696 - policy_loss: 2.2185 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4113 - value_mse: 0.1171\n","epoch 910\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9656 - policy_loss: 2.2142 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4206 - value_mse: 0.1157\n","epoch 911\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9521 - policy_loss: 2.2006 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4182 - value_mse: 0.1172\n","epoch 912\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9487 - policy_loss: 2.1977 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4179 - value_mse: 0.1163\n","epoch 913\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9798 - policy_loss: 2.2270 - value_loss: 0.6886 - policy_categorical_accuracy: 0.4143 - value_mse: 0.1179\n","epoch 914\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0093 - policy_loss: 2.2578 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4133 - value_mse: 0.1159\n","epoch 915\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9569 - policy_loss: 2.2045 - value_loss: 0.6881 - policy_categorical_accuracy: 0.4155 - value_mse: 0.1170\n","epoch 916\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9485 - policy_loss: 2.1968 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4262 - value_mse: 0.1151\n","epoch 917\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9539 - policy_loss: 2.2036 - value_loss: 0.6860 - policy_categorical_accuracy: 0.4202 - value_mse: 0.1163\n","epoch 918\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9537 - policy_loss: 2.2022 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4165 - value_mse: 0.1172\n","epoch 919\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9831 - policy_loss: 2.2322 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4184 - value_mse: 0.1158\n","epoch 920\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9565 - policy_loss: 2.2042 - value_loss: 0.6879 - policy_categorical_accuracy: 0.4173 - value_mse: 0.1171\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.946929693222046, 2.195309638977051, 0.6872974634170532, 0.42730000615119934, 0.11711889505386353]\n","epoch 921\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9191 - policy_loss: 2.1674 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4304 - value_mse: 0.1165\n","epoch 922\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9659 - policy_loss: 2.2148 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4216 - value_mse: 0.1169\n","epoch 923\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9513 - policy_loss: 2.2003 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4206 - value_mse: 0.1170\n","epoch 924\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9641 - policy_loss: 2.2134 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4192 - value_mse: 0.1159\n","epoch 925\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9567 - policy_loss: 2.2054 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4213 - value_mse: 0.1172\n","epoch 926\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9569 - policy_loss: 2.2066 - value_loss: 0.6859 - policy_categorical_accuracy: 0.4230 - value_mse: 0.1157\n","epoch 927\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9750 - policy_loss: 2.2243 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4205 - value_mse: 0.1157\n","epoch 928\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 2.9695 - policy_loss: 2.2182 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4113 - value_mse: 0.1184\n","epoch 929\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 2.9859 - policy_loss: 2.2358 - value_loss: 0.6858 - policy_categorical_accuracy: 0.4129 - value_mse: 0.1158\n","epoch 930\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 57ms/step - loss: 2.9736 - policy_loss: 2.2225 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4124 - value_mse: 0.1164\n","epoch 931\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9814 - policy_loss: 2.2307 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4188 - value_mse: 0.1169\n","epoch 932\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9677 - policy_loss: 2.2168 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4145 - value_mse: 0.1182\n","epoch 933\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9385 - policy_loss: 2.1885 - value_loss: 0.6857 - policy_categorical_accuracy: 0.4268 - value_mse: 0.1168\n","epoch 934\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9621 - policy_loss: 2.2111 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4201 - value_mse: 0.1162\n","epoch 935\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9728 - policy_loss: 2.2221 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4191 - value_mse: 0.1164\n","epoch 936\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.0043 - policy_loss: 2.2526 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4128 - value_mse: 0.1165\n","epoch 937\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9389 - policy_loss: 2.1879 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4208 - value_mse: 0.1166\n","epoch 938\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9448 - policy_loss: 2.1948 - value_loss: 0.6855 - policy_categorical_accuracy: 0.4252 - value_mse: 0.1168\n","epoch 939\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9640 - policy_loss: 2.2131 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4194 - value_mse: 0.1174\n","epoch 940\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9416 - policy_loss: 2.1905 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4274 - value_mse: 0.1165\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.985621213912964, 2.233133316040039, 0.6880218386650085, 0.42239999771118164, 0.11749590933322906]\n","epoch 941\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9651 - policy_loss: 2.2136 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4144 - value_mse: 0.1175\n","epoch 942\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9511 - policy_loss: 2.2001 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4215 - value_mse: 0.1168\n","epoch 943\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9862 - policy_loss: 2.2345 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4138 - value_mse: 0.1174\n","epoch 944\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9424 - policy_loss: 2.1909 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4203 - value_mse: 0.1156\n","epoch 945\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9118 - policy_loss: 2.1601 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4247 - value_mse: 0.1180\n","epoch 946\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9659 - policy_loss: 2.2154 - value_loss: 0.6860 - policy_categorical_accuracy: 0.4220 - value_mse: 0.1148\n","epoch 947\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9477 - policy_loss: 2.1959 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4190 - value_mse: 0.1164\n","epoch 948\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9628 - policy_loss: 2.2111 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4129 - value_mse: 0.1177\n","epoch 949\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9697 - policy_loss: 2.2191 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4145 - value_mse: 0.1158\n","epoch 950\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9790 - policy_loss: 2.2268 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4131 - value_mse: 0.1166\n","epoch 951\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9437 - policy_loss: 2.1922 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4150 - value_mse: 0.1175\n","epoch 952\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9677 - policy_loss: 2.2173 - value_loss: 0.6858 - policy_categorical_accuracy: 0.4137 - value_mse: 0.1168\n","epoch 953\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9922 - policy_loss: 2.2412 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4058 - value_mse: 0.1151\n","epoch 954\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9341 - policy_loss: 2.1823 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4265 - value_mse: 0.1175\n","epoch 955\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9444 - policy_loss: 2.1925 - value_loss: 0.6873 - policy_categorical_accuracy: 0.4218 - value_mse: 0.1173\n","epoch 956\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9508 - policy_loss: 2.1997 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4233 - value_mse: 0.1160\n","epoch 957\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9509 - policy_loss: 2.1992 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4227 - value_mse: 0.1154\n","epoch 958\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9602 - policy_loss: 2.2090 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4169 - value_mse: 0.1171\n","epoch 959\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9972 - policy_loss: 2.2463 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4152 - value_mse: 0.1173\n","epoch 960\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9799 - policy_loss: 2.2288 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4156 - value_mse: 0.1156\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9421796798706055, 2.190140962600708, 0.687378466129303, 0.42489999532699585, 0.1171765848994255]\n","epoch 961\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9603 - policy_loss: 2.2072 - value_loss: 0.6884 - policy_categorical_accuracy: 0.4247 - value_mse: 0.1170\n","epoch 962\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9803 - policy_loss: 2.2298 - value_loss: 0.6858 - policy_categorical_accuracy: 0.4201 - value_mse: 0.1168\n","epoch 963\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9576 - policy_loss: 2.2063 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4154 - value_mse: 0.1181\n","epoch 964\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 60ms/step - loss: 2.9540 - policy_loss: 2.2031 - value_loss: 0.6863 - policy_categorical_accuracy: 0.4149 - value_mse: 0.1153\n","epoch 965\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 2.9960 - policy_loss: 2.2465 - value_loss: 0.6849 - policy_categorical_accuracy: 0.4106 - value_mse: 0.1158\n","epoch 966\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9630 - policy_loss: 2.2105 - value_loss: 0.6879 - policy_categorical_accuracy: 0.4187 - value_mse: 0.1149\n","epoch 967\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9875 - policy_loss: 2.2368 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4181 - value_mse: 0.1161\n","epoch 968\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9618 - policy_loss: 2.2109 - value_loss: 0.6862 - policy_categorical_accuracy: 0.4197 - value_mse: 0.1146\n","epoch 969\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9580 - policy_loss: 2.2069 - value_loss: 0.6864 - policy_categorical_accuracy: 0.4131 - value_mse: 0.1188\n","epoch 970\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9758 - policy_loss: 2.2235 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4079 - value_mse: 0.1169\n","epoch 971\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9941 - policy_loss: 2.2427 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4121 - value_mse: 0.1163\n","epoch 972\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9671 - policy_loss: 2.2152 - value_loss: 0.6872 - policy_categorical_accuracy: 0.4180 - value_mse: 0.1154\n","epoch 973\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9331 - policy_loss: 2.1836 - value_loss: 0.6848 - policy_categorical_accuracy: 0.4219 - value_mse: 0.1166\n","epoch 974\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9652 - policy_loss: 2.2135 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4139 - value_mse: 0.1180\n","epoch 975\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9890 - policy_loss: 2.2365 - value_loss: 0.6878 - policy_categorical_accuracy: 0.4156 - value_mse: 0.1168\n","epoch 976\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9673 - policy_loss: 2.2157 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4166 - value_mse: 0.1165\n","epoch 977\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9755 - policy_loss: 2.2229 - value_loss: 0.6879 - policy_categorical_accuracy: 0.4167 - value_mse: 0.1163\n","epoch 978\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9792 - policy_loss: 2.2276 - value_loss: 0.6869 - policy_categorical_accuracy: 0.4177 - value_mse: 0.1175\n","epoch 979\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9640 - policy_loss: 2.2122 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4242 - value_mse: 0.1165\n","epoch 980\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9515 - policy_loss: 2.2008 - value_loss: 0.6860 - policy_categorical_accuracy: 0.4213 - value_mse: 0.1174\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.930572509765625, 2.1791799068450928, 0.6866785883903503, 0.4262000024318695, 0.11682546138763428]\n","epoch 981\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9595 - policy_loss: 2.2087 - value_loss: 0.6861 - policy_categorical_accuracy: 0.4191 - value_mse: 0.1170\n","epoch 982\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9778 - policy_loss: 2.2255 - value_loss: 0.6876 - policy_categorical_accuracy: 0.4151 - value_mse: 0.1169\n","epoch 983\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9581 - policy_loss: 2.2075 - value_loss: 0.6859 - policy_categorical_accuracy: 0.4181 - value_mse: 0.1156\n","epoch 984\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9353 - policy_loss: 2.1840 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4191 - value_mse: 0.1167\n","epoch 985\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9530 - policy_loss: 2.2001 - value_loss: 0.6881 - policy_categorical_accuracy: 0.4183 - value_mse: 0.1171\n","epoch 986\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9458 - policy_loss: 2.1944 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4211 - value_mse: 0.1169\n","epoch 987\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9553 - policy_loss: 2.2031 - value_loss: 0.6874 - policy_categorical_accuracy: 0.4178 - value_mse: 0.1169\n","epoch 988\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9496 - policy_loss: 2.1971 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4205 - value_mse: 0.1170\n","epoch 989\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9388 - policy_loss: 2.1860 - value_loss: 0.6880 - policy_categorical_accuracy: 0.4203 - value_mse: 0.1179\n","epoch 990\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9392 - policy_loss: 2.1874 - value_loss: 0.6871 - policy_categorical_accuracy: 0.4234 - value_mse: 0.1170\n","epoch 991\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9273 - policy_loss: 2.1748 - value_loss: 0.6877 - policy_categorical_accuracy: 0.4246 - value_mse: 0.1168\n","epoch 992\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9659 - policy_loss: 2.2154 - value_loss: 0.6858 - policy_categorical_accuracy: 0.4225 - value_mse: 0.1153\n","epoch 993\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9578 - policy_loss: 2.2064 - value_loss: 0.6866 - policy_categorical_accuracy: 0.4236 - value_mse: 0.1156\n","epoch 994\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9645 - policy_loss: 2.2132 - value_loss: 0.6865 - policy_categorical_accuracy: 0.4137 - value_mse: 0.1156\n","epoch 995\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9744 - policy_loss: 2.2229 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4156 - value_mse: 0.1163\n","epoch 996\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9487 - policy_loss: 2.1971 - value_loss: 0.6868 - policy_categorical_accuracy: 0.4162 - value_mse: 0.1176\n","epoch 997\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9817 - policy_loss: 2.2289 - value_loss: 0.6880 - policy_categorical_accuracy: 0.4173 - value_mse: 0.1175\n","epoch 998\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9532 - policy_loss: 2.2014 - value_loss: 0.6870 - policy_categorical_accuracy: 0.4178 - value_mse: 0.1176\n","epoch 999\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 2.9684 - policy_loss: 2.2169 - value_loss: 0.6867 - policy_categorical_accuracy: 0.4128 - value_mse: 0.1145\n","epoch 1000\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 2.9545 - policy_loss: 2.2045 - value_loss: 0.6851 - policy_categorical_accuracy: 0.4279 - value_mse: 0.1158\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.955159902572632, 2.2034902572631836, 0.6868168711662292, 0.4187999963760376, 0.11689266562461853]\n"]}],"source":["#!python mobile_net_v2.py"]},{"cell_type":"code","source":["!python mobile_net_v2_auto.py --file-name Mobile_Net_v2_test_42epochs --n-epochs 42"],"metadata":{"id":"fSI3__sVnL6i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672721599270,"user_tz":180,"elapsed":343673,"user":{"displayName":"Lucas Pereira Fernandes","userId":"05625161092497965326"}},"outputId":"0d30a649-3286-4758-977f-b1000f29f957"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-03 04:47:36.119155: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-03 04:47:37.131388: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-01-03 04:47:37.131959: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-01-03 04:47:37.131980: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","getValidation\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","tcmalloc: large alloc 2400002048 bytes == 0x55ac2000 @  0x7f05c4a71887 0x7f0571c6c0d9 0x7f0571c7185f 0x7f0571c8606f 0x58e314 0x514581 0x58e967 0x51049c 0x5a5fb6 0x607433 0x601066 0x60112c 0x6015f6 0x64faa2 0x64fc4e 0x7f05c466cc87 0x5b64ca\n","nbPositionsSGF = 29425326\n","nbPositionsSGF = 29425326\n","loading validation.data\n","2023-01-03 04:48:04.086235: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-03 04:48:04.094204: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-03 04:48:04.094794: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-03 04:48:04.095642: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-03 04:48:04.095874: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-03 04:48:04.096476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-03 04:48:04.097068: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-03 04:48:04.728889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-03 04:48:04.729641: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-03 04:48:04.730222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-03 04:48:04.730773: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-01-03 04:48:04.730826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13779 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," board (InputLayer)             [(None, 19, 19, 31)  0           []                               \n","                                ]                                                                 \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 19, 19, 24)   768         ['board[0][0]']                  \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 19, 19, 24)  96          ['conv2d[0][0]']                 \n"," alization)                                                                                       \n","                                                                                                  \n"," tf.math.sigmoid (TFOpLambda)   (None, 19, 19, 24)   0           ['batch_normalization[0][0]']    \n","                                                                                                  \n"," multiply (Multiply)            (None, 19, 19, 24)   0           ['batch_normalization[0][0]',    \n","                                                                  'tf.math.sigmoid[0][0]']        \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 19, 19, 48)   1152        ['multiply[0][0]']               \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 19, 19, 48)  192         ['conv2d_1[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.math.sigmoid_1 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," multiply_1 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_1[0][0]',  \n","                                                                  'tf.math.sigmoid_1[0][0]']      \n","                                                                                                  \n"," depthwise_conv2d (DepthwiseCon  (None, 19, 19, 48)  432         ['multiply_1[0][0]']             \n"," v2D)                                                                                             \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 19, 19, 48)  192         ['depthwise_conv2d[0][0]']       \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.math.sigmoid_2 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_2[0][0]']  \n","                                                                                                  \n"," multiply_2 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_2[0][0]',  \n","                                                                  'tf.math.sigmoid_2[0][0]']      \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 19, 19, 24)   1152        ['multiply_2[0][0]']             \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 19, 19, 24)  96          ['conv2d_2[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add (Add)                      (None, 19, 19, 24)   0           ['batch_normalization_3[0][0]',  \n","                                                                  'multiply[0][0]']               \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 19, 19, 48)   1152        ['add[0][0]']                    \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 19, 19, 48)  192         ['conv2d_3[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.math.sigmoid_3 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_4[0][0]']  \n","                                                                                                  \n"," multiply_3 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_4[0][0]',  \n","                                                                  'tf.math.sigmoid_3[0][0]']      \n","                                                                                                  \n"," depthwise_conv2d_1 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_3[0][0]']             \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 19, 19, 48)  192         ['depthwise_conv2d_1[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.math.sigmoid_4 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," multiply_4 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_5[0][0]',  \n","                                                                  'tf.math.sigmoid_4[0][0]']      \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 19, 19, 24)   1152        ['multiply_4[0][0]']             \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 19, 19, 24)  96          ['conv2d_4[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add_1 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_6[0][0]',  \n","                                                                  'add[0][0]']                    \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 19, 19, 48)   1152        ['add_1[0][0]']                  \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 19, 19, 48)  192         ['conv2d_5[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.math.sigmoid_5 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_7[0][0]']  \n","                                                                                                  \n"," multiply_5 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_7[0][0]',  \n","                                                                  'tf.math.sigmoid_5[0][0]']      \n","                                                                                                  \n"," depthwise_conv2d_2 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_5[0][0]']             \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 19, 19, 48)  192         ['depthwise_conv2d_2[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," tf.math.sigmoid_6 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_8[0][0]']  \n","                                                                                                  \n"," multiply_6 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_8[0][0]',  \n","                                                                  'tf.math.sigmoid_6[0][0]']      \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 19, 19, 24)   1152        ['multiply_6[0][0]']             \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 19, 19, 24)  96          ['conv2d_6[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add_2 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_9[0][0]',  \n","                                                                  'add_1[0][0]']                  \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 19, 19, 48)   1152        ['add_2[0][0]']                  \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 19, 19, 48)  192         ['conv2d_7[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_7 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_10[0][0]'] \n","                                                                                                  \n"," multiply_7 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_10[0][0]', \n","                                                                  'tf.math.sigmoid_7[0][0]']      \n","                                                                                                  \n"," depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_7[0][0]']             \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_11 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_3[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_8 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_11[0][0]'] \n","                                                                                                  \n"," multiply_8 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_11[0][0]', \n","                                                                  'tf.math.sigmoid_8[0][0]']      \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 19, 19, 24)   1152        ['multiply_8[0][0]']             \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 19, 19, 24)  96          ['conv2d_8[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_3 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_12[0][0]', \n","                                                                  'add_2[0][0]']                  \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 19, 19, 48)   1152        ['add_3[0][0]']                  \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 19, 19, 48)  192         ['conv2d_9[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_9 (TFOpLambda)  (None, 19, 19, 48)  0           ['batch_normalization_13[0][0]'] \n","                                                                                                  \n"," multiply_9 (Multiply)          (None, 19, 19, 48)   0           ['batch_normalization_13[0][0]', \n","                                                                  'tf.math.sigmoid_9[0][0]']      \n","                                                                                                  \n"," depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_9[0][0]']             \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_4[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_10 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_14[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_10 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_14[0][0]', \n","                                                                  'tf.math.sigmoid_10[0][0]']     \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 19, 19, 24)   1152        ['multiply_10[0][0]']            \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 19, 19, 24)  96          ['conv2d_10[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_4 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_15[0][0]', \n","                                                                  'add_3[0][0]']                  \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 19, 19, 48)   1152        ['add_4[0][0]']                  \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 19, 19, 48)  192         ['conv2d_11[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_11 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_16[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_11 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_16[0][0]', \n","                                                                  'tf.math.sigmoid_11[0][0]']     \n","                                                                                                  \n"," depthwise_conv2d_5 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_11[0][0]']            \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_5[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_12 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_17[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_12 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_17[0][0]', \n","                                                                  'tf.math.sigmoid_12[0][0]']     \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 19, 19, 24)   1152        ['multiply_12[0][0]']            \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 19, 19, 24)  96          ['conv2d_12[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_5 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_18[0][0]', \n","                                                                  'add_4[0][0]']                  \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 19, 19, 48)   1152        ['add_5[0][0]']                  \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 19, 19, 48)  192         ['conv2d_13[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_13 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_19[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_13 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_19[0][0]', \n","                                                                  'tf.math.sigmoid_13[0][0]']     \n","                                                                                                  \n"," depthwise_conv2d_6 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_13[0][0]']            \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_6[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_14 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_20[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_14 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_20[0][0]', \n","                                                                  'tf.math.sigmoid_14[0][0]']     \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 19, 19, 24)   1152        ['multiply_14[0][0]']            \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 19, 19, 24)  96          ['conv2d_14[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_6 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_21[0][0]', \n","                                                                  'add_5[0][0]']                  \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 19, 19, 48)   1152        ['add_6[0][0]']                  \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 19, 19, 48)  192         ['conv2d_15[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_15 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_22[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_15 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_22[0][0]', \n","                                                                  'tf.math.sigmoid_15[0][0]']     \n","                                                                                                  \n"," depthwise_conv2d_7 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_15[0][0]']            \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_7[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_16 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_23[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_16 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_23[0][0]', \n","                                                                  'tf.math.sigmoid_16[0][0]']     \n","                                                                                                  \n"," conv2d_16 (Conv2D)             (None, 19, 19, 24)   1152        ['multiply_16[0][0]']            \n","                                                                                                  \n"," batch_normalization_24 (BatchN  (None, 19, 19, 24)  96          ['conv2d_16[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_7 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_24[0][0]', \n","                                                                  'add_6[0][0]']                  \n","                                                                                                  \n"," conv2d_17 (Conv2D)             (None, 19, 19, 48)   1152        ['add_7[0][0]']                  \n","                                                                                                  \n"," batch_normalization_25 (BatchN  (None, 19, 19, 48)  192         ['conv2d_17[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_17 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_25[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_17 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_25[0][0]', \n","                                                                  'tf.math.sigmoid_17[0][0]']     \n","                                                                                                  \n"," depthwise_conv2d_8 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_17[0][0]']            \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_26 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_8[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_18 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_26[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_18 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_26[0][0]', \n","                                                                  'tf.math.sigmoid_18[0][0]']     \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 19, 19, 24)   1152        ['multiply_18[0][0]']            \n","                                                                                                  \n"," batch_normalization_27 (BatchN  (None, 19, 19, 24)  96          ['conv2d_18[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_8 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_27[0][0]', \n","                                                                  'add_7[0][0]']                  \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 19, 19, 48)   1152        ['add_8[0][0]']                  \n","                                                                                                  \n"," batch_normalization_28 (BatchN  (None, 19, 19, 48)  192         ['conv2d_19[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_19 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_28[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_19 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_28[0][0]', \n","                                                                  'tf.math.sigmoid_19[0][0]']     \n","                                                                                                  \n"," depthwise_conv2d_9 (DepthwiseC  (None, 19, 19, 48)  432         ['multiply_19[0][0]']            \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_29 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_9[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_20 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_29[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_20 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_29[0][0]', \n","                                                                  'tf.math.sigmoid_20[0][0]']     \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 19, 19, 24)   1152        ['multiply_20[0][0]']            \n","                                                                                                  \n"," batch_normalization_30 (BatchN  (None, 19, 19, 24)  96          ['conv2d_20[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_9 (Add)                    (None, 19, 19, 24)   0           ['batch_normalization_30[0][0]', \n","                                                                  'add_8[0][0]']                  \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 19, 19, 48)   1152        ['add_9[0][0]']                  \n","                                                                                                  \n"," batch_normalization_31 (BatchN  (None, 19, 19, 48)  192         ['conv2d_21[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_21 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_31[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_21 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_31[0][0]', \n","                                                                  'tf.math.sigmoid_21[0][0]']     \n","                                                                                                  \n"," depthwise_conv2d_10 (Depthwise  (None, 19, 19, 48)  432         ['multiply_21[0][0]']            \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_32 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_10[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_22 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_32[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_22 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_32[0][0]', \n","                                                                  'tf.math.sigmoid_22[0][0]']     \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 19, 19, 24)   1152        ['multiply_22[0][0]']            \n","                                                                                                  \n"," batch_normalization_33 (BatchN  (None, 19, 19, 24)  96          ['conv2d_22[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_10 (Add)                   (None, 19, 19, 24)   0           ['batch_normalization_33[0][0]', \n","                                                                  'add_9[0][0]']                  \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 19, 19, 48)   1152        ['add_10[0][0]']                 \n","                                                                                                  \n"," batch_normalization_34 (BatchN  (None, 19, 19, 48)  192         ['conv2d_23[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_23 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_34[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_23 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_34[0][0]', \n","                                                                  'tf.math.sigmoid_23[0][0]']     \n","                                                                                                  \n"," depthwise_conv2d_11 (Depthwise  (None, 19, 19, 48)  432         ['multiply_23[0][0]']            \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_35 (BatchN  (None, 19, 19, 48)  192         ['depthwise_conv2d_11[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.math.sigmoid_24 (TFOpLambda  (None, 19, 19, 48)  0           ['batch_normalization_35[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," multiply_24 (Multiply)         (None, 19, 19, 48)   0           ['batch_normalization_35[0][0]', \n","                                                                  'tf.math.sigmoid_24[0][0]']     \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 19, 19, 24)   1152        ['multiply_24[0][0]']            \n","                                                                                                  \n"," batch_normalization_36 (BatchN  (None, 19, 19, 24)  96          ['conv2d_24[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_11 (Add)                   (None, 19, 19, 24)   0           ['batch_normalization_36[0][0]', \n","                                                                  'add_10[0][0]']                 \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 19, 19, 1)    24          ['add_11[0][0]']                 \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 19, 19, 1)    24          ['add_11[0][0]']                 \n","                                                                                                  \n"," flatten_1 (Flatten)            (None, 361)          0           ['conv2d_26[0][0]']              \n","                                                                                                  \n"," flatten (Flatten)              (None, 361)          0           ['conv2d_25[0][0]']              \n","                                                                                                  \n"," dense (Dense)                  (None, 50)           18100       ['flatten_1[0][0]']              \n","                                                                                                  \n"," policy (Activation)            (None, 361)          0           ['flatten[0][0]']                \n","                                                                                                  \n"," value (Dense)                  (None, 1)            51          ['dense[0][0]']                  \n","                                                                                                  \n","==================================================================================================\n","Total params: 57,655\n","Trainable params: 54,727\n","Non-trainable params: 2,928\n","__________________________________________________________________________________________________\n","epoch 1\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-03 04:48:19.351154: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n","2023-01-03 04:48:20.761392: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x10bb95000 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-01-03 04:48:20.761443: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2023-01-03 04:48:20.790397: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2023-01-03 04:48:20.995482: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","79/79 [==============================] - 27s 56ms/step - loss: 7.7820 - policy_loss: 6.8578 - value_loss: 0.8358 - policy_categorical_accuracy: 0.0158 - value_mse: 0.1564\n","epoch 2\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 5.8240 - policy_loss: 5.0343 - value_loss: 0.7013 - policy_categorical_accuracy: 0.0444 - value_mse: 0.1233\n","epoch 3\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 5.1287 - policy_loss: 4.3425 - value_loss: 0.6981 - policy_categorical_accuracy: 0.1199 - value_mse: 0.1228\n","epoch 4\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 4.6956 - policy_loss: 3.9120 - value_loss: 0.6956 - policy_categorical_accuracy: 0.1753 - value_mse: 0.1220\n","epoch 5\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 4.5637 - policy_loss: 3.7818 - value_loss: 0.6942 - policy_categorical_accuracy: 0.1925 - value_mse: 0.1200\n","epoch 6\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 4.4062 - policy_loss: 3.6243 - value_loss: 0.6945 - policy_categorical_accuracy: 0.2155 - value_mse: 0.1187\n","epoch 7\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 4.3102 - policy_loss: 3.5298 - value_loss: 0.6932 - policy_categorical_accuracy: 0.2344 - value_mse: 0.1202\n","epoch 8\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 4.1895 - policy_loss: 3.4101 - value_loss: 0.6925 - policy_categorical_accuracy: 0.2479 - value_mse: 0.1195\n","epoch 9\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 57ms/step - loss: 4.1267 - policy_loss: 3.3476 - value_loss: 0.6925 - policy_categorical_accuracy: 0.2593 - value_mse: 0.1187\n","epoch 10\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 4.0539 - policy_loss: 3.2754 - value_loss: 0.6921 - policy_categorical_accuracy: 0.2666 - value_mse: 0.1185\n","epoch 11\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.9773 - policy_loss: 3.1986 - value_loss: 0.6925 - policy_categorical_accuracy: 0.2831 - value_mse: 0.1209\n","epoch 12\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.9302 - policy_loss: 3.1525 - value_loss: 0.6919 - policy_categorical_accuracy: 0.2906 - value_mse: 0.1197\n","epoch 13\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.8767 - policy_loss: 3.0993 - value_loss: 0.6918 - policy_categorical_accuracy: 0.2875 - value_mse: 0.1184\n","epoch 14\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.8659 - policy_loss: 3.0884 - value_loss: 0.6922 - policy_categorical_accuracy: 0.2898 - value_mse: 0.1172\n","epoch 15\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.8758 - policy_loss: 3.0990 - value_loss: 0.6918 - policy_categorical_accuracy: 0.2933 - value_mse: 0.1196\n","epoch 16\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 58ms/step - loss: 3.8276 - policy_loss: 3.0516 - value_loss: 0.6912 - policy_categorical_accuracy: 0.2956 - value_mse: 0.1173\n","epoch 17\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 57ms/step - loss: 3.8186 - policy_loss: 3.0427 - value_loss: 0.6914 - policy_categorical_accuracy: 0.2994 - value_mse: 0.1175\n","epoch 18\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.7783 - policy_loss: 3.0027 - value_loss: 0.6914 - policy_categorical_accuracy: 0.3090 - value_mse: 0.1202\n","epoch 19\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 3.7658 - policy_loss: 2.9913 - value_loss: 0.6905 - policy_categorical_accuracy: 0.3057 - value_mse: 0.1161\n","epoch 20\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.7334 - policy_loss: 2.9589 - value_loss: 0.6908 - policy_categorical_accuracy: 0.3087 - value_mse: 0.1194\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.7498843669891357, 2.9754927158355713, 0.6907919049263, 0.3084999918937683, 0.11886969953775406]\n","epoch 21\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.7039 - policy_loss: 2.9310 - value_loss: 0.6894 - policy_categorical_accuracy: 0.3094 - value_mse: 0.1173\n","epoch 22\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.7029 - policy_loss: 2.9291 - value_loss: 0.6906 - policy_categorical_accuracy: 0.3160 - value_mse: 0.1190\n","epoch 23\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.7032 - policy_loss: 2.9305 - value_loss: 0.6898 - policy_categorical_accuracy: 0.3125 - value_mse: 0.1184\n","epoch 24\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.6896 - policy_loss: 2.9169 - value_loss: 0.6901 - policy_categorical_accuracy: 0.3209 - value_mse: 0.1187\n","epoch 25\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.6750 - policy_loss: 2.9017 - value_loss: 0.6909 - policy_categorical_accuracy: 0.3222 - value_mse: 0.1178\n","epoch 26\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.6847 - policy_loss: 2.9131 - value_loss: 0.6895 - policy_categorical_accuracy: 0.3158 - value_mse: 0.1165\n","epoch 27\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 57ms/step - loss: 3.6241 - policy_loss: 2.8523 - value_loss: 0.6900 - policy_categorical_accuracy: 0.3272 - value_mse: 0.1193\n","epoch 28\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.6139 - policy_loss: 2.8425 - value_loss: 0.6898 - policy_categorical_accuracy: 0.3325 - value_mse: 0.1175\n","epoch 29\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.6145 - policy_loss: 2.8431 - value_loss: 0.6901 - policy_categorical_accuracy: 0.3336 - value_mse: 0.1174\n","epoch 30\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 55ms/step - loss: 3.5547 - policy_loss: 2.7843 - value_loss: 0.6894 - policy_categorical_accuracy: 0.3314 - value_mse: 0.1178\n","epoch 31\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.6004 - policy_loss: 2.8303 - value_loss: 0.6893 - policy_categorical_accuracy: 0.3308 - value_mse: 0.1165\n","epoch 32\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.5850 - policy_loss: 2.8146 - value_loss: 0.6899 - policy_categorical_accuracy: 0.3358 - value_mse: 0.1168\n","epoch 33\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 57ms/step - loss: 3.5965 - policy_loss: 2.8280 - value_loss: 0.6882 - policy_categorical_accuracy: 0.3339 - value_mse: 0.1160\n","epoch 34\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 57ms/step - loss: 3.5926 - policy_loss: 2.8232 - value_loss: 0.6894 - policy_categorical_accuracy: 0.3280 - value_mse: 0.1180\n","epoch 35\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.5615 - policy_loss: 2.7927 - value_loss: 0.6890 - policy_categorical_accuracy: 0.3391 - value_mse: 0.1162\n","epoch 36\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 57ms/step - loss: 3.5517 - policy_loss: 2.7845 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3344 - value_mse: 0.1178\n","epoch 37\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.5582 - policy_loss: 2.7907 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3371 - value_mse: 0.1178\n","epoch 38\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.5771 - policy_loss: 2.8089 - value_loss: 0.6893 - policy_categorical_accuracy: 0.3305 - value_mse: 0.1186\n","epoch 39\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.5665 - policy_loss: 2.7988 - value_loss: 0.6891 - policy_categorical_accuracy: 0.3295 - value_mse: 0.1173\n","epoch 40\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 5s 59ms/step - loss: 3.5440 - policy_loss: 2.7773 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3389 - value_mse: 0.1148\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.5283687114715576, 2.7619543075561523, 0.688228189945221, 0.33570000529289246, 0.11760216951370239]\n","epoch 41\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.5444 - policy_loss: 2.7777 - value_loss: 0.6886 - policy_categorical_accuracy: 0.3367 - value_mse: 0.1167\n","epoch 42\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 4s 56ms/step - loss: 3.5224 - policy_loss: 2.7561 - value_loss: 0.6885 - policy_categorical_accuracy: 0.3349 - value_mse: 0.1187\n"]}]},{"cell_type":"code","source":["import numpy as np\n","a = np.load('Mobile_Net_v2_test_42epochs_val.npy')"],"metadata":{"id":"w7V8s9xT5g0j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bfwu10ns60gp","executionInfo":{"status":"ok","timestamp":1672721100419,"user_tz":180,"elapsed":357,"user":{"displayName":"Lucas Pereira Fernandes","userId":"05625161092497965326"}},"outputId":"7ae8bb27-9e7a-488b-cf99-1533932c4988"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3.51729369, 2.75028372, 0.68980569, 0.3461    , 0.11837885])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["!python resnet.py --file-name resnet_0 --n-epochs 100"],"metadata":{"id":"dt-2RUX-63hW"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}